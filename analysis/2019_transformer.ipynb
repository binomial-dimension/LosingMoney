{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from EarlyStopping import EarlyStopping\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# S is the source sequence length\n",
    "# T is the target sequence length\n",
    "# N is the batch size\n",
    "# E is the feature number\n",
    "\n",
    "#src = torch.rand((10, 32, 512)) # (S,N,E)\n",
    "#tgt = torch.rand((20, 32, 512)) # (T,N,E)\n",
    "#out = transformer_model(src, tgt)\n",
    "\n",
    "input_window = 150  # number of input steps\n",
    "output_window = 1  # number of prediction steps, in this model its fixed to one\n",
    "batch_size = 512\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=7000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() *\n",
    "            (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        #pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "\n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self, feature_size=300, num_layers=1, dropout=0.1):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size,\n",
    "                                                        nhead=10,\n",
    "                                                        dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer,\n",
    "                                                         num_layers=num_layers)\n",
    "        self.decoder = nn.Linear(feature_size, 1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src,\n",
    "                                          self.src_mask)  #, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(\n",
    "            mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "\n",
    "# if window is 100 and prediction step is 1\n",
    "# in -> [0..99]\n",
    "# target -> [1..100]\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L - tw):\n",
    "        train_seq = input_data[i:i + tw]\n",
    "        train_label = input_data[i + output_window:i + tw + output_window]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return torch.FloatTensor(np.array(inout_seq))\n",
    "\n",
    "\n",
    "def get_data(name):\n",
    "    # construct a littel toy dataset\n",
    "    time = np.arange(0, 400, 0.1)\n",
    "    data = pd.read_csv('../data/hs300.csv')\n",
    "    amplitude = data[name].values\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    #loading weather data from a file\n",
    "    #from pandas import read_csv\n",
    "    #series = read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "\n",
    "    # looks like normalizing input values curtial for the model\n",
    "    scaler = StandardScaler()\n",
    "    #amplitude = scaler.fit_transform(series.to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "    amplitude = scaler.fit_transform(amplitude.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "    sampels = int(len(amplitude)*0.9)\n",
    "    train_data = amplitude[:sampels]\n",
    "    test_data = amplitude[sampels:]\n",
    "\n",
    "    # convert our train data into a pytorch train tensor\n",
    "    #train_tensor = torch.FloatTensor(train_data).view(-1)\n",
    "    # todo: add comment..\n",
    "    train_sequence = create_inout_sequences(train_data, input_window)\n",
    "    train_sequence = train_sequence[:\n",
    "                                    -output_window]  #todo: fix hack? -> din't think this through, looks like the last n sequences are to short, so I just remove them. Hackety Hack..\n",
    "\n",
    "    #test_data = torch.FloatTensor(test_data).view(-1)\n",
    "    test_data = create_inout_sequences(test_data, input_window)\n",
    "    test_data = test_data[:-output_window]  #todo: fix hack?\n",
    "\n",
    "    return train_sequence.to(device), test_data.to(device),scaler\n",
    "\n",
    "\n",
    "def get_batch(source, i, batch_size):\n",
    "    seq_len = min(batch_size, len(source) - 1 - i)\n",
    "    data = source[i:i + seq_len]\n",
    "    input = torch.stack(\n",
    "        torch.stack([item[0] for item in data]).chunk(input_window,1))  # 1 is feature size\n",
    "    target = torch.stack(\n",
    "        torch.stack([item[1] for item in data]).chunk(input_window, 1))\n",
    "    return input, target\n",
    "\n",
    "\n",
    "def train(train_data,epoch,train_losses):\n",
    "    model.train()  # Turn on the train mode \\o/\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    \n",
    "\n",
    "    for batch, i in enumerate(range(0, len(train_data) - 1, batch_size)):\n",
    "        data, targets = get_batch(train_data, i, batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.8)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = int(len(train_data) / batch_size)\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "\n",
    "def plot_and_loss(eval_model, data_source, epoch):\n",
    "    eval_model.eval()\n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)\n",
    "    truth = torch.Tensor(0)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1):\n",
    "            data, target = get_batch(data_source, i, 1)\n",
    "            output = eval_model(data)\n",
    "            total_loss += criterion(output, target).item()\n",
    "            test_result = torch.cat((test_result, output[-1].view(-1).cpu()),\n",
    "                                    0)\n",
    "            truth = torch.cat((truth, target[-1].view(-1).cpu()), 0)\n",
    "\n",
    "    #test_result = test_result.cpu().numpy() -> no need to detach stuff..\n",
    "    len(test_result)\n",
    "\n",
    "    pyplot.plot(test_result, color=\"red\", label=\"prediction\")\n",
    "    pyplot.plot(truth[:len(test_result)], color=\"blue\", label=\"truth\")\n",
    "    pyplot.plot(test_result - truth, color=\"green\", label=\"error\")\n",
    "    pyplot.legend()\n",
    "    pyplot.grid(True, which='both')\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    pyplot.savefig('graph/transformer-epoch%d.png' % epoch)\n",
    "    pyplot.close()\n",
    "\n",
    "    return total_loss / i\n",
    "\n",
    "\n",
    "# predict the next n steps based on the input data\n",
    "def predict_future(eval_model, data_source, steps):\n",
    "    eval_model.eval()\n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)\n",
    "    truth = torch.Tensor(0)\n",
    "    data, _ = get_batch(data_source, 0, 1)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, steps):\n",
    "            output = eval_model(data[-input_window:])\n",
    "            data = torch.cat((data, output[-1:]))\n",
    "\n",
    "    data = data.cpu().view(-1)\n",
    "\n",
    "    # I used this plot to visualize if the model pics up any long therm structure within the data.\n",
    "    pyplot.plot(data, color=\"red\")\n",
    "    pyplot.plot(data[:input_window], color=\"blue\")\n",
    "    pyplot.grid(True, which='both')\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    pyplot.savefig('graph/transformer-future%d.png' % steps)\n",
    "    pyplot.close()\n",
    "\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval()  # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    eval_batch_size = 500\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1, eval_batch_size):\n",
    "            data, targets = get_batch(data_source, i, eval_batch_size)\n",
    "            output = eval_model(data)\n",
    "            total_loss += len(data[0]) * criterion(output, targets).cpu().item()\n",
    "    return total_loss / len(data_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_get(name):\n",
    "    input_window = 120  # number of input steps\n",
    "    output_window = 1  # number of prediction steps, in this model its fixed to one\n",
    "    batch_size = 800\n",
    "    device = torch.device(\"cuda\")\n",
    "    train_data, val_data, scaler = get_data(name)\n",
    "    global model \n",
    "    model = TransAm().to(device)\n",
    "\n",
    "    global criterion\n",
    "    criterion = nn.MSELoss()\n",
    "    lr = 0.0001  # learning rate\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    global optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    global scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.985)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    global epochs\n",
    "    epochs = 500  # The number of epochs\n",
    "    best_model = None\n",
    "\n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = [] \n",
    "    \n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=50, verbose=True)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(train_data,epoch,train_losses)\n",
    "\n",
    "        if (epoch % 100 == 0):\n",
    "            val_loss = plot_and_loss(model, val_data, epoch)\n",
    "            predict_future(model, val_data, 5)\n",
    "        else:\n",
    "            val_loss = evaluate(model, val_data)\n",
    "\n",
    "        valid_losses.append(val_loss)\n",
    "\n",
    "\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        epoch_len = len(str(epochs))\n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "        \n",
    "        print(print_msg)\n",
    "\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "    \n",
    "    def get_predict(eval_model, data_source):\n",
    "        eval_model.eval()\n",
    "        total_loss = 0.\n",
    "        test_result = torch.Tensor(0)\n",
    "        truth = torch.Tensor(0)\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(data_source) - 1):\n",
    "                data, target = get_batch(data_source, i, 1)\n",
    "                output = eval_model(data)\n",
    "                total_loss += torch.sqrt(criterion(output, target)).item()\n",
    "                test_result = torch.cat((test_result, output[-1].view(-1).cpu()),\n",
    "                                        0)\n",
    "                truth = torch.cat((truth, target[-1].view(-1).cpu()), 0)\n",
    "\n",
    "        #test_result = test_result.cpu().numpy() -> no need to detach stuff..\n",
    "        return scaler.inverse_transform(test_result.view(-1, 1)), scaler.inverse_transform(truth.view(-1, 1))\n",
    "\n",
    "    \n",
    "    return get_predict(model, val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/500] train_loss: 4.48274 valid_loss: 2.03696\n",
      "Validation loss decreased (inf --> 2.036965).  Saving model ...\n",
      "[  2/500] train_loss: 1.48145 valid_loss: 0.55183\n",
      "Validation loss decreased (2.036965 --> 0.551825).  Saving model ...\n",
      "[  3/500] train_loss: 1.27192 valid_loss: 0.91734\n",
      "[  4/500] train_loss: 1.23018 valid_loss: 0.54352\n",
      "Validation loss decreased (0.551825 --> 0.543520).  Saving model ...\n",
      "[  5/500] train_loss: 1.13266 valid_loss: 0.55754\n",
      "[  6/500] train_loss: 0.98315 valid_loss: 0.48622\n",
      "Validation loss decreased (0.543520 --> 0.486220).  Saving model ...\n",
      "[  7/500] train_loss: 0.95010 valid_loss: 0.47687\n",
      "Validation loss decreased (0.486220 --> 0.476873).  Saving model ...\n",
      "[  8/500] train_loss: 0.95475 valid_loss: 0.59415\n",
      "[  9/500] train_loss: 1.07765 valid_loss: 0.64679\n",
      "[ 10/500] train_loss: 0.97200 valid_loss: 0.47988\n",
      "[ 11/500] train_loss: 0.98381 valid_loss: 0.49914\n",
      "[ 12/500] train_loss: 1.01632 valid_loss: 0.54248\n",
      "[ 13/500] train_loss: 0.96519 valid_loss: 0.49607\n",
      "[ 14/500] train_loss: 1.00258 valid_loss: 0.50945\n",
      "[ 15/500] train_loss: 1.02629 valid_loss: 0.52726\n",
      "[ 16/500] train_loss: 0.92096 valid_loss: 0.46796\n",
      "Validation loss decreased (0.476873 --> 0.467957).  Saving model ...\n",
      "[ 17/500] train_loss: 0.96328 valid_loss: 0.47553\n",
      "[ 18/500] train_loss: 0.98788 valid_loss: 0.47299\n",
      "[ 19/500] train_loss: 0.91852 valid_loss: 0.46977\n",
      "[ 20/500] train_loss: 0.94338 valid_loss: 0.47673\n",
      "[ 21/500] train_loss: 0.98383 valid_loss: 0.50135\n",
      "[ 22/500] train_loss: 0.92124 valid_loss: 0.47540\n",
      "[ 23/500] train_loss: 0.96853 valid_loss: 0.49491\n",
      "[ 24/500] train_loss: 0.91028 valid_loss: 0.48395\n",
      "[ 25/500] train_loss: 0.95998 valid_loss: 0.46772\n",
      "Validation loss decreased (0.467957 --> 0.467725).  Saving model ...\n",
      "[ 26/500] train_loss: 0.92528 valid_loss: 0.47519\n",
      "[ 27/500] train_loss: 0.91561 valid_loss: 0.47448\n",
      "[ 28/500] train_loss: 0.93984 valid_loss: 0.47763\n",
      "[ 29/500] train_loss: 0.90431 valid_loss: 0.47057\n",
      "[ 30/500] train_loss: 0.94899 valid_loss: 0.46104\n",
      "Validation loss decreased (0.467725 --> 0.461035).  Saving model ...\n",
      "[ 31/500] train_loss: 0.91319 valid_loss: 0.47167\n",
      "[ 32/500] train_loss: 0.93344 valid_loss: 0.48009\n",
      "[ 33/500] train_loss: 0.90009 valid_loss: 0.46653\n",
      "[ 34/500] train_loss: 0.93440 valid_loss: 0.46343\n",
      "[ 35/500] train_loss: 0.91611 valid_loss: 0.47165\n",
      "[ 36/500] train_loss: 0.91360 valid_loss: 0.47509\n",
      "[ 37/500] train_loss: 0.90480 valid_loss: 0.46864\n",
      "[ 38/500] train_loss: 0.95083 valid_loss: 0.48099\n",
      "[ 39/500] train_loss: 0.90857 valid_loss: 0.47076\n",
      "[ 40/500] train_loss: 0.91639 valid_loss: 0.47156\n",
      "[ 41/500] train_loss: 0.90809 valid_loss: 0.47271\n",
      "[ 42/500] train_loss: 0.95968 valid_loss: 0.47691\n",
      "[ 43/500] train_loss: 0.92291 valid_loss: 0.46327\n",
      "[ 44/500] train_loss: 0.91040 valid_loss: 0.47456\n",
      "[ 45/500] train_loss: 0.89848 valid_loss: 0.46682\n",
      "[ 46/500] train_loss: 0.92506 valid_loss: 0.46591\n",
      "[ 47/500] train_loss: 0.90894 valid_loss: 0.46714\n",
      "[ 48/500] train_loss: 0.90496 valid_loss: 0.47110\n",
      "[ 49/500] train_loss: 0.89638 valid_loss: 0.46929\n",
      "[ 50/500] train_loss: 0.92320 valid_loss: 0.47604\n",
      "[ 51/500] train_loss: 0.89310 valid_loss: 0.47051\n",
      "[ 52/500] train_loss: 0.91054 valid_loss: 0.47345\n",
      "[ 53/500] train_loss: 0.89346 valid_loss: 0.46831\n",
      "[ 54/500] train_loss: 0.91356 valid_loss: 0.47727\n",
      "[ 55/500] train_loss: 0.88906 valid_loss: 0.46821\n",
      "[ 56/500] train_loss: 0.90987 valid_loss: 0.46973\n",
      "[ 57/500] train_loss: 0.89394 valid_loss: 0.46797\n",
      "[ 58/500] train_loss: 0.90730 valid_loss: 0.47123\n",
      "[ 59/500] train_loss: 0.88680 valid_loss: 0.46597\n",
      "[ 60/500] train_loss: 0.90384 valid_loss: 0.47133\n",
      "[ 61/500] train_loss: 0.89023 valid_loss: 0.46660\n",
      "[ 62/500] train_loss: 0.90190 valid_loss: 0.46899\n",
      "[ 63/500] train_loss: 0.88722 valid_loss: 0.46561\n",
      "[ 64/500] train_loss: 0.89927 valid_loss: 0.46838\n",
      "[ 65/500] train_loss: 0.88604 valid_loss: 0.46531\n",
      "[ 66/500] train_loss: 0.89909 valid_loss: 0.46949\n",
      "[ 67/500] train_loss: 0.88485 valid_loss: 0.46557\n",
      "[ 68/500] train_loss: 0.89580 valid_loss: 0.46636\n",
      "[ 69/500] train_loss: 0.88642 valid_loss: 0.46501\n",
      "[ 70/500] train_loss: 0.89901 valid_loss: 0.46747\n",
      "[ 71/500] train_loss: 0.88223 valid_loss: 0.46539\n",
      "[ 72/500] train_loss: 0.89233 valid_loss: 0.46400\n",
      "[ 73/500] train_loss: 0.88411 valid_loss: 0.46480\n",
      "[ 74/500] train_loss: 0.89769 valid_loss: 0.46597\n",
      "[ 75/500] train_loss: 0.88115 valid_loss: 0.46510\n",
      "[ 76/500] train_loss: 0.88932 valid_loss: 0.46241\n",
      "[ 77/500] train_loss: 0.88393 valid_loss: 0.46542\n",
      "[ 78/500] train_loss: 0.90060 valid_loss: 0.46288\n",
      "[ 79/500] train_loss: 0.88465 valid_loss: 0.46537\n",
      "[ 80/500] train_loss: 0.88768 valid_loss: 0.46202\n",
      "Early stopping\n",
      "[  1/500] train_loss: 5.19887 valid_loss: 0.60128\n",
      "Validation loss decreased (inf --> 0.601277).  Saving model ...\n",
      "[  2/500] train_loss: 1.47148 valid_loss: 0.74375\n",
      "[  3/500] train_loss: 1.48697 valid_loss: 0.70203\n",
      "[  4/500] train_loss: 1.45487 valid_loss: 0.91816\n",
      "[  5/500] train_loss: 1.04579 valid_loss: 0.47454\n",
      "Validation loss decreased (0.601277 --> 0.474540).  Saving model ...\n",
      "[  6/500] train_loss: 1.02498 valid_loss: 0.44696\n",
      "Validation loss decreased (0.474540 --> 0.446965).  Saving model ...\n",
      "[  7/500] train_loss: 1.03376 valid_loss: 0.46518\n",
      "[  8/500] train_loss: 1.02975 valid_loss: 0.43327\n",
      "Validation loss decreased (0.446965 --> 0.433274).  Saving model ...\n",
      "[  9/500] train_loss: 0.95039 valid_loss: 0.43895\n",
      "[ 10/500] train_loss: 1.01107 valid_loss: 0.48137\n",
      "[ 11/500] train_loss: 1.10498 valid_loss: 0.46258\n",
      "[ 12/500] train_loss: 0.93865 valid_loss: 0.43680\n",
      "[ 13/500] train_loss: 0.96047 valid_loss: 0.44465\n",
      "[ 14/500] train_loss: 0.96727 valid_loss: 0.43047\n",
      "Validation loss decreased (0.433274 --> 0.430474).  Saving model ...\n",
      "[ 15/500] train_loss: 0.92813 valid_loss: 0.42718\n",
      "Validation loss decreased (0.430474 --> 0.427178).  Saving model ...\n",
      "[ 16/500] train_loss: 1.02679 valid_loss: 0.43752\n",
      "[ 17/500] train_loss: 0.94825 valid_loss: 0.44990\n",
      "[ 18/500] train_loss: 0.92170 valid_loss: 0.42820\n",
      "[ 19/500] train_loss: 0.95091 valid_loss: 0.42937\n",
      "[ 20/500] train_loss: 0.92797 valid_loss: 0.42416\n",
      "Validation loss decreased (0.427178 --> 0.424161).  Saving model ...\n",
      "[ 21/500] train_loss: 0.96972 valid_loss: 0.43181\n",
      "[ 22/500] train_loss: 0.95767 valid_loss: 0.43308\n",
      "[ 23/500] train_loss: 0.92219 valid_loss: 0.42508\n",
      "[ 24/500] train_loss: 0.93331 valid_loss: 0.43973\n",
      "[ 25/500] train_loss: 0.96095 valid_loss: 0.43340\n",
      "[ 26/500] train_loss: 0.91900 valid_loss: 0.44594\n",
      "[ 27/500] train_loss: 0.93008 valid_loss: 0.42679\n",
      "[ 28/500] train_loss: 0.91713 valid_loss: 0.42611\n",
      "[ 29/500] train_loss: 0.93840 valid_loss: 0.43526\n",
      "[ 30/500] train_loss: 0.92591 valid_loss: 0.43073\n",
      "[ 31/500] train_loss: 0.91443 valid_loss: 0.42871\n",
      "[ 32/500] train_loss: 0.92479 valid_loss: 0.42881\n",
      "[ 33/500] train_loss: 0.91960 valid_loss: 0.42833\n",
      "[ 34/500] train_loss: 0.91080 valid_loss: 0.42511\n",
      "[ 35/500] train_loss: 0.93079 valid_loss: 0.43101\n",
      "[ 36/500] train_loss: 0.90939 valid_loss: 0.42295\n",
      "Validation loss decreased (0.424161 --> 0.422949).  Saving model ...\n",
      "[ 37/500] train_loss: 0.92158 valid_loss: 0.43010\n",
      "[ 38/500] train_loss: 0.92993 valid_loss: 0.44750\n",
      "[ 39/500] train_loss: 0.90711 valid_loss: 0.42250\n",
      "Validation loss decreased (0.422949 --> 0.422495).  Saving model ...\n",
      "[ 40/500] train_loss: 0.92909 valid_loss: 0.42367\n",
      "[ 41/500] train_loss: 0.91405 valid_loss: 0.42896\n",
      "[ 42/500] train_loss: 0.90411 valid_loss: 0.42285\n",
      "[ 43/500] train_loss: 0.92166 valid_loss: 0.42717\n",
      "[ 44/500] train_loss: 0.90211 valid_loss: 0.42925\n",
      "[ 45/500] train_loss: 0.90589 valid_loss: 0.42821\n",
      "[ 46/500] train_loss: 0.91189 valid_loss: 0.42544\n",
      "[ 47/500] train_loss: 0.90407 valid_loss: 0.42430\n",
      "[ 48/500] train_loss: 0.92043 valid_loss: 0.44202\n",
      "[ 49/500] train_loss: 0.90503 valid_loss: 0.42795\n",
      "[ 50/500] train_loss: 0.93118 valid_loss: 0.43265\n",
      "[ 51/500] train_loss: 0.90352 valid_loss: 0.42636\n",
      "[ 52/500] train_loss: 0.90589 valid_loss: 0.42793\n",
      "[ 53/500] train_loss: 0.89971 valid_loss: 0.42583\n",
      "[ 54/500] train_loss: 0.90881 valid_loss: 0.43122\n",
      "[ 55/500] train_loss: 0.90006 valid_loss: 0.42489\n",
      "[ 56/500] train_loss: 0.90355 valid_loss: 0.42528\n",
      "[ 57/500] train_loss: 0.89754 valid_loss: 0.42463\n",
      "[ 58/500] train_loss: 0.90749 valid_loss: 0.43023\n",
      "[ 59/500] train_loss: 0.89650 valid_loss: 0.42431\n",
      "[ 60/500] train_loss: 0.90007 valid_loss: 0.42507\n",
      "[ 61/500] train_loss: 0.89549 valid_loss: 0.42510\n",
      "[ 62/500] train_loss: 0.90453 valid_loss: 0.43241\n",
      "[ 63/500] train_loss: 0.89486 valid_loss: 0.42486\n",
      "[ 64/500] train_loss: 0.90669 valid_loss: 0.43158\n",
      "[ 65/500] train_loss: 0.89358 valid_loss: 0.42477\n",
      "[ 66/500] train_loss: 0.89662 valid_loss: 0.42412\n",
      "[ 67/500] train_loss: 0.89471 valid_loss: 0.42493\n",
      "[ 68/500] train_loss: 0.90062 valid_loss: 0.43179\n",
      "[ 69/500] train_loss: 0.89450 valid_loss: 0.42537\n",
      "[ 70/500] train_loss: 0.91179 valid_loss: 0.43926\n",
      "[ 71/500] train_loss: 0.89251 valid_loss: 0.43087\n",
      "[ 72/500] train_loss: 0.90596 valid_loss: 0.43486\n",
      "[ 73/500] train_loss: 0.89475 valid_loss: 0.42385\n",
      "[ 74/500] train_loss: 0.92278 valid_loss: 0.45025\n",
      "[ 75/500] train_loss: 0.89346 valid_loss: 0.42696\n",
      "[ 76/500] train_loss: 0.89863 valid_loss: 0.42760\n",
      "[ 77/500] train_loss: 0.89248 valid_loss: 0.42441\n",
      "[ 78/500] train_loss: 0.91438 valid_loss: 0.44884\n",
      "[ 79/500] train_loss: 0.89224 valid_loss: 0.42675\n",
      "[ 80/500] train_loss: 0.89791 valid_loss: 0.42658\n",
      "[ 81/500] train_loss: 0.89218 valid_loss: 0.42422\n",
      "[ 82/500] train_loss: 0.91235 valid_loss: 0.44306\n",
      "[ 83/500] train_loss: 0.89277 valid_loss: 0.42608\n",
      "[ 84/500] train_loss: 0.89804 valid_loss: 0.42724\n",
      "[ 85/500] train_loss: 0.89018 valid_loss: 0.42500\n",
      "[ 86/500] train_loss: 0.90407 valid_loss: 0.43469\n",
      "[ 87/500] train_loss: 0.89077 valid_loss: 0.42410\n",
      "[ 88/500] train_loss: 0.89637 valid_loss: 0.42674\n",
      "[ 89/500] train_loss: 0.88985 valid_loss: 0.42447\n",
      "Early stopping\n",
      "[  1/500] train_loss: 3.39770 valid_loss: 0.33123\n",
      "Validation loss decreased (inf --> 0.331232).  Saving model ...\n",
      "[  2/500] train_loss: 5.18569 valid_loss: 5.81950\n",
      "[  3/500] train_loss: 1.94524 valid_loss: 0.13422\n",
      "Validation loss decreased (0.331232 --> 0.134221).  Saving model ...\n",
      "[  4/500] train_loss: 0.24291 valid_loss: 0.23620\n",
      "[  5/500] train_loss: 0.78654 valid_loss: 0.42695\n",
      "[  6/500] train_loss: 0.16245 valid_loss: 0.12674\n",
      "Validation loss decreased (0.134221 --> 0.126736).  Saving model ...\n",
      "[  7/500] train_loss: 0.10135 valid_loss: 0.06497\n",
      "Validation loss decreased (0.126736 --> 0.064971).  Saving model ...\n",
      "[  8/500] train_loss: 0.11369 valid_loss: 0.03272\n",
      "Validation loss decreased (0.064971 --> 0.032718).  Saving model ...\n",
      "[  9/500] train_loss: 0.25691 valid_loss: 0.42016\n",
      "[ 10/500] train_loss: 0.09419 valid_loss: 0.04500\n",
      "[ 11/500] train_loss: 0.08912 valid_loss: 0.08853\n",
      "[ 12/500] train_loss: 0.07895 valid_loss: 0.12312\n",
      "[ 13/500] train_loss: 0.20737 valid_loss: 0.07796\n",
      "[ 14/500] train_loss: 0.43288 valid_loss: 0.02440\n",
      "Validation loss decreased (0.032718 --> 0.024397).  Saving model ...\n",
      "[ 15/500] train_loss: 0.17657 valid_loss: 0.04160\n",
      "[ 16/500] train_loss: 0.26442 valid_loss: 0.04524\n",
      "[ 17/500] train_loss: 0.14318 valid_loss: 0.03615\n",
      "[ 18/500] train_loss: 0.19613 valid_loss: 0.02601\n",
      "[ 19/500] train_loss: 0.13149 valid_loss: 0.02630\n",
      "[ 20/500] train_loss: 0.15520 valid_loss: 0.02763\n",
      "[ 21/500] train_loss: 0.11893 valid_loss: 0.02369\n",
      "Validation loss decreased (0.024397 --> 0.023695).  Saving model ...\n",
      "[ 22/500] train_loss: 0.13057 valid_loss: 0.02431\n",
      "[ 23/500] train_loss: 0.11045 valid_loss: 0.02193\n",
      "Validation loss decreased (0.023695 --> 0.021932).  Saving model ...\n",
      "[ 24/500] train_loss: 0.11057 valid_loss: 0.02432\n",
      "[ 25/500] train_loss: 0.10324 valid_loss: 0.02207\n",
      "[ 26/500] train_loss: 0.09540 valid_loss: 0.02320\n",
      "[ 27/500] train_loss: 0.09678 valid_loss: 0.02165\n",
      "Validation loss decreased (0.021932 --> 0.021645).  Saving model ...\n",
      "[ 28/500] train_loss: 0.08329 valid_loss: 0.02121\n",
      "Validation loss decreased (0.021645 --> 0.021211).  Saving model ...\n",
      "[ 29/500] train_loss: 0.09065 valid_loss: 0.02065\n",
      "Validation loss decreased (0.021211 --> 0.020653).  Saving model ...\n",
      "[ 30/500] train_loss: 0.07368 valid_loss: 0.01938\n",
      "Validation loss decreased (0.020653 --> 0.019379).  Saving model ...\n",
      "[ 31/500] train_loss: 0.08495 valid_loss: 0.02015\n",
      "[ 32/500] train_loss: 0.06573 valid_loss: 0.01791\n",
      "Validation loss decreased (0.019379 --> 0.017906).  Saving model ...\n",
      "[ 33/500] train_loss: 0.07978 valid_loss: 0.01899\n",
      "[ 34/500] train_loss: 0.05899 valid_loss: 0.01680\n",
      "Validation loss decreased (0.017906 --> 0.016796).  Saving model ...\n",
      "[ 35/500] train_loss: 0.07491 valid_loss: 0.01898\n",
      "[ 36/500] train_loss: 0.05375 valid_loss: 0.01472\n",
      "Validation loss decreased (0.016796 --> 0.014718).  Saving model ...\n",
      "[ 37/500] train_loss: 0.07005 valid_loss: 0.01662\n",
      "[ 38/500] train_loss: 0.04875 valid_loss: 0.01458\n",
      "Validation loss decreased (0.014718 --> 0.014581).  Saving model ...\n",
      "[ 39/500] train_loss: 0.06586 valid_loss: 0.01752\n",
      "[ 40/500] train_loss: 0.04515 valid_loss: 0.01226\n",
      "Validation loss decreased (0.014581 --> 0.012265).  Saving model ...\n",
      "[ 41/500] train_loss: 0.06139 valid_loss: 0.01448\n",
      "[ 42/500] train_loss: 0.04157 valid_loss: 0.01338\n",
      "[ 43/500] train_loss: 0.05758 valid_loss: 0.01602\n",
      "[ 44/500] train_loss: 0.03901 valid_loss: 0.01076\n",
      "Validation loss decreased (0.012265 --> 0.010760).  Saving model ...\n",
      "[ 45/500] train_loss: 0.05388 valid_loss: 0.01320\n",
      "[ 46/500] train_loss: 0.03601 valid_loss: 0.01227\n",
      "[ 47/500] train_loss: 0.05089 valid_loss: 0.01501\n",
      "[ 48/500] train_loss: 0.03429 valid_loss: 0.00945\n",
      "Validation loss decreased (0.010760 --> 0.009447).  Saving model ...\n",
      "[ 49/500] train_loss: 0.04784 valid_loss: 0.01155\n",
      "[ 50/500] train_loss: 0.03169 valid_loss: 0.01263\n",
      "[ 51/500] train_loss: 0.04543 valid_loss: 0.01554\n",
      "[ 52/500] train_loss: 0.03099 valid_loss: 0.00789\n",
      "Validation loss decreased (0.009447 --> 0.007888).  Saving model ...\n",
      "[ 53/500] train_loss: 0.04247 valid_loss: 0.00928\n",
      "[ 54/500] train_loss: 0.02831 valid_loss: 0.01159\n",
      "[ 55/500] train_loss: 0.03464 valid_loss: 0.00825\n",
      "[ 56/500] train_loss: 0.03603 valid_loss: 0.00901\n",
      "[ 57/500] train_loss: 0.02731 valid_loss: 0.00801\n",
      "[ 58/500] train_loss: 0.03633 valid_loss: 0.00733\n",
      "Validation loss decreased (0.007888 --> 0.007327).  Saving model ...\n",
      "[ 59/500] train_loss: 0.02404 valid_loss: 0.00743\n",
      "[ 60/500] train_loss: 0.03388 valid_loss: 0.00784\n",
      "[ 61/500] train_loss: 0.02325 valid_loss: 0.00731\n",
      "Validation loss decreased (0.007327 --> 0.007312).  Saving model ...\n",
      "[ 62/500] train_loss: 0.03110 valid_loss: 0.00745\n",
      "[ 63/500] train_loss: 0.02296 valid_loss: 0.00711\n",
      "Validation loss decreased (0.007312 --> 0.007109).  Saving model ...\n",
      "[ 64/500] train_loss: 0.02850 valid_loss: 0.00783\n",
      "[ 65/500] train_loss: 0.02303 valid_loss: 0.00741\n",
      "[ 66/500] train_loss: 0.02619 valid_loss: 0.00767\n",
      "[ 67/500] train_loss: 0.02307 valid_loss: 0.00753\n",
      "[ 68/500] train_loss: 0.02433 valid_loss: 0.00769\n",
      "[ 69/500] train_loss: 0.02306 valid_loss: 0.00773\n",
      "[ 70/500] train_loss: 0.02285 valid_loss: 0.00749\n",
      "[ 71/500] train_loss: 0.02300 valid_loss: 0.00767\n",
      "[ 72/500] train_loss: 0.02165 valid_loss: 0.00749\n",
      "[ 73/500] train_loss: 0.02299 valid_loss: 0.00802\n",
      "[ 74/500] train_loss: 0.02095 valid_loss: 0.00707\n",
      "Validation loss decreased (0.007109 --> 0.007068).  Saving model ...\n",
      "[ 75/500] train_loss: 0.02295 valid_loss: 0.00742\n",
      "[ 76/500] train_loss: 0.02203 valid_loss: 0.00665\n",
      "Validation loss decreased (0.007068 --> 0.006647).  Saving model ...\n",
      "[ 77/500] train_loss: 0.01726 valid_loss: 0.00697\n",
      "[ 78/500] train_loss: 0.01762 valid_loss: 0.00679\n",
      "[ 79/500] train_loss: 0.01724 valid_loss: 0.00613\n",
      "Validation loss decreased (0.006647 --> 0.006126).  Saving model ...\n",
      "[ 80/500] train_loss: 0.01475 valid_loss: 0.00738\n",
      "[ 81/500] train_loss: 0.01717 valid_loss: 0.00589\n",
      "Validation loss decreased (0.006126 --> 0.005895).  Saving model ...\n",
      "[ 82/500] train_loss: 0.01449 valid_loss: 0.00843\n",
      "[ 83/500] train_loss: 0.01622 valid_loss: 0.00785\n",
      "[ 84/500] train_loss: 0.01483 valid_loss: 0.00782\n",
      "[ 85/500] train_loss: 0.01645 valid_loss: 0.00577\n",
      "Validation loss decreased (0.005895 --> 0.005771).  Saving model ...\n",
      "[ 86/500] train_loss: 0.01431 valid_loss: 0.00850\n",
      "[ 87/500] train_loss: 0.01581 valid_loss: 0.00537\n",
      "Validation loss decreased (0.005771 --> 0.005373).  Saving model ...\n",
      "[ 88/500] train_loss: 0.01271 valid_loss: 0.00616\n",
      "[ 89/500] train_loss: 0.01303 valid_loss: 0.00618\n",
      "[ 90/500] train_loss: 0.01234 valid_loss: 0.00554\n",
      "[ 91/500] train_loss: 0.01478 valid_loss: 0.00568\n",
      "[ 92/500] train_loss: 0.01278 valid_loss: 0.00653\n",
      "[ 93/500] train_loss: 0.01375 valid_loss: 0.00505\n",
      "Validation loss decreased (0.005373 --> 0.005051).  Saving model ...\n",
      "[ 94/500] train_loss: 0.01264 valid_loss: 0.00606\n",
      "[ 95/500] train_loss: 0.01275 valid_loss: 0.00516\n",
      "[ 96/500] train_loss: 0.01161 valid_loss: 0.00532\n",
      "[ 97/500] train_loss: 0.01287 valid_loss: 0.00522\n",
      "[ 98/500] train_loss: 0.01159 valid_loss: 0.00538\n",
      "[ 99/500] train_loss: 0.01247 valid_loss: 0.00501\n",
      "Validation loss decreased (0.005051 --> 0.005006).  Saving model ...\n",
      "[100/500] train_loss: 0.01113 valid_loss: 0.00569\n",
      "[101/500] train_loss: 0.01162 valid_loss: 0.00510\n",
      "[102/500] train_loss: 0.01097 valid_loss: 0.00519\n",
      "[103/500] train_loss: 0.01219 valid_loss: 0.00502\n",
      "[104/500] train_loss: 0.01083 valid_loss: 0.00540\n",
      "[105/500] train_loss: 0.01144 valid_loss: 0.00499\n",
      "Validation loss decreased (0.005006 --> 0.004990).  Saving model ...\n",
      "[106/500] train_loss: 0.01058 valid_loss: 0.00532\n",
      "[107/500] train_loss: 0.01156 valid_loss: 0.00498\n",
      "Validation loss decreased (0.004990 --> 0.004979).  Saving model ...\n",
      "[108/500] train_loss: 0.01053 valid_loss: 0.00569\n",
      "[109/500] train_loss: 0.01033 valid_loss: 0.00540\n",
      "[110/500] train_loss: 0.01040 valid_loss: 0.00500\n",
      "[111/500] train_loss: 0.01101 valid_loss: 0.00482\n",
      "Validation loss decreased (0.004979 --> 0.004816).  Saving model ...\n",
      "[112/500] train_loss: 0.01020 valid_loss: 0.00568\n",
      "[113/500] train_loss: 0.01008 valid_loss: 0.00512\n",
      "[114/500] train_loss: 0.01012 valid_loss: 0.00486\n",
      "[115/500] train_loss: 0.01070 valid_loss: 0.00492\n",
      "[116/500] train_loss: 0.01002 valid_loss: 0.00524\n",
      "[117/500] train_loss: 0.01010 valid_loss: 0.00510\n",
      "[118/500] train_loss: 0.00996 valid_loss: 0.00519\n",
      "[119/500] train_loss: 0.01012 valid_loss: 0.00483\n",
      "[120/500] train_loss: 0.00977 valid_loss: 0.00548\n",
      "[121/500] train_loss: 0.00965 valid_loss: 0.00495\n",
      "[122/500] train_loss: 0.00966 valid_loss: 0.00489\n",
      "[123/500] train_loss: 0.00968 valid_loss: 0.00543\n",
      "[124/500] train_loss: 0.00966 valid_loss: 0.00509\n",
      "[125/500] train_loss: 0.00970 valid_loss: 0.00478\n",
      "Validation loss decreased (0.004816 --> 0.004785).  Saving model ...\n",
      "[126/500] train_loss: 0.00952 valid_loss: 0.00525\n",
      "[127/500] train_loss: 0.00945 valid_loss: 0.00505\n",
      "[128/500] train_loss: 0.00955 valid_loss: 0.00498\n",
      "[129/500] train_loss: 0.00967 valid_loss: 0.00495\n",
      "[130/500] train_loss: 0.00940 valid_loss: 0.00496\n",
      "[131/500] train_loss: 0.00941 valid_loss: 0.00514\n",
      "[132/500] train_loss: 0.00931 valid_loss: 0.00491\n",
      "[133/500] train_loss: 0.00941 valid_loss: 0.00492\n",
      "[134/500] train_loss: 0.00923 valid_loss: 0.00528\n",
      "[135/500] train_loss: 0.00923 valid_loss: 0.00484\n",
      "[136/500] train_loss: 0.00920 valid_loss: 0.00502\n",
      "[137/500] train_loss: 0.00915 valid_loss: 0.00494\n",
      "[138/500] train_loss: 0.00917 valid_loss: 0.00501\n",
      "[139/500] train_loss: 0.00915 valid_loss: 0.00499\n",
      "[140/500] train_loss: 0.00916 valid_loss: 0.00508\n",
      "[141/500] train_loss: 0.00912 valid_loss: 0.00497\n",
      "[142/500] train_loss: 0.00905 valid_loss: 0.00495\n",
      "[143/500] train_loss: 0.00907 valid_loss: 0.00501\n",
      "[144/500] train_loss: 0.00905 valid_loss: 0.00498\n",
      "[145/500] train_loss: 0.00901 valid_loss: 0.00496\n",
      "[146/500] train_loss: 0.00900 valid_loss: 0.00494\n",
      "[147/500] train_loss: 0.00896 valid_loss: 0.00499\n",
      "[148/500] train_loss: 0.00897 valid_loss: 0.00497\n",
      "[149/500] train_loss: 0.00895 valid_loss: 0.00499\n",
      "[150/500] train_loss: 0.00893 valid_loss: 0.00490\n",
      "[151/500] train_loss: 0.00891 valid_loss: 0.00503\n",
      "[152/500] train_loss: 0.00885 valid_loss: 0.00491\n",
      "[153/500] train_loss: 0.00885 valid_loss: 0.00501\n",
      "[154/500] train_loss: 0.00881 valid_loss: 0.00487\n",
      "[155/500] train_loss: 0.00885 valid_loss: 0.00503\n",
      "[156/500] train_loss: 0.00880 valid_loss: 0.00482\n",
      "[157/500] train_loss: 0.00881 valid_loss: 0.00507\n",
      "[158/500] train_loss: 0.00877 valid_loss: 0.00486\n",
      "[159/500] train_loss: 0.00877 valid_loss: 0.00504\n",
      "[160/500] train_loss: 0.00878 valid_loss: 0.00486\n",
      "[161/500] train_loss: 0.00874 valid_loss: 0.00505\n",
      "[162/500] train_loss: 0.00872 valid_loss: 0.00488\n",
      "[163/500] train_loss: 0.00871 valid_loss: 0.00498\n",
      "[164/500] train_loss: 0.00872 valid_loss: 0.00486\n",
      "[165/500] train_loss: 0.00869 valid_loss: 0.00502\n",
      "[166/500] train_loss: 0.00868 valid_loss: 0.00489\n",
      "[167/500] train_loss: 0.00869 valid_loss: 0.00501\n",
      "[168/500] train_loss: 0.00862 valid_loss: 0.00490\n",
      "[169/500] train_loss: 0.00865 valid_loss: 0.00496\n",
      "[170/500] train_loss: 0.00860 valid_loss: 0.00485\n",
      "[171/500] train_loss: 0.00863 valid_loss: 0.00498\n",
      "[172/500] train_loss: 0.00862 valid_loss: 0.00487\n",
      "[173/500] train_loss: 0.00861 valid_loss: 0.00495\n",
      "[174/500] train_loss: 0.00861 valid_loss: 0.00491\n",
      "[175/500] train_loss: 0.00860 valid_loss: 0.00491\n",
      "Early stopping\n",
      "[  1/500] train_loss: 7.03627 valid_loss: 4.03325\n",
      "Validation loss decreased (inf --> 4.033247).  Saving model ...\n",
      "[  2/500] train_loss: 1.54778 valid_loss: 0.06783\n",
      "Validation loss decreased (4.033247 --> 0.067835).  Saving model ...\n",
      "[  3/500] train_loss: 4.14610 valid_loss: 2.98048\n",
      "[  4/500] train_loss: 0.50118 valid_loss: 0.11744\n",
      "[  5/500] train_loss: 0.43014 valid_loss: 0.10321\n",
      "[  6/500] train_loss: 0.47693 valid_loss: 1.03795\n",
      "[  7/500] train_loss: 0.18149 valid_loss: 0.13809\n",
      "[  8/500] train_loss: 0.17605 valid_loss: 0.11459\n",
      "[  9/500] train_loss: 0.14220 valid_loss: 0.07996\n",
      "[ 10/500] train_loss: 0.32909 valid_loss: 0.13679\n",
      "[ 11/500] train_loss: 1.12228 valid_loss: 0.07612\n",
      "[ 12/500] train_loss: 0.64067 valid_loss: 0.06497\n",
      "Validation loss decreased (0.067835 --> 0.064974).  Saving model ...\n",
      "[ 13/500] train_loss: 0.15421 valid_loss: 0.14749\n",
      "[ 14/500] train_loss: 0.07200 valid_loss: 0.41498\n",
      "[ 15/500] train_loss: 0.09688 valid_loss: 0.06288\n",
      "Validation loss decreased (0.064974 --> 0.062880).  Saving model ...\n",
      "[ 16/500] train_loss: 0.06844 valid_loss: 0.19135\n",
      "[ 17/500] train_loss: 0.18175 valid_loss: 0.01728\n",
      "Validation loss decreased (0.062880 --> 0.017278).  Saving model ...\n",
      "[ 18/500] train_loss: 0.17821 valid_loss: 0.14383\n",
      "[ 19/500] train_loss: 0.13922 valid_loss: 0.09264\n",
      "[ 20/500] train_loss: 0.04073 valid_loss: 0.01798\n",
      "[ 21/500] train_loss: 0.09164 valid_loss: 0.14200\n",
      "[ 22/500] train_loss: 0.18751 valid_loss: 0.04864\n",
      "[ 23/500] train_loss: 0.07318 valid_loss: 0.16939\n",
      "[ 24/500] train_loss: 0.07282 valid_loss: 0.02061\n",
      "[ 25/500] train_loss: 0.03392 valid_loss: 0.01593\n",
      "Validation loss decreased (0.017278 --> 0.015929).  Saving model ...\n",
      "[ 26/500] train_loss: 0.05932 valid_loss: 0.02150\n",
      "[ 27/500] train_loss: 0.03722 valid_loss: 0.03995\n",
      "[ 28/500] train_loss: 0.03636 valid_loss: 0.00963\n",
      "Validation loss decreased (0.015929 --> 0.009625).  Saving model ...\n",
      "[ 29/500] train_loss: 0.05107 valid_loss: 0.01416\n",
      "[ 30/500] train_loss: 0.02356 valid_loss: 0.01885\n",
      "[ 31/500] train_loss: 0.06597 valid_loss: 0.09375\n",
      "[ 32/500] train_loss: 0.06002 valid_loss: 0.02573\n",
      "[ 33/500] train_loss: 0.04225 valid_loss: 0.09746\n",
      "[ 34/500] train_loss: 0.06257 valid_loss: 0.03937\n",
      "[ 35/500] train_loss: 0.13909 valid_loss: 0.04820\n",
      "[ 36/500] train_loss: 0.04516 valid_loss: 0.02166\n",
      "[ 37/500] train_loss: 0.06073 valid_loss: 0.01283\n",
      "[ 38/500] train_loss: 0.03552 valid_loss: 0.02398\n",
      "[ 39/500] train_loss: 0.06260 valid_loss: 0.00935\n",
      "Validation loss decreased (0.009625 --> 0.009353).  Saving model ...\n",
      "[ 40/500] train_loss: 0.04115 valid_loss: 0.01545\n",
      "[ 41/500] train_loss: 0.02437 valid_loss: 0.02406\n",
      "[ 42/500] train_loss: 0.03405 valid_loss: 0.01560\n",
      "[ 43/500] train_loss: 0.04456 valid_loss: 0.00697\n",
      "Validation loss decreased (0.009353 --> 0.006973).  Saving model ...\n",
      "[ 44/500] train_loss: 0.03563 valid_loss: 0.00798\n",
      "[ 45/500] train_loss: 0.02600 valid_loss: 0.01096\n",
      "[ 46/500] train_loss: 0.03868 valid_loss: 0.02064\n",
      "[ 47/500] train_loss: 0.05031 valid_loss: 0.02624\n",
      "[ 48/500] train_loss: 0.02791 valid_loss: 0.02038\n",
      "[ 49/500] train_loss: 0.03091 valid_loss: 0.01151\n",
      "[ 50/500] train_loss: 0.02181 valid_loss: 0.01031\n",
      "[ 51/500] train_loss: 0.01969 valid_loss: 0.00607\n",
      "Validation loss decreased (0.006973 --> 0.006070).  Saving model ...\n",
      "[ 52/500] train_loss: 0.03175 valid_loss: 0.02197\n",
      "[ 53/500] train_loss: 0.02051 valid_loss: 0.00596\n",
      "Validation loss decreased (0.006070 --> 0.005958).  Saving model ...\n",
      "[ 54/500] train_loss: 0.01527 valid_loss: 0.00751\n",
      "[ 55/500] train_loss: 0.01562 valid_loss: 0.00881\n",
      "[ 56/500] train_loss: 0.01658 valid_loss: 0.00980\n",
      "[ 57/500] train_loss: 0.01564 valid_loss: 0.02552\n",
      "[ 58/500] train_loss: 0.01806 valid_loss: 0.00650\n",
      "[ 59/500] train_loss: 0.01419 valid_loss: 0.00594\n",
      "Validation loss decreased (0.005958 --> 0.005940).  Saving model ...\n",
      "[ 60/500] train_loss: 0.01856 valid_loss: 0.00786\n",
      "[ 61/500] train_loss: 0.01691 valid_loss: 0.00954\n",
      "[ 62/500] train_loss: 0.02112 valid_loss: 0.01006\n",
      "[ 63/500] train_loss: 0.06126 valid_loss: 0.00752\n",
      "[ 64/500] train_loss: 0.02750 valid_loss: 0.02804\n",
      "[ 65/500] train_loss: 0.03207 valid_loss: 0.01164\n",
      "[ 66/500] train_loss: 0.02036 valid_loss: 0.01354\n",
      "[ 67/500] train_loss: 0.02093 valid_loss: 0.00614\n",
      "[ 68/500] train_loss: 0.01551 valid_loss: 0.00837\n",
      "[ 69/500] train_loss: 0.01421 valid_loss: 0.00567\n",
      "Validation loss decreased (0.005940 --> 0.005670).  Saving model ...\n",
      "[ 70/500] train_loss: 0.01575 valid_loss: 0.00584\n",
      "[ 71/500] train_loss: 0.01382 valid_loss: 0.00525\n",
      "Validation loss decreased (0.005670 --> 0.005245).  Saving model ...\n",
      "[ 72/500] train_loss: 0.01668 valid_loss: 0.01047\n",
      "[ 73/500] train_loss: 0.01506 valid_loss: 0.00545\n",
      "[ 74/500] train_loss: 0.01528 valid_loss: 0.00702\n",
      "[ 75/500] train_loss: 0.01366 valid_loss: 0.00519\n",
      "Validation loss decreased (0.005245 --> 0.005193).  Saving model ...\n",
      "[ 76/500] train_loss: 0.01798 valid_loss: 0.01445\n",
      "[ 77/500] train_loss: 0.01285 valid_loss: 0.00617\n",
      "[ 78/500] train_loss: 0.01424 valid_loss: 0.00787\n",
      "[ 79/500] train_loss: 0.01147 valid_loss: 0.00515\n",
      "Validation loss decreased (0.005193 --> 0.005152).  Saving model ...\n",
      "[ 80/500] train_loss: 0.01305 valid_loss: 0.00808\n",
      "[ 81/500] train_loss: 0.01173 valid_loss: 0.00474\n",
      "Validation loss decreased (0.005152 --> 0.004740).  Saving model ...\n",
      "[ 82/500] train_loss: 0.01310 valid_loss: 0.00543\n",
      "[ 83/500] train_loss: 0.01123 valid_loss: 0.00495\n",
      "[ 84/500] train_loss: 0.01186 valid_loss: 0.00814\n",
      "[ 85/500] train_loss: 0.01395 valid_loss: 0.00507\n",
      "[ 86/500] train_loss: 0.01380 valid_loss: 0.01572\n",
      "[ 87/500] train_loss: 0.01238 valid_loss: 0.00527\n",
      "[ 88/500] train_loss: 0.01568 valid_loss: 0.00820\n",
      "[ 89/500] train_loss: 0.01183 valid_loss: 0.00434\n",
      "Validation loss decreased (0.004740 --> 0.004341).  Saving model ...\n",
      "[ 90/500] train_loss: 0.01132 valid_loss: 0.00757\n",
      "[ 91/500] train_loss: 0.01013 valid_loss: 0.00576\n",
      "[ 92/500] train_loss: 0.01102 valid_loss: 0.00856\n",
      "[ 93/500] train_loss: 0.01007 valid_loss: 0.00509\n",
      "[ 94/500] train_loss: 0.01032 valid_loss: 0.00816\n",
      "[ 95/500] train_loss: 0.01009 valid_loss: 0.00634\n",
      "[ 96/500] train_loss: 0.01005 valid_loss: 0.00893\n",
      "[ 97/500] train_loss: 0.00987 valid_loss: 0.00565\n",
      "[ 98/500] train_loss: 0.00986 valid_loss: 0.00753\n",
      "[ 99/500] train_loss: 0.00986 valid_loss: 0.00517\n",
      "[100/500] train_loss: 0.00971 valid_loss: 0.00793\n",
      "[101/500] train_loss: 0.00994 valid_loss: 0.00789\n",
      "[102/500] train_loss: 0.00969 valid_loss: 0.00662\n",
      "[103/500] train_loss: 0.00976 valid_loss: 0.00475\n",
      "[104/500] train_loss: 0.00955 valid_loss: 0.00738\n",
      "[105/500] train_loss: 0.01061 valid_loss: 0.00971\n",
      "[106/500] train_loss: 0.01002 valid_loss: 0.00409\n",
      "Validation loss decreased (0.004341 --> 0.004089).  Saving model ...\n",
      "[107/500] train_loss: 0.00968 valid_loss: 0.00589\n",
      "[108/500] train_loss: 0.00909 valid_loss: 0.00731\n",
      "[109/500] train_loss: 0.00947 valid_loss: 0.00809\n",
      "[110/500] train_loss: 0.00957 valid_loss: 0.00492\n",
      "[111/500] train_loss: 0.00934 valid_loss: 0.00603\n",
      "[112/500] train_loss: 0.00908 valid_loss: 0.00814\n",
      "[113/500] train_loss: 0.01010 valid_loss: 0.00558\n",
      "[114/500] train_loss: 0.01019 valid_loss: 0.00528\n",
      "[115/500] train_loss: 0.00939 valid_loss: 0.01000\n",
      "[116/500] train_loss: 0.00987 valid_loss: 0.00392\n",
      "Validation loss decreased (0.004089 --> 0.003921).  Saving model ...\n",
      "[117/500] train_loss: 0.01170 valid_loss: 0.00922\n",
      "[118/500] train_loss: 0.01008 valid_loss: 0.00397\n",
      "[119/500] train_loss: 0.00969 valid_loss: 0.00772\n",
      "[120/500] train_loss: 0.00930 valid_loss: 0.00633\n",
      "[121/500] train_loss: 0.00904 valid_loss: 0.00600\n",
      "[122/500] train_loss: 0.00900 valid_loss: 0.00879\n",
      "[123/500] train_loss: 0.00894 valid_loss: 0.00447\n",
      "[124/500] train_loss: 0.00990 valid_loss: 0.00577\n",
      "[125/500] train_loss: 0.00875 valid_loss: 0.00851\n",
      "[126/500] train_loss: 0.00869 valid_loss: 0.00625\n",
      "[127/500] train_loss: 0.00902 valid_loss: 0.00690\n",
      "[128/500] train_loss: 0.00877 valid_loss: 0.00706\n",
      "[129/500] train_loss: 0.00876 valid_loss: 0.00663\n",
      "[130/500] train_loss: 0.00860 valid_loss: 0.00832\n",
      "[131/500] train_loss: 0.00853 valid_loss: 0.00568\n",
      "[132/500] train_loss: 0.00852 valid_loss: 0.00768\n",
      "[133/500] train_loss: 0.00861 valid_loss: 0.00793\n",
      "[134/500] train_loss: 0.00845 valid_loss: 0.00602\n",
      "[135/500] train_loss: 0.00839 valid_loss: 0.00710\n",
      "[136/500] train_loss: 0.00846 valid_loss: 0.00701\n",
      "[137/500] train_loss: 0.00838 valid_loss: 0.00620\n",
      "[138/500] train_loss: 0.00845 valid_loss: 0.00750\n",
      "[139/500] train_loss: 0.00836 valid_loss: 0.00651\n",
      "[140/500] train_loss: 0.00842 valid_loss: 0.00702\n",
      "[141/500] train_loss: 0.00830 valid_loss: 0.00655\n",
      "[142/500] train_loss: 0.00829 valid_loss: 0.00696\n",
      "[143/500] train_loss: 0.00830 valid_loss: 0.00602\n",
      "[144/500] train_loss: 0.00823 valid_loss: 0.00714\n",
      "[145/500] train_loss: 0.00823 valid_loss: 0.00643\n",
      "[146/500] train_loss: 0.00819 valid_loss: 0.00685\n",
      "[147/500] train_loss: 0.00817 valid_loss: 0.00678\n",
      "[148/500] train_loss: 0.00817 valid_loss: 0.00656\n",
      "[149/500] train_loss: 0.00814 valid_loss: 0.00663\n",
      "[150/500] train_loss: 0.00817 valid_loss: 0.00665\n",
      "[151/500] train_loss: 0.00815 valid_loss: 0.00661\n",
      "[152/500] train_loss: 0.00815 valid_loss: 0.00679\n",
      "[153/500] train_loss: 0.00811 valid_loss: 0.00669\n",
      "[154/500] train_loss: 0.00813 valid_loss: 0.00683\n",
      "[155/500] train_loss: 0.00809 valid_loss: 0.00665\n",
      "[156/500] train_loss: 0.00810 valid_loss: 0.00669\n",
      "[157/500] train_loss: 0.00807 valid_loss: 0.00673\n",
      "[158/500] train_loss: 0.00806 valid_loss: 0.00656\n",
      "[159/500] train_loss: 0.00806 valid_loss: 0.00671\n",
      "[160/500] train_loss: 0.00804 valid_loss: 0.00663\n",
      "[161/500] train_loss: 0.00802 valid_loss: 0.00681\n",
      "[162/500] train_loss: 0.00803 valid_loss: 0.00654\n",
      "[163/500] train_loss: 0.00803 valid_loss: 0.00677\n",
      "[164/500] train_loss: 0.00803 valid_loss: 0.00660\n",
      "[165/500] train_loss: 0.00802 valid_loss: 0.00666\n",
      "[166/500] train_loss: 0.00797 valid_loss: 0.00659\n",
      "Early stopping\n",
      "[  1/500] train_loss: 3.59878 valid_loss: 0.28421\n",
      "Validation loss decreased (inf --> 0.284206).  Saving model ...\n",
      "[  2/500] train_loss: 4.04871 valid_loss: 4.30882\n",
      "[  3/500] train_loss: 2.25315 valid_loss: 0.16420\n",
      "Validation loss decreased (0.284206 --> 0.164196).  Saving model ...\n",
      "[  4/500] train_loss: 0.38987 valid_loss: 0.15252\n",
      "Validation loss decreased (0.164196 --> 0.152521).  Saving model ...\n",
      "[  5/500] train_loss: 0.45945 valid_loss: 1.06256\n",
      "[  6/500] train_loss: 0.17063 valid_loss: 0.11978\n",
      "Validation loss decreased (0.152521 --> 0.119783).  Saving model ...\n",
      "[  7/500] train_loss: 0.07369 valid_loss: 0.03177\n",
      "Validation loss decreased (0.119783 --> 0.031774).  Saving model ...\n",
      "[  8/500] train_loss: 0.09567 valid_loss: 0.01932\n",
      "Validation loss decreased (0.031774 --> 0.019321).  Saving model ...\n",
      "[  9/500] train_loss: 0.12437 valid_loss: 0.11709\n",
      "[ 10/500] train_loss: 0.07308 valid_loss: 0.08561\n",
      "[ 11/500] train_loss: 0.08641 valid_loss: 0.04695\n",
      "[ 12/500] train_loss: 0.09985 valid_loss: 0.01777\n",
      "Validation loss decreased (0.019321 --> 0.017774).  Saving model ...\n",
      "[ 13/500] train_loss: 0.05549 valid_loss: 0.07683\n",
      "[ 14/500] train_loss: 0.08245 valid_loss: 0.29157\n",
      "[ 15/500] train_loss: 0.08903 valid_loss: 0.11339\n",
      "[ 16/500] train_loss: 0.07422 valid_loss: 0.13376\n",
      "[ 17/500] train_loss: 0.15365 valid_loss: 0.04774\n",
      "[ 18/500] train_loss: 0.78306 valid_loss: 0.03068\n",
      "[ 19/500] train_loss: 0.07496 valid_loss: 0.01386\n",
      "Validation loss decreased (0.017774 --> 0.013859).  Saving model ...\n",
      "[ 20/500] train_loss: 0.08460 valid_loss: 0.08542\n",
      "[ 21/500] train_loss: 0.03228 valid_loss: 0.01183\n",
      "Validation loss decreased (0.013859 --> 0.011832).  Saving model ...\n",
      "[ 22/500] train_loss: 0.03885 valid_loss: 0.03924\n",
      "[ 23/500] train_loss: 0.05752 valid_loss: 0.01027\n",
      "Validation loss decreased (0.011832 --> 0.010274).  Saving model ...\n",
      "[ 24/500] train_loss: 0.05718 valid_loss: 0.02961\n",
      "[ 25/500] train_loss: 0.08015 valid_loss: 0.10389\n",
      "[ 26/500] train_loss: 0.11124 valid_loss: 0.02093\n",
      "[ 27/500] train_loss: 0.06145 valid_loss: 0.05765\n",
      "[ 28/500] train_loss: 0.04046 valid_loss: 0.03882\n",
      "[ 29/500] train_loss: 0.04550 valid_loss: 0.02060\n",
      "[ 30/500] train_loss: 0.14080 valid_loss: 0.13710\n",
      "[ 31/500] train_loss: 0.04260 valid_loss: 0.02661\n",
      "[ 32/500] train_loss: 0.03645 valid_loss: 0.01199\n",
      "[ 33/500] train_loss: 0.02707 valid_loss: 0.02938\n",
      "[ 34/500] train_loss: 0.02949 valid_loss: 0.05779\n",
      "[ 35/500] train_loss: 0.07480 valid_loss: 0.05749\n",
      "[ 36/500] train_loss: 0.15952 valid_loss: 0.01225\n",
      "[ 37/500] train_loss: 0.01692 valid_loss: 0.00717\n",
      "Validation loss decreased (0.010274 --> 0.007174).  Saving model ...\n",
      "[ 38/500] train_loss: 0.01776 valid_loss: 0.00759\n",
      "[ 39/500] train_loss: 0.01699 valid_loss: 0.01233\n",
      "[ 40/500] train_loss: 0.02174 valid_loss: 0.00607\n",
      "Validation loss decreased (0.007174 --> 0.006072).  Saving model ...\n",
      "[ 41/500] train_loss: 0.01600 valid_loss: 0.01807\n",
      "[ 42/500] train_loss: 0.02813 valid_loss: 0.03648\n",
      "[ 43/500] train_loss: 0.03623 valid_loss: 0.01710\n",
      "[ 44/500] train_loss: 0.03535 valid_loss: 0.03171\n",
      "[ 45/500] train_loss: 0.02038 valid_loss: 0.03913\n",
      "[ 46/500] train_loss: 0.01831 valid_loss: 0.01744\n",
      "[ 47/500] train_loss: 0.01922 valid_loss: 0.01868\n",
      "[ 48/500] train_loss: 0.01635 valid_loss: 0.01582\n",
      "[ 49/500] train_loss: 0.01407 valid_loss: 0.01020\n",
      "[ 50/500] train_loss: 0.01776 valid_loss: 0.00418\n",
      "Validation loss decreased (0.006072 --> 0.004177).  Saving model ...\n",
      "[ 51/500] train_loss: 0.01186 valid_loss: 0.00686\n",
      "[ 52/500] train_loss: 0.01303 valid_loss: 0.00743\n",
      "[ 53/500] train_loss: 0.01416 valid_loss: 0.00814\n",
      "[ 54/500] train_loss: 0.02925 valid_loss: 0.00865\n",
      "[ 55/500] train_loss: 0.02004 valid_loss: 0.01957\n",
      "[ 56/500] train_loss: 0.01512 valid_loss: 0.00820\n",
      "[ 57/500] train_loss: 0.02365 valid_loss: 0.01560\n",
      "[ 58/500] train_loss: 0.04366 valid_loss: 0.01028\n",
      "[ 59/500] train_loss: 0.01438 valid_loss: 0.00973\n",
      "[ 60/500] train_loss: 0.01564 valid_loss: 0.01241\n",
      "[ 61/500] train_loss: 0.01487 valid_loss: 0.00550\n",
      "[ 62/500] train_loss: 0.01216 valid_loss: 0.00672\n",
      "[ 63/500] train_loss: 0.01007 valid_loss: 0.00744\n",
      "[ 64/500] train_loss: 0.01204 valid_loss: 0.00650\n",
      "[ 65/500] train_loss: 0.01228 valid_loss: 0.00470\n",
      "[ 66/500] train_loss: 0.01345 valid_loss: 0.00460\n",
      "[ 67/500] train_loss: 0.01127 valid_loss: 0.00482\n",
      "[ 68/500] train_loss: 0.01040 valid_loss: 0.00408\n",
      "Validation loss decreased (0.004177 --> 0.004084).  Saving model ...\n",
      "[ 69/500] train_loss: 0.01219 valid_loss: 0.00387\n",
      "Validation loss decreased (0.004084 --> 0.003872).  Saving model ...\n",
      "[ 70/500] train_loss: 0.01065 valid_loss: 0.00497\n",
      "[ 71/500] train_loss: 0.01063 valid_loss: 0.00461\n",
      "[ 72/500] train_loss: 0.00952 valid_loss: 0.00448\n",
      "[ 73/500] train_loss: 0.01193 valid_loss: 0.00527\n",
      "[ 74/500] train_loss: 0.01476 valid_loss: 0.00928\n",
      "[ 75/500] train_loss: 0.01344 valid_loss: 0.00754\n",
      "[ 76/500] train_loss: 0.01505 valid_loss: 0.00480\n",
      "[ 77/500] train_loss: 0.00964 valid_loss: 0.00775\n",
      "[ 78/500] train_loss: 0.01002 valid_loss: 0.00467\n",
      "[ 79/500] train_loss: 0.01056 valid_loss: 0.00340\n",
      "Validation loss decreased (0.003872 --> 0.003399).  Saving model ...\n",
      "[ 80/500] train_loss: 0.01204 valid_loss: 0.00457\n",
      "[ 81/500] train_loss: 0.00979 valid_loss: 0.00375\n",
      "[ 82/500] train_loss: 0.00889 valid_loss: 0.00493\n",
      "[ 83/500] train_loss: 0.00894 valid_loss: 0.00416\n",
      "[ 84/500] train_loss: 0.00924 valid_loss: 0.00391\n",
      "[ 85/500] train_loss: 0.00933 valid_loss: 0.00436\n",
      "[ 86/500] train_loss: 0.00979 valid_loss: 0.00625\n",
      "[ 87/500] train_loss: 0.00965 valid_loss: 0.00345\n",
      "[ 88/500] train_loss: 0.01188 valid_loss: 0.00404\n",
      "[ 89/500] train_loss: 0.00893 valid_loss: 0.00500\n",
      "[ 90/500] train_loss: 0.00848 valid_loss: 0.00535\n",
      "[ 91/500] train_loss: 0.00859 valid_loss: 0.00541\n",
      "[ 92/500] train_loss: 0.00856 valid_loss: 0.00352\n",
      "[ 93/500] train_loss: 0.00850 valid_loss: 0.00324\n",
      "Validation loss decreased (0.003399 --> 0.003244).  Saving model ...\n",
      "[ 94/500] train_loss: 0.00891 valid_loss: 0.00441\n",
      "[ 95/500] train_loss: 0.00951 valid_loss: 0.00655\n",
      "[ 96/500] train_loss: 0.00899 valid_loss: 0.00371\n",
      "[ 97/500] train_loss: 0.00866 valid_loss: 0.00399\n",
      "[ 98/500] train_loss: 0.00862 valid_loss: 0.00355\n",
      "[ 99/500] train_loss: 0.00999 valid_loss: 0.00950\n",
      "[100/500] train_loss: 0.00822 valid_loss: 0.00325\n",
      "[101/500] train_loss: 0.00914 valid_loss: 0.00372\n",
      "[102/500] train_loss: 0.00999 valid_loss: 0.00357\n",
      "[103/500] train_loss: 0.00879 valid_loss: 0.00808\n",
      "[104/500] train_loss: 0.00784 valid_loss: 0.00317\n",
      "Validation loss decreased (0.003244 --> 0.003169).  Saving model ...\n",
      "[105/500] train_loss: 0.00798 valid_loss: 0.00304\n",
      "Validation loss decreased (0.003169 --> 0.003040).  Saving model ...\n",
      "[106/500] train_loss: 0.00855 valid_loss: 0.00334\n",
      "[107/500] train_loss: 0.00887 valid_loss: 0.00770\n",
      "[108/500] train_loss: 0.00774 valid_loss: 0.00318\n",
      "[109/500] train_loss: 0.00796 valid_loss: 0.00374\n",
      "[110/500] train_loss: 0.00810 valid_loss: 0.00330\n",
      "[111/500] train_loss: 0.00840 valid_loss: 0.00652\n",
      "[112/500] train_loss: 0.00758 valid_loss: 0.00327\n",
      "[113/500] train_loss: 0.00783 valid_loss: 0.00438\n",
      "[114/500] train_loss: 0.00762 valid_loss: 0.00356\n",
      "[115/500] train_loss: 0.00786 valid_loss: 0.00546\n",
      "[116/500] train_loss: 0.00739 valid_loss: 0.00341\n",
      "[117/500] train_loss: 0.00762 valid_loss: 0.00422\n",
      "[118/500] train_loss: 0.00740 valid_loss: 0.00378\n",
      "[119/500] train_loss: 0.00771 valid_loss: 0.00509\n",
      "[120/500] train_loss: 0.00734 valid_loss: 0.00336\n",
      "[121/500] train_loss: 0.00753 valid_loss: 0.00453\n",
      "[122/500] train_loss: 0.00732 valid_loss: 0.00373\n",
      "[123/500] train_loss: 0.00750 valid_loss: 0.00467\n",
      "[124/500] train_loss: 0.00726 valid_loss: 0.00354\n",
      "[125/500] train_loss: 0.00738 valid_loss: 0.00440\n",
      "[126/500] train_loss: 0.00724 valid_loss: 0.00362\n",
      "[127/500] train_loss: 0.00733 valid_loss: 0.00448\n",
      "[128/500] train_loss: 0.00721 valid_loss: 0.00369\n",
      "[129/500] train_loss: 0.00732 valid_loss: 0.00455\n",
      "[130/500] train_loss: 0.00714 valid_loss: 0.00359\n",
      "[131/500] train_loss: 0.00722 valid_loss: 0.00432\n",
      "[132/500] train_loss: 0.00715 valid_loss: 0.00366\n",
      "[133/500] train_loss: 0.00723 valid_loss: 0.00442\n",
      "[134/500] train_loss: 0.00712 valid_loss: 0.00371\n",
      "[135/500] train_loss: 0.00722 valid_loss: 0.00426\n",
      "[136/500] train_loss: 0.00708 valid_loss: 0.00382\n",
      "[137/500] train_loss: 0.00709 valid_loss: 0.00416\n",
      "[138/500] train_loss: 0.00709 valid_loss: 0.00353\n",
      "[139/500] train_loss: 0.00707 valid_loss: 0.00440\n",
      "[140/500] train_loss: 0.00703 valid_loss: 0.00361\n",
      "[141/500] train_loss: 0.00709 valid_loss: 0.00422\n",
      "[142/500] train_loss: 0.00703 valid_loss: 0.00380\n",
      "[143/500] train_loss: 0.00704 valid_loss: 0.00410\n",
      "[144/500] train_loss: 0.00699 valid_loss: 0.00393\n",
      "[145/500] train_loss: 0.00695 valid_loss: 0.00411\n",
      "[146/500] train_loss: 0.00695 valid_loss: 0.00388\n",
      "[147/500] train_loss: 0.00692 valid_loss: 0.00404\n",
      "[148/500] train_loss: 0.00693 valid_loss: 0.00391\n",
      "[149/500] train_loss: 0.00691 valid_loss: 0.00395\n",
      "[150/500] train_loss: 0.00692 valid_loss: 0.00396\n",
      "[151/500] train_loss: 0.00689 valid_loss: 0.00399\n",
      "[152/500] train_loss: 0.00689 valid_loss: 0.00392\n",
      "[153/500] train_loss: 0.00691 valid_loss: 0.00400\n",
      "[154/500] train_loss: 0.00688 valid_loss: 0.00392\n",
      "[155/500] train_loss: 0.00688 valid_loss: 0.00408\n",
      "Early stopping\n",
      "[  1/500] train_loss: 14.86542 valid_loss: 0.49593\n",
      "Validation loss decreased (inf --> 0.495927).  Saving model ...\n",
      "[  2/500] train_loss: 1.72545 valid_loss: 3.90045\n",
      "[  3/500] train_loss: 3.14272 valid_loss: 0.19478\n",
      "Validation loss decreased (0.495927 --> 0.194782).  Saving model ...\n",
      "[  4/500] train_loss: 0.41173 valid_loss: 1.18723\n",
      "[  5/500] train_loss: 0.33971 valid_loss: 0.08874\n",
      "Validation loss decreased (0.194782 --> 0.088739).  Saving model ...\n",
      "[  6/500] train_loss: 0.99402 valid_loss: 0.52506\n",
      "[  7/500] train_loss: 0.51521 valid_loss: 0.18171\n",
      "[  8/500] train_loss: 0.26024 valid_loss: 0.25503\n",
      "[  9/500] train_loss: 0.16642 valid_loss: 0.02106\n",
      "Validation loss decreased (0.088739 --> 0.021059).  Saving model ...\n",
      "[ 10/500] train_loss: 0.09701 valid_loss: 0.05942\n",
      "[ 11/500] train_loss: 0.25848 valid_loss: 0.08326\n",
      "[ 12/500] train_loss: 0.06926 valid_loss: 0.21218\n",
      "[ 13/500] train_loss: 0.07237 valid_loss: 0.07199\n",
      "[ 14/500] train_loss: 0.19288 valid_loss: 0.03634\n",
      "[ 15/500] train_loss: 0.06909 valid_loss: 0.05223\n",
      "[ 16/500] train_loss: 0.04378 valid_loss: 0.02733\n",
      "[ 17/500] train_loss: 0.12955 valid_loss: 0.17516\n",
      "[ 18/500] train_loss: 0.10003 valid_loss: 0.03821\n",
      "[ 19/500] train_loss: 0.05846 valid_loss: 0.01572\n",
      "Validation loss decreased (0.021059 --> 0.015718).  Saving model ...\n",
      "[ 20/500] train_loss: 0.06387 valid_loss: 0.27800\n",
      "[ 21/500] train_loss: 0.10619 valid_loss: 0.01889\n",
      "[ 22/500] train_loss: 0.10914 valid_loss: 0.02655\n",
      "[ 23/500] train_loss: 0.04973 valid_loss: 0.01155\n",
      "Validation loss decreased (0.015718 --> 0.011551).  Saving model ...\n",
      "[ 24/500] train_loss: 0.06518 valid_loss: 0.02675\n",
      "[ 25/500] train_loss: 0.29103 valid_loss: 0.01161\n",
      "[ 26/500] train_loss: 0.06667 valid_loss: 0.01347\n",
      "[ 27/500] train_loss: 0.08303 valid_loss: 0.02216\n",
      "[ 28/500] train_loss: 0.03735 valid_loss: 0.02097\n",
      "[ 29/500] train_loss: 0.06963 valid_loss: 0.07701\n",
      "[ 30/500] train_loss: 0.12776 valid_loss: 0.01150\n",
      "Validation loss decreased (0.011551 --> 0.011496).  Saving model ...\n",
      "[ 31/500] train_loss: 0.03317 valid_loss: 0.01684\n",
      "[ 32/500] train_loss: 0.03215 valid_loss: 0.01588\n",
      "[ 33/500] train_loss: 0.03551 valid_loss: 0.00879\n",
      "Validation loss decreased (0.011496 --> 0.008788).  Saving model ...\n",
      "[ 34/500] train_loss: 0.02770 valid_loss: 0.00783\n",
      "Validation loss decreased (0.008788 --> 0.007832).  Saving model ...\n",
      "[ 35/500] train_loss: 0.02029 valid_loss: 0.02650\n",
      "[ 36/500] train_loss: 0.04374 valid_loss: 0.03280\n",
      "[ 37/500] train_loss: 0.06508 valid_loss: 0.01601\n",
      "[ 38/500] train_loss: 0.05717 valid_loss: 0.03227\n",
      "[ 39/500] train_loss: 0.05035 valid_loss: 0.03381\n",
      "[ 40/500] train_loss: 0.06062 valid_loss: 0.00784\n",
      "[ 41/500] train_loss: 0.02845 valid_loss: 0.02045\n",
      "[ 42/500] train_loss: 0.06242 valid_loss: 0.00774\n",
      "Validation loss decreased (0.007832 --> 0.007738).  Saving model ...\n",
      "[ 43/500] train_loss: 0.03016 valid_loss: 0.01114\n",
      "[ 44/500] train_loss: 0.02650 valid_loss: 0.01089\n",
      "[ 45/500] train_loss: 0.06240 valid_loss: 0.01050\n",
      "[ 46/500] train_loss: 0.01775 valid_loss: 0.00687\n",
      "Validation loss decreased (0.007738 --> 0.006865).  Saving model ...\n",
      "[ 47/500] train_loss: 0.01994 valid_loss: 0.00725\n",
      "[ 48/500] train_loss: 0.01815 valid_loss: 0.00688\n",
      "[ 49/500] train_loss: 0.01573 valid_loss: 0.00740\n",
      "[ 50/500] train_loss: 0.01855 valid_loss: 0.01093\n",
      "[ 51/500] train_loss: 0.01662 valid_loss: 0.01074\n",
      "[ 52/500] train_loss: 0.01514 valid_loss: 0.00649\n",
      "Validation loss decreased (0.006865 --> 0.006489).  Saving model ...\n",
      "[ 53/500] train_loss: 0.01587 valid_loss: 0.01265\n",
      "[ 54/500] train_loss: 0.01814 valid_loss: 0.00614\n",
      "Validation loss decreased (0.006489 --> 0.006140).  Saving model ...\n",
      "[ 55/500] train_loss: 0.01748 valid_loss: 0.00685\n",
      "[ 56/500] train_loss: 0.01430 valid_loss: 0.00942\n",
      "[ 57/500] train_loss: 0.01517 valid_loss: 0.00749\n",
      "[ 58/500] train_loss: 0.01338 valid_loss: 0.00574\n",
      "Validation loss decreased (0.006140 --> 0.005735).  Saving model ...\n",
      "[ 59/500] train_loss: 0.01590 valid_loss: 0.00567\n",
      "Validation loss decreased (0.005735 --> 0.005669).  Saving model ...\n",
      "[ 60/500] train_loss: 0.01323 valid_loss: 0.00568\n",
      "[ 61/500] train_loss: 0.01380 valid_loss: 0.00646\n",
      "[ 62/500] train_loss: 0.01235 valid_loss: 0.00692\n",
      "[ 63/500] train_loss: 0.01285 valid_loss: 0.00894\n",
      "[ 64/500] train_loss: 0.01410 valid_loss: 0.00513\n",
      "Validation loss decreased (0.005669 --> 0.005133).  Saving model ...\n",
      "[ 65/500] train_loss: 0.01680 valid_loss: 0.00698\n",
      "[ 66/500] train_loss: 0.01347 valid_loss: 0.00856\n",
      "[ 67/500] train_loss: 0.01205 valid_loss: 0.00706\n",
      "[ 68/500] train_loss: 0.01540 valid_loss: 0.00518\n",
      "[ 69/500] train_loss: 0.02695 valid_loss: 0.00649\n",
      "[ 70/500] train_loss: 0.01393 valid_loss: 0.00641\n",
      "[ 71/500] train_loss: 0.01287 valid_loss: 0.00596\n",
      "[ 72/500] train_loss: 0.01186 valid_loss: 0.00949\n",
      "[ 73/500] train_loss: 0.01122 valid_loss: 0.00770\n",
      "[ 74/500] train_loss: 0.01493 valid_loss: 0.00596\n",
      "[ 75/500] train_loss: 0.02090 valid_loss: 0.00750\n",
      "[ 76/500] train_loss: 0.01369 valid_loss: 0.00767\n",
      "[ 77/500] train_loss: 0.01193 valid_loss: 0.00572\n",
      "[ 78/500] train_loss: 0.01087 valid_loss: 0.00767\n",
      "[ 79/500] train_loss: 0.01035 valid_loss: 0.00772\n",
      "[ 80/500] train_loss: 0.01093 valid_loss: 0.00582\n",
      "[ 81/500] train_loss: 0.01105 valid_loss: 0.00540\n",
      "[ 82/500] train_loss: 0.01112 valid_loss: 0.00526\n",
      "[ 83/500] train_loss: 0.01088 valid_loss: 0.00635\n",
      "[ 84/500] train_loss: 0.01221 valid_loss: 0.00665\n",
      "[ 85/500] train_loss: 0.01255 valid_loss: 0.00610\n",
      "[ 86/500] train_loss: 0.01115 valid_loss: 0.00685\n",
      "[ 87/500] train_loss: 0.01022 valid_loss: 0.00528\n",
      "[ 88/500] train_loss: 0.01327 valid_loss: 0.00572\n",
      "[ 89/500] train_loss: 0.01031 valid_loss: 0.00590\n",
      "[ 90/500] train_loss: 0.00986 valid_loss: 0.00620\n",
      "[ 91/500] train_loss: 0.00976 valid_loss: 0.00519\n",
      "[ 92/500] train_loss: 0.01009 valid_loss: 0.00627\n",
      "[ 93/500] train_loss: 0.01018 valid_loss: 0.00554\n",
      "[ 94/500] train_loss: 0.01050 valid_loss: 0.00530\n",
      "[ 95/500] train_loss: 0.01012 valid_loss: 0.00599\n",
      "[ 96/500] train_loss: 0.00935 valid_loss: 0.00494\n",
      "Validation loss decreased (0.005133 --> 0.004936).  Saving model ...\n",
      "[ 97/500] train_loss: 0.00981 valid_loss: 0.00517\n",
      "[ 98/500] train_loss: 0.00955 valid_loss: 0.00530\n",
      "[ 99/500] train_loss: 0.01066 valid_loss: 0.00669\n",
      "[100/500] train_loss: 0.00995 valid_loss: 0.00490\n",
      "Validation loss decreased (0.004936 --> 0.004896).  Saving model ...\n",
      "[101/500] train_loss: 0.01023 valid_loss: 0.00766\n",
      "[102/500] train_loss: 0.00911 valid_loss: 0.00477\n",
      "Validation loss decreased (0.004896 --> 0.004767).  Saving model ...\n",
      "[103/500] train_loss: 0.00922 valid_loss: 0.00475\n",
      "Validation loss decreased (0.004767 --> 0.004754).  Saving model ...\n",
      "[104/500] train_loss: 0.00957 valid_loss: 0.00565\n",
      "[105/500] train_loss: 0.00892 valid_loss: 0.00508\n",
      "[106/500] train_loss: 0.00962 valid_loss: 0.00464\n",
      "Validation loss decreased (0.004754 --> 0.004644).  Saving model ...\n",
      "[107/500] train_loss: 0.00887 valid_loss: 0.00507\n",
      "[108/500] train_loss: 0.00885 valid_loss: 0.00553\n",
      "[109/500] train_loss: 0.00895 valid_loss: 0.00483\n",
      "[110/500] train_loss: 0.00899 valid_loss: 0.00473\n",
      "[111/500] train_loss: 0.00923 valid_loss: 0.00720\n",
      "[112/500] train_loss: 0.00900 valid_loss: 0.00466\n",
      "[113/500] train_loss: 0.01076 valid_loss: 0.00488\n",
      "[114/500] train_loss: 0.00890 valid_loss: 0.00562\n",
      "[115/500] train_loss: 0.00879 valid_loss: 0.00459\n",
      "Validation loss decreased (0.004644 --> 0.004587).  Saving model ...\n",
      "[116/500] train_loss: 0.00988 valid_loss: 0.00621\n",
      "[117/500] train_loss: 0.01023 valid_loss: 0.00457\n",
      "Validation loss decreased (0.004587 --> 0.004572).  Saving model ...\n",
      "[118/500] train_loss: 0.00907 valid_loss: 0.00636\n",
      "[119/500] train_loss: 0.00889 valid_loss: 0.00473\n",
      "[120/500] train_loss: 0.00886 valid_loss: 0.00519\n",
      "[121/500] train_loss: 0.00857 valid_loss: 0.00573\n",
      "[122/500] train_loss: 0.00875 valid_loss: 0.00450\n",
      "Validation loss decreased (0.004572 --> 0.004502).  Saving model ...\n",
      "[123/500] train_loss: 0.00867 valid_loss: 0.00598\n",
      "[124/500] train_loss: 0.00916 valid_loss: 0.00476\n",
      "[125/500] train_loss: 0.00860 valid_loss: 0.00584\n",
      "[126/500] train_loss: 0.00846 valid_loss: 0.00527\n",
      "[127/500] train_loss: 0.00845 valid_loss: 0.00490\n",
      "[128/500] train_loss: 0.00838 valid_loss: 0.00565\n",
      "[129/500] train_loss: 0.00846 valid_loss: 0.00466\n",
      "[130/500] train_loss: 0.00883 valid_loss: 0.00547\n",
      "[131/500] train_loss: 0.00839 valid_loss: 0.00469\n",
      "[132/500] train_loss: 0.00847 valid_loss: 0.00559\n",
      "[133/500] train_loss: 0.00817 valid_loss: 0.00511\n",
      "[134/500] train_loss: 0.00819 valid_loss: 0.00515\n",
      "[135/500] train_loss: 0.00814 valid_loss: 0.00546\n",
      "[136/500] train_loss: 0.00814 valid_loss: 0.00515\n",
      "[137/500] train_loss: 0.00817 valid_loss: 0.00515\n",
      "[138/500] train_loss: 0.00819 valid_loss: 0.00541\n",
      "[139/500] train_loss: 0.00813 valid_loss: 0.00536\n",
      "[140/500] train_loss: 0.00812 valid_loss: 0.00524\n",
      "[141/500] train_loss: 0.00812 valid_loss: 0.00522\n",
      "[142/500] train_loss: 0.00802 valid_loss: 0.00535\n",
      "[143/500] train_loss: 0.00802 valid_loss: 0.00522\n",
      "[144/500] train_loss: 0.00800 valid_loss: 0.00518\n",
      "[145/500] train_loss: 0.00802 valid_loss: 0.00539\n",
      "[146/500] train_loss: 0.00797 valid_loss: 0.00515\n",
      "[147/500] train_loss: 0.00803 valid_loss: 0.00542\n",
      "[148/500] train_loss: 0.00798 valid_loss: 0.00519\n",
      "[149/500] train_loss: 0.00796 valid_loss: 0.00531\n",
      "[150/500] train_loss: 0.00796 valid_loss: 0.00531\n",
      "[151/500] train_loss: 0.00788 valid_loss: 0.00520\n",
      "[152/500] train_loss: 0.00789 valid_loss: 0.00535\n",
      "[153/500] train_loss: 0.00786 valid_loss: 0.00520\n",
      "[154/500] train_loss: 0.00789 valid_loss: 0.00534\n",
      "[155/500] train_loss: 0.00788 valid_loss: 0.00522\n",
      "[156/500] train_loss: 0.00788 valid_loss: 0.00528\n",
      "[157/500] train_loss: 0.00784 valid_loss: 0.00524\n",
      "[158/500] train_loss: 0.00784 valid_loss: 0.00527\n",
      "[159/500] train_loss: 0.00786 valid_loss: 0.00529\n",
      "[160/500] train_loss: 0.00780 valid_loss: 0.00524\n",
      "[161/500] train_loss: 0.00781 valid_loss: 0.00530\n",
      "[162/500] train_loss: 0.00780 valid_loss: 0.00524\n",
      "[163/500] train_loss: 0.00780 valid_loss: 0.00531\n",
      "[164/500] train_loss: 0.00781 valid_loss: 0.00525\n",
      "[165/500] train_loss: 0.00777 valid_loss: 0.00525\n",
      "[166/500] train_loss: 0.00776 valid_loss: 0.00525\n",
      "[167/500] train_loss: 0.00776 valid_loss: 0.00530\n",
      "[168/500] train_loss: 0.00777 valid_loss: 0.00533\n",
      "[169/500] train_loss: 0.00773 valid_loss: 0.00519\n",
      "[170/500] train_loss: 0.00776 valid_loss: 0.00534\n",
      "[171/500] train_loss: 0.00776 valid_loss: 0.00525\n",
      "[172/500] train_loss: 0.00774 valid_loss: 0.00535\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "result = dict()\n",
    "for i in ['low_rate','high_rate','close','open','high','low']:\n",
    "    predict,truth = train_and_get(i)\n",
    "    result.update({i:predict})\n",
    "    result.update({i+'_truth':truth})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result.keys():\n",
    "    result[i] = result[i].reshape(-1)\n",
    "output = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x198ea872790>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output['low_error'] = output['low_rate'] - output['low_rate_truth']\n",
    "output['high_error'] = output['high_rate'] - output['high_rate_truth']\n",
    "pyplot.plot(output['low_error']/output['low_rate_truth'])\n",
    "pyplot.plot(output['high_error']/output['high_rate_truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('result1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00d1462882258b783cb181eb86adde5698c4f2204c9695f847918151df6a5450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
