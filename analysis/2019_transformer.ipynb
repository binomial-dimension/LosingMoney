{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# S is the source sequence length\n",
    "# T is the target sequence length\n",
    "# N is the batch size\n",
    "# E is the feature number\n",
    "\n",
    "#src = torch.rand((10, 32, 512)) # (S,N,E)\n",
    "#tgt = torch.rand((20, 32, 512)) # (T,N,E)\n",
    "#out = transformer_model(src, tgt)\n",
    "\n",
    "input_window = 150  # number of input steps\n",
    "output_window = 1  # number of prediction steps, in this model its fixed to one\n",
    "batch_size = 512\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=6000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() *\n",
    "            (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        #pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "\n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self, feature_size=300, num_layers=1, dropout=0.1):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size,\n",
    "                                                        nhead=10,\n",
    "                                                        dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer,\n",
    "                                                         num_layers=num_layers)\n",
    "        self.decoder = nn.Linear(feature_size, 1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src,\n",
    "                                          self.src_mask)  #, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(\n",
    "            mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "\n",
    "# if window is 100 and prediction step is 1\n",
    "# in -> [0..99]\n",
    "# target -> [1..100]\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L - tw):\n",
    "        train_seq = input_data[i:i + tw]\n",
    "        train_label = input_data[i + output_window:i + tw + output_window]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return torch.FloatTensor(inout_seq)\n",
    "\n",
    "\n",
    "def get_data(name):\n",
    "    # construct a littel toy dataset\n",
    "    time = np.arange(0, 400, 0.1)\n",
    "    data = pd.read_csv('../data/399300.csv')\n",
    "    amplitude = data[name].values\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    #loading weather data from a file\n",
    "    #from pandas import read_csv\n",
    "    #series = read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "\n",
    "    # looks like normalizing input values curtial for the model\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    #amplitude = scaler.fit_transform(series.to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "    amplitude = scaler.fit_transform(amplitude.reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "    sampels = int(len(amplitude)*0.9)\n",
    "    train_data = amplitude[:sampels]\n",
    "    test_data = amplitude[sampels:]\n",
    "\n",
    "    # convert our train data into a pytorch train tensor\n",
    "    #train_tensor = torch.FloatTensor(train_data).view(-1)\n",
    "    # todo: add comment..\n",
    "    train_sequence = create_inout_sequences(train_data, input_window)\n",
    "    train_sequence = train_sequence[:\n",
    "                                    -output_window]  #todo: fix hack? -> din't think this through, looks like the last n sequences are to short, so I just remove them. Hackety Hack..\n",
    "\n",
    "    #test_data = torch.FloatTensor(test_data).view(-1)\n",
    "    test_data = create_inout_sequences(test_data, input_window)\n",
    "    test_data = test_data[:-output_window]  #todo: fix hack?\n",
    "\n",
    "    return train_sequence.to(device), test_data.to(device),scaler\n",
    "\n",
    "\n",
    "def get_batch(source, i, batch_size):\n",
    "    seq_len = min(batch_size, len(source) - 1 - i)\n",
    "    data = source[i:i + seq_len]\n",
    "    input = torch.stack(\n",
    "        torch.stack([item[0] for item in data]).chunk(input_window,1))  # 1 is feature size\n",
    "    target = torch.stack(\n",
    "        torch.stack([item[1] for item in data]).chunk(input_window, 1))\n",
    "    return input, target\n",
    "\n",
    "\n",
    "def train(train_data,epoch):\n",
    "    model.train()  # Turn on the train mode \\o/\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    \n",
    "\n",
    "    for batch, i in enumerate(range(0, len(train_data) - 1, batch_size)):\n",
    "        data, targets = get_batch(train_data, i, batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.7)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = int(len(train_data) / batch_size)\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.6f} | {:5.2f} ms | '\n",
    "                  'loss {:5.5f} | ppl {:8.2f}'.format(\n",
    "                      epoch, batch,\n",
    "                      len(train_data) // batch_size,\n",
    "                      scheduler.get_lr()[0], elapsed * 1000 / log_interval,\n",
    "                      cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def plot_and_loss(eval_model, data_source, epoch):\n",
    "    eval_model.eval()\n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)\n",
    "    truth = torch.Tensor(0)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1):\n",
    "            data, target = get_batch(data_source, i, 1)\n",
    "            output = eval_model(data)\n",
    "            total_loss += criterion(output, target).item()\n",
    "            test_result = torch.cat((test_result, output[-1].view(-1).cpu()),\n",
    "                                    0)\n",
    "            truth = torch.cat((truth, target[-1].view(-1).cpu()), 0)\n",
    "\n",
    "    #test_result = test_result.cpu().numpy() -> no need to detach stuff..\n",
    "    len(test_result)\n",
    "\n",
    "    pyplot.plot(test_result, color=\"red\", label=\"prediction\")\n",
    "    pyplot.plot(truth[:len(test_result)], color=\"blue\", label=\"truth\")\n",
    "    pyplot.plot(test_result - truth, color=\"green\", label=\"error\")\n",
    "    pyplot.legend()\n",
    "    pyplot.grid(True, which='both')\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    pyplot.savefig('graph/transformer-epoch%d.png' % epoch)\n",
    "    pyplot.close()\n",
    "\n",
    "    return total_loss / i\n",
    "\n",
    "\n",
    "# predict the next n steps based on the input data\n",
    "def predict_future(eval_model, data_source, steps):\n",
    "    eval_model.eval()\n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)\n",
    "    truth = torch.Tensor(0)\n",
    "    data, _ = get_batch(data_source, 0, 1)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, steps):\n",
    "            output = eval_model(data[-input_window:])\n",
    "            data = torch.cat((data, output[-1:]))\n",
    "\n",
    "    data = data.cpu().view(-1)\n",
    "\n",
    "    # I used this plot to visualize if the model pics up any long therm structure within the data.\n",
    "    pyplot.plot(data, color=\"red\")\n",
    "    pyplot.plot(data[:input_window], color=\"blue\")\n",
    "    pyplot.grid(True, which='both')\n",
    "    pyplot.axhline(y=0, color='k')\n",
    "    pyplot.savefig('graph/transformer-future%d.png' % steps)\n",
    "    pyplot.close()\n",
    "\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval()  # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    eval_batch_size = 1000\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1, eval_batch_size):\n",
    "            data, targets = get_batch(data_source, i, eval_batch_size)\n",
    "            output = eval_model(data)\n",
    "            total_loss += len(data[0]) * criterion(output,\n",
    "                                                   targets).cpu().item()\n",
    "    return total_loss / len(data_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_get(name):\n",
    "    input_window = 120  # number of input steps\n",
    "    output_window = 1  # number of prediction steps, in this model its fixed to one\n",
    "    batch_size = 512\n",
    "    device = torch.device(\"cuda\")\n",
    "    train_data, val_data, scaler = get_data(name)\n",
    "    global model \n",
    "    model = TransAm().to(device)\n",
    "\n",
    "    global criterion\n",
    "    criterion = nn.MSELoss()\n",
    "    lr = 0.001  # learning rate\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    global optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    global scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    global epochs\n",
    "    epochs = 300  # The number of epochs\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(train_data,epoch)\n",
    "\n",
    "        if (epoch % 100 == 0):\n",
    "            val_loss = plot_and_loss(model, val_data, epoch)\n",
    "            predict_future(model, val_data, 5)\n",
    "        else:\n",
    "            val_loss = evaluate(model, val_data)\n",
    "\n",
    "        if(epoch % 50 ==0):\n",
    "            print('-' * 89)\n",
    "            print(\n",
    "                '| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f}'\n",
    "                .format(epoch, (time.time() - epoch_start_time), val_loss,\n",
    "                        math.exp(val_loss)))\n",
    "            print('-' * 89)\n",
    "        scheduler.step()\n",
    "    \n",
    "    def get_predict(eval_model, data_source):\n",
    "        eval_model.eval()\n",
    "        total_loss = 0.\n",
    "        test_result = torch.Tensor(0)\n",
    "        truth = torch.Tensor(0)\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(data_source) - 1):\n",
    "                data, target = get_batch(data_source, i, 1)\n",
    "                output = eval_model(data)\n",
    "                total_loss += criterion(output, target).item()\n",
    "                test_result = torch.cat((test_result, output[-1].view(-1).cpu()),\n",
    "                                        0)\n",
    "                truth = torch.cat((truth, target[-1].view(-1).cpu()), 0)\n",
    "\n",
    "        #test_result = test_result.cpu().numpy() -> no need to detach stuff..\n",
    "        return scaler.inverse_transform(test_result.view(-1, 1))[120:], scaler.inverse_transform(truth.view(-1, 1))[120:]\n",
    "\n",
    "    \n",
    "    return get_predict(model, val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tools\\anaconda3\\envs\\data\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:381: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     8/    8 batches | lr 0.001000 | 129.34 ms | loss 28.85596 | ppl 3403957749763.20\n",
      "| epoch   2 |     8/    8 batches | lr 0.000960 | 89.48 ms | loss 4.95687 | ppl   142.15\n",
      "| epoch   3 |     8/    8 batches | lr 0.000941 | 89.17 ms | loss 0.56694 | ppl     1.76\n",
      "| epoch   4 |     8/    8 batches | lr 0.000922 | 88.22 ms | loss 0.65478 | ppl     1.92\n",
      "| epoch   5 |     8/    8 batches | lr 0.000904 | 89.00 ms | loss 1.60253 | ppl     4.97\n",
      "| epoch   6 |     8/    8 batches | lr 0.000886 | 90.30 ms | loss 0.51910 | ppl     1.68\n",
      "| epoch   7 |     8/    8 batches | lr 0.000868 | 90.20 ms | loss 0.32358 | ppl     1.38\n",
      "| epoch   8 |     8/    8 batches | lr 0.000851 | 90.98 ms | loss 0.12584 | ppl     1.13\n",
      "| epoch   9 |     8/    8 batches | lr 0.000834 | 89.47 ms | loss 0.20405 | ppl     1.23\n",
      "| epoch  10 |     8/    8 batches | lr 0.000817 | 89.88 ms | loss 0.15181 | ppl     1.16\n",
      "| epoch  11 |     8/    8 batches | lr 0.000801 | 90.04 ms | loss 0.11742 | ppl     1.12\n",
      "| epoch  12 |     8/    8 batches | lr 0.000785 | 89.99 ms | loss 0.09175 | ppl     1.10\n",
      "| epoch  13 |     8/    8 batches | lr 0.000769 | 89.82 ms | loss 0.06661 | ppl     1.07\n",
      "| epoch  14 |     8/    8 batches | lr 0.000754 | 89.90 ms | loss 0.19729 | ppl     1.22\n",
      "| epoch  15 |     8/    8 batches | lr 0.000739 | 90.35 ms | loss 0.06802 | ppl     1.07\n",
      "| epoch  16 |     8/    8 batches | lr 0.000724 | 90.28 ms | loss 0.03880 | ppl     1.04\n",
      "| epoch  17 |     8/    8 batches | lr 0.000709 | 90.11 ms | loss 0.15699 | ppl     1.17\n",
      "| epoch  18 |     8/    8 batches | lr 0.000695 | 89.83 ms | loss 0.16951 | ppl     1.18\n",
      "| epoch  19 |     8/    8 batches | lr 0.000681 | 89.57 ms | loss 0.03301 | ppl     1.03\n",
      "| epoch  20 |     8/    8 batches | lr 0.000668 | 89.99 ms | loss 0.17574 | ppl     1.19\n",
      "| epoch  21 |     8/    8 batches | lr 0.000654 | 89.40 ms | loss 0.27849 | ppl     1.32\n",
      "| epoch  22 |     8/    8 batches | lr 0.000641 | 89.41 ms | loss 0.07626 | ppl     1.08\n",
      "| epoch  23 |     8/    8 batches | lr 0.000628 | 89.67 ms | loss 0.06120 | ppl     1.06\n",
      "| epoch  24 |     8/    8 batches | lr 0.000616 | 89.43 ms | loss 0.15632 | ppl     1.17\n",
      "| epoch  25 |     8/    8 batches | lr 0.000603 | 89.64 ms | loss 0.10712 | ppl     1.11\n",
      "| epoch  26 |     8/    8 batches | lr 0.000591 | 90.11 ms | loss 0.06372 | ppl     1.07\n",
      "| epoch  27 |     8/    8 batches | lr 0.000580 | 90.08 ms | loss 0.01594 | ppl     1.02\n",
      "| epoch  28 |     8/    8 batches | lr 0.000568 | 89.57 ms | loss 0.01186 | ppl     1.01\n",
      "| epoch  29 |     8/    8 batches | lr 0.000557 | 89.45 ms | loss 0.02278 | ppl     1.02\n",
      "| epoch  30 |     8/    8 batches | lr 0.000545 | 89.68 ms | loss 0.03248 | ppl     1.03\n",
      "| epoch  31 |     8/    8 batches | lr 0.000535 | 89.74 ms | loss 0.03725 | ppl     1.04\n",
      "| epoch  32 |     8/    8 batches | lr 0.000524 | 89.62 ms | loss 0.01091 | ppl     1.01\n",
      "| epoch  33 |     8/    8 batches | lr 0.000513 | 89.51 ms | loss 0.01942 | ppl     1.02\n",
      "| epoch  34 |     8/    8 batches | lr 0.000503 | 90.02 ms | loss 0.01793 | ppl     1.02\n",
      "| epoch  35 |     8/    8 batches | lr 0.000493 | 89.88 ms | loss 0.00983 | ppl     1.01\n",
      "| epoch  36 |     8/    8 batches | lr 0.000483 | 89.72 ms | loss 0.00682 | ppl     1.01\n",
      "| epoch  37 |     8/    8 batches | lr 0.000474 | 90.13 ms | loss 0.00539 | ppl     1.01\n",
      "| epoch  38 |     8/    8 batches | lr 0.000464 | 89.65 ms | loss 0.00640 | ppl     1.01\n",
      "| epoch  39 |     8/    8 batches | lr 0.000455 | 89.89 ms | loss 0.01276 | ppl     1.01\n",
      "| epoch  40 |     8/    8 batches | lr 0.000446 | 89.90 ms | loss 0.01197 | ppl     1.01\n",
      "| epoch  41 |     8/    8 batches | lr 0.000437 | 89.48 ms | loss 0.01721 | ppl     1.02\n",
      "| epoch  42 |     8/    8 batches | lr 0.000428 | 89.78 ms | loss 0.01734 | ppl     1.02\n",
      "| epoch  43 |     8/    8 batches | lr 0.000419 | 89.37 ms | loss 0.01829 | ppl     1.02\n",
      "| epoch  44 |     8/    8 batches | lr 0.000411 | 89.40 ms | loss 0.02730 | ppl     1.03\n",
      "| epoch  45 |     8/    8 batches | lr 0.000403 | 89.50 ms | loss 0.01996 | ppl     1.02\n",
      "| epoch  46 |     8/    8 batches | lr 0.000395 | 90.02 ms | loss 0.02777 | ppl     1.03\n",
      "| epoch  47 |     8/    8 batches | lr 0.000387 | 90.07 ms | loss 0.00775 | ppl     1.01\n",
      "| epoch  48 |     8/    8 batches | lr 0.000379 | 90.69 ms | loss 0.01099 | ppl     1.01\n",
      "| epoch  49 |     8/    8 batches | lr 0.000372 | 89.65 ms | loss 0.00712 | ppl     1.01\n",
      "| epoch  50 |     8/    8 batches | lr 0.000364 | 89.53 ms | loss 0.00519 | ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time:  0.74s | valid loss 0.00259 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  51 |     8/    8 batches | lr 0.000357 | 89.80 ms | loss 0.00671 | ppl     1.01\n",
      "| epoch  52 |     8/    8 batches | lr 0.000350 | 89.36 ms | loss 0.00857 | ppl     1.01\n",
      "| epoch  53 |     8/    8 batches | lr 0.000343 | 89.67 ms | loss 0.05155 | ppl     1.05\n",
      "| epoch  54 |     8/    8 batches | lr 0.000336 | 89.33 ms | loss 0.02149 | ppl     1.02\n",
      "| epoch  55 |     8/    8 batches | lr 0.000329 | 89.54 ms | loss 0.02039 | ppl     1.02\n",
      "| epoch  56 |     8/    8 batches | lr 0.000323 | 89.77 ms | loss 0.00491 | ppl     1.00\n",
      "| epoch  57 |     8/    8 batches | lr 0.000316 | 89.91 ms | loss 0.00341 | ppl     1.00\n",
      "| epoch  58 |     8/    8 batches | lr 0.000310 | 89.71 ms | loss 0.00376 | ppl     1.00\n",
      "| epoch  59 |     8/    8 batches | lr 0.000304 | 89.27 ms | loss 0.00324 | ppl     1.00\n",
      "| epoch  60 |     8/    8 batches | lr 0.000298 | 89.71 ms | loss 0.00479 | ppl     1.00\n",
      "| epoch  61 |     8/    8 batches | lr 0.000292 | 89.91 ms | loss 0.00463 | ppl     1.00\n",
      "| epoch  62 |     8/    8 batches | lr 0.000286 | 89.81 ms | loss 0.00666 | ppl     1.01\n",
      "| epoch  63 |     8/    8 batches | lr 0.000280 | 89.63 ms | loss 0.00844 | ppl     1.01\n",
      "| epoch  64 |     8/    8 batches | lr 0.000274 | 89.95 ms | loss 0.00556 | ppl     1.01\n",
      "| epoch  65 |     8/    8 batches | lr 0.000269 | 89.84 ms | loss 0.00648 | ppl     1.01\n",
      "| epoch  66 |     8/    8 batches | lr 0.000264 | 89.64 ms | loss 0.01235 | ppl     1.01\n",
      "| epoch  67 |     8/    8 batches | lr 0.000258 | 89.16 ms | loss 0.01565 | ppl     1.02\n",
      "| epoch  68 |     8/    8 batches | lr 0.000253 | 89.73 ms | loss 0.02000 | ppl     1.02\n",
      "| epoch  69 |     8/    8 batches | lr 0.000248 | 89.26 ms | loss 0.01677 | ppl     1.02\n",
      "| epoch  70 |     8/    8 batches | lr 0.000243 | 89.98 ms | loss 0.00822 | ppl     1.01\n",
      "| epoch  71 |     8/    8 batches | lr 0.000238 | 89.82 ms | loss 0.01066 | ppl     1.01\n",
      "| epoch  72 |     8/    8 batches | lr 0.000233 | 90.03 ms | loss 0.00839 | ppl     1.01\n",
      "| epoch  73 |     8/    8 batches | lr 0.000229 | 89.69 ms | loss 0.00575 | ppl     1.01\n",
      "| epoch  74 |     8/    8 batches | lr 0.000224 | 90.68 ms | loss 0.00835 | ppl     1.01\n",
      "| epoch  75 |     8/    8 batches | lr 0.000220 | 91.23 ms | loss 0.00751 | ppl     1.01\n",
      "| epoch  76 |     8/    8 batches | lr 0.000215 | 90.55 ms | loss 0.00941 | ppl     1.01\n",
      "| epoch  77 |     8/    8 batches | lr 0.000211 | 90.21 ms | loss 0.00968 | ppl     1.01\n",
      "| epoch  78 |     8/    8 batches | lr 0.000207 | 89.89 ms | loss 0.00695 | ppl     1.01\n",
      "| epoch  79 |     8/    8 batches | lr 0.000203 | 89.64 ms | loss 0.00570 | ppl     1.01\n",
      "| epoch  80 |     8/    8 batches | lr 0.000199 | 89.51 ms | loss 0.01120 | ppl     1.01\n",
      "| epoch  81 |     8/    8 batches | lr 0.000195 | 89.60 ms | loss 0.00829 | ppl     1.01\n",
      "| epoch  82 |     8/    8 batches | lr 0.000191 | 89.88 ms | loss 0.00529 | ppl     1.01\n",
      "| epoch  83 |     8/    8 batches | lr 0.000187 | 90.17 ms | loss 0.00355 | ppl     1.00\n",
      "| epoch  84 |     8/    8 batches | lr 0.000183 | 98.95 ms | loss 0.00644 | ppl     1.01\n",
      "| epoch  85 |     8/    8 batches | lr 0.000180 | 89.54 ms | loss 0.00585 | ppl     1.01\n",
      "| epoch  86 |     8/    8 batches | lr 0.000176 | 89.83 ms | loss 0.00411 | ppl     1.00\n",
      "| epoch  87 |     8/    8 batches | lr 0.000172 | 89.84 ms | loss 0.00541 | ppl     1.01\n",
      "| epoch  88 |     8/    8 batches | lr 0.000169 | 90.34 ms | loss 0.00437 | ppl     1.00\n",
      "| epoch  89 |     8/    8 batches | lr 0.000166 | 90.85 ms | loss 0.00353 | ppl     1.00\n",
      "| epoch  90 |     8/    8 batches | lr 0.000162 | 91.29 ms | loss 0.00461 | ppl     1.00\n",
      "| epoch  91 |     8/    8 batches | lr 0.000159 | 91.32 ms | loss 0.00393 | ppl     1.00\n",
      "| epoch  92 |     8/    8 batches | lr 0.000156 | 90.20 ms | loss 0.00261 | ppl     1.00\n",
      "| epoch  93 |     8/    8 batches | lr 0.000153 | 92.97 ms | loss 0.00300 | ppl     1.00\n",
      "| epoch  94 |     8/    8 batches | lr 0.000150 | 91.39 ms | loss 0.00461 | ppl     1.00\n",
      "| epoch  95 |     8/    8 batches | lr 0.000147 | 90.81 ms | loss 0.00434 | ppl     1.00\n",
      "| epoch  96 |     8/    8 batches | lr 0.000144 | 90.32 ms | loss 0.00367 | ppl     1.00\n",
      "| epoch  97 |     8/    8 batches | lr 0.000141 | 90.21 ms | loss 0.00442 | ppl     1.00\n",
      "| epoch  98 |     8/    8 batches | lr 0.000138 | 91.18 ms | loss 0.00552 | ppl     1.01\n",
      "| epoch  99 |     8/    8 batches | lr 0.000135 | 91.64 ms | loss 0.00553 | ppl     1.01\n",
      "| epoch 100 |     8/    8 batches | lr 0.000133 | 91.52 ms | loss 0.00426 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time:  1.12s | valid loss 0.00499 | valid ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 101 |     8/    8 batches | lr 0.000130 | 91.40 ms | loss 0.00305 | ppl     1.00\n",
      "| epoch 102 |     8/    8 batches | lr 0.000127 | 91.43 ms | loss 0.00402 | ppl     1.00\n",
      "| epoch 103 |     8/    8 batches | lr 0.000125 | 91.96 ms | loss 0.00462 | ppl     1.00\n",
      "| epoch 104 |     8/    8 batches | lr 0.000122 | 91.47 ms | loss 0.00373 | ppl     1.00\n",
      "| epoch 105 |     8/    8 batches | lr 0.000120 | 91.35 ms | loss 0.00395 | ppl     1.00\n",
      "| epoch 106 |     8/    8 batches | lr 0.000117 | 90.61 ms | loss 0.00481 | ppl     1.00\n",
      "| epoch 107 |     8/    8 batches | lr 0.000115 | 92.00 ms | loss 0.00320 | ppl     1.00\n",
      "| epoch 108 |     8/    8 batches | lr 0.000113 | 92.08 ms | loss 0.00305 | ppl     1.00\n",
      "| epoch 109 |     8/    8 batches | lr 0.000111 | 92.03 ms | loss 0.00377 | ppl     1.00\n",
      "| epoch 110 |     8/    8 batches | lr 0.000108 | 93.03 ms | loss 0.00361 | ppl     1.00\n",
      "| epoch 111 |     8/    8 batches | lr 0.000106 | 94.39 ms | loss 0.00353 | ppl     1.00\n",
      "| epoch 112 |     8/    8 batches | lr 0.000104 | 92.05 ms | loss 0.00421 | ppl     1.00\n",
      "| epoch 113 |     8/    8 batches | lr 0.000102 | 93.22 ms | loss 0.00303 | ppl     1.00\n",
      "| epoch 114 |     8/    8 batches | lr 0.000100 | 92.93 ms | loss 0.00272 | ppl     1.00\n",
      "| epoch 115 |     8/    8 batches | lr 0.000098 | 91.68 ms | loss 0.00329 | ppl     1.00\n",
      "| epoch 116 |     8/    8 batches | lr 0.000096 | 91.29 ms | loss 0.00325 | ppl     1.00\n",
      "| epoch 117 |     8/    8 batches | lr 0.000094 | 91.30 ms | loss 0.00301 | ppl     1.00\n",
      "| epoch 118 |     8/    8 batches | lr 0.000092 | 88.85 ms | loss 0.00352 | ppl     1.00\n",
      "| epoch 119 |     8/    8 batches | lr 0.000090 | 89.62 ms | loss 0.00297 | ppl     1.00\n",
      "| epoch 120 |     8/    8 batches | lr 0.000089 | 89.35 ms | loss 0.00265 | ppl     1.00\n",
      "| epoch 121 |     8/    8 batches | lr 0.000087 | 91.58 ms | loss 0.00312 | ppl     1.00\n",
      "| epoch 122 |     8/    8 batches | lr 0.000085 | 89.89 ms | loss 0.00303 | ppl     1.00\n",
      "| epoch 123 |     8/    8 batches | lr 0.000083 | 89.10 ms | loss 0.00290 | ppl     1.00\n",
      "| epoch 124 |     8/    8 batches | lr 0.000082 | 89.39 ms | loss 0.00323 | ppl     1.00\n",
      "| epoch 125 |     8/    8 batches | lr 0.000080 | 91.41 ms | loss 0.00271 | ppl     1.00\n",
      "| epoch 126 |     8/    8 batches | lr 0.000078 | 88.72 ms | loss 0.00242 | ppl     1.00\n",
      "| epoch 127 |     8/    8 batches | lr 0.000077 | 88.26 ms | loss 0.00271 | ppl     1.00\n",
      "| epoch 128 |     8/    8 batches | lr 0.000075 | 90.41 ms | loss 0.00265 | ppl     1.00\n",
      "| epoch 129 |     8/    8 batches | lr 0.000074 | 90.22 ms | loss 0.00254 | ppl     1.00\n",
      "| epoch 130 |     8/    8 batches | lr 0.000072 | 89.58 ms | loss 0.00299 | ppl     1.00\n",
      "| epoch 131 |     8/    8 batches | lr 0.000071 | 89.51 ms | loss 0.00256 | ppl     1.00\n",
      "| epoch 132 |     8/    8 batches | lr 0.000069 | 90.20 ms | loss 0.00232 | ppl     1.00\n",
      "| epoch 133 |     8/    8 batches | lr 0.000068 | 89.78 ms | loss 0.00249 | ppl     1.00\n",
      "| epoch 134 |     8/    8 batches | lr 0.000067 | 89.65 ms | loss 0.00237 | ppl     1.00\n",
      "| epoch 135 |     8/    8 batches | lr 0.000065 | 89.73 ms | loss 0.00226 | ppl     1.00\n",
      "| epoch 136 |     8/    8 batches | lr 0.000064 | 90.94 ms | loss 0.00238 | ppl     1.00\n",
      "| epoch 137 |     8/    8 batches | lr 0.000063 | 88.75 ms | loss 0.00232 | ppl     1.00\n",
      "| epoch 138 |     8/    8 batches | lr 0.000062 | 89.83 ms | loss 0.00221 | ppl     1.00\n",
      "| epoch 139 |     8/    8 batches | lr 0.000060 | 90.23 ms | loss 0.00223 | ppl     1.00\n",
      "| epoch 140 |     8/    8 batches | lr 0.000059 | 88.54 ms | loss 0.00222 | ppl     1.00\n",
      "| epoch 141 |     8/    8 batches | lr 0.000058 | 89.87 ms | loss 0.00217 | ppl     1.00\n",
      "| epoch 142 |     8/    8 batches | lr 0.000057 | 90.27 ms | loss 0.00214 | ppl     1.00\n",
      "| epoch 143 |     8/    8 batches | lr 0.000056 | 90.20 ms | loss 0.00212 | ppl     1.00\n",
      "| epoch 144 |     8/    8 batches | lr 0.000055 | 89.91 ms | loss 0.00213 | ppl     1.00\n",
      "| epoch 145 |     8/    8 batches | lr 0.000053 | 89.62 ms | loss 0.00211 | ppl     1.00\n",
      "| epoch 146 |     8/    8 batches | lr 0.000052 | 89.03 ms | loss 0.00208 | ppl     1.00\n",
      "| epoch 147 |     8/    8 batches | lr 0.000051 | 89.64 ms | loss 0.00208 | ppl     1.00\n",
      "| epoch 148 |     8/    8 batches | lr 0.000050 | 89.62 ms | loss 0.00207 | ppl     1.00\n",
      "| epoch 149 |     8/    8 batches | lr 0.000049 | 89.55 ms | loss 0.00206 | ppl     1.00\n",
      "| epoch 150 |     8/    8 batches | lr 0.000048 | 89.89 ms | loss 0.00206 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 150 | time:  0.74s | valid loss 0.00343 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 151 |     8/    8 batches | lr 0.000047 | 89.12 ms | loss 0.00205 | ppl     1.00\n",
      "| epoch 152 |     8/    8 batches | lr 0.000046 | 89.69 ms | loss 0.00205 | ppl     1.00\n",
      "| epoch 153 |     8/    8 batches | lr 0.000045 | 88.92 ms | loss 0.00204 | ppl     1.00\n",
      "| epoch 154 |     8/    8 batches | lr 0.000045 | 88.50 ms | loss 0.00203 | ppl     1.00\n",
      "| epoch 155 |     8/    8 batches | lr 0.000044 | 89.42 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 156 |     8/    8 batches | lr 0.000043 | 88.46 ms | loss 0.00203 | ppl     1.00\n",
      "| epoch 157 |     8/    8 batches | lr 0.000042 | 88.71 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 158 |     8/    8 batches | lr 0.000041 | 88.64 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 159 |     8/    8 batches | lr 0.000040 | 88.76 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 160 |     8/    8 batches | lr 0.000039 | 88.81 ms | loss 0.00201 | ppl     1.00\n",
      "| epoch 161 |     8/    8 batches | lr 0.000039 | 88.73 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 162 |     8/    8 batches | lr 0.000038 | 88.87 ms | loss 0.00201 | ppl     1.00\n",
      "| epoch 163 |     8/    8 batches | lr 0.000037 | 88.81 ms | loss 0.00201 | ppl     1.00\n",
      "| epoch 164 |     8/    8 batches | lr 0.000036 | 88.91 ms | loss 0.00200 | ppl     1.00\n",
      "| epoch 165 |     8/    8 batches | lr 0.000036 | 88.64 ms | loss 0.00200 | ppl     1.00\n",
      "| epoch 166 |     8/    8 batches | lr 0.000035 | 88.79 ms | loss 0.00199 | ppl     1.00\n",
      "| epoch 167 |     8/    8 batches | lr 0.000034 | 88.70 ms | loss 0.00200 | ppl     1.00\n",
      "| epoch 168 |     8/    8 batches | lr 0.000034 | 88.66 ms | loss 0.00199 | ppl     1.00\n",
      "| epoch 169 |     8/    8 batches | lr 0.000033 | 88.82 ms | loss 0.00199 | ppl     1.00\n",
      "| epoch 170 |     8/    8 batches | lr 0.000032 | 88.92 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 171 |     8/    8 batches | lr 0.000032 | 88.95 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 172 |     8/    8 batches | lr 0.000031 | 88.66 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 173 |     8/    8 batches | lr 0.000030 | 88.68 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 174 |     8/    8 batches | lr 0.000030 | 88.80 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 175 |     8/    8 batches | lr 0.000029 | 88.72 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 176 |     8/    8 batches | lr 0.000029 | 88.61 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 177 |     8/    8 batches | lr 0.000028 | 88.65 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 178 |     8/    8 batches | lr 0.000027 | 88.73 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 179 |     8/    8 batches | lr 0.000027 | 88.76 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 180 |     8/    8 batches | lr 0.000026 | 89.66 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 181 |     8/    8 batches | lr 0.000026 | 89.55 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 182 |     8/    8 batches | lr 0.000025 | 90.05 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 183 |     8/    8 batches | lr 0.000025 | 89.85 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 184 |     8/    8 batches | lr 0.000024 | 97.37 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 185 |     8/    8 batches | lr 0.000024 | 88.39 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 186 |     8/    8 batches | lr 0.000023 | 90.36 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 187 |     8/    8 batches | lr 0.000023 | 89.53 ms | loss 0.00194 | ppl     1.00\n",
      "| epoch 188 |     8/    8 batches | lr 0.000022 | 88.63 ms | loss 0.00194 | ppl     1.00\n",
      "| epoch 189 |     8/    8 batches | lr 0.000022 | 88.66 ms | loss 0.00194 | ppl     1.00\n",
      "| epoch 190 |     8/    8 batches | lr 0.000022 | 90.73 ms | loss 0.00193 | ppl     1.00\n",
      "| epoch 191 |     8/    8 batches | lr 0.000021 | 89.57 ms | loss 0.00193 | ppl     1.00\n",
      "| epoch 192 |     8/    8 batches | lr 0.000021 | 89.21 ms | loss 0.00193 | ppl     1.00\n",
      "| epoch 193 |     8/    8 batches | lr 0.000020 | 88.96 ms | loss 0.00194 | ppl     1.00\n",
      "| epoch 194 |     8/    8 batches | lr 0.000020 | 89.03 ms | loss 0.00194 | ppl     1.00\n",
      "| epoch 195 |     8/    8 batches | lr 0.000019 | 89.05 ms | loss 0.00193 | ppl     1.00\n",
      "| epoch 196 |     8/    8 batches | lr 0.000019 | 91.06 ms | loss 0.00193 | ppl     1.00\n",
      "| epoch 197 |     8/    8 batches | lr 0.000019 | 91.26 ms | loss 0.00192 | ppl     1.00\n",
      "| epoch 198 |     8/    8 batches | lr 0.000018 | 91.36 ms | loss 0.00192 | ppl     1.00\n",
      "| epoch 199 |     8/    8 batches | lr 0.000018 | 91.13 ms | loss 0.00193 | ppl     1.00\n",
      "| epoch 200 |     8/    8 batches | lr 0.000018 | 89.31 ms | loss 0.00192 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 200 | time:  1.07s | valid loss 0.00289 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 201 |     8/    8 batches | lr 0.000017 | 90.03 ms | loss 0.00192 | ppl     1.00\n",
      "| epoch 202 |     8/    8 batches | lr 0.000017 | 88.61 ms | loss 0.00192 | ppl     1.00\n",
      "| epoch 203 |     8/    8 batches | lr 0.000017 | 89.73 ms | loss 0.00192 | ppl     1.00\n",
      "| epoch 204 |     8/    8 batches | lr 0.000016 | 89.35 ms | loss 0.00192 | ppl     1.00\n",
      "| epoch 205 |     8/    8 batches | lr 0.000016 | 89.81 ms | loss 0.00191 | ppl     1.00\n",
      "| epoch 206 |     8/    8 batches | lr 0.000016 | 88.87 ms | loss 0.00191 | ppl     1.00\n",
      "| epoch 207 |     8/    8 batches | lr 0.000015 | 88.88 ms | loss 0.00192 | ppl     1.00\n",
      "| epoch 208 |     8/    8 batches | lr 0.000015 | 88.83 ms | loss 0.00191 | ppl     1.00\n",
      "| epoch 209 |     8/    8 batches | lr 0.000015 | 89.08 ms | loss 0.00191 | ppl     1.00\n",
      "| epoch 210 |     8/    8 batches | lr 0.000014 | 88.76 ms | loss 0.00191 | ppl     1.00\n",
      "| epoch 211 |     8/    8 batches | lr 0.000014 | 88.65 ms | loss 0.00191 | ppl     1.00\n",
      "| epoch 212 |     8/    8 batches | lr 0.000014 | 90.01 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 213 |     8/    8 batches | lr 0.000014 | 91.79 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 214 |     8/    8 batches | lr 0.000013 | 91.67 ms | loss 0.00191 | ppl     1.00\n",
      "| epoch 215 |     8/    8 batches | lr 0.000013 | 89.36 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 216 |     8/    8 batches | lr 0.000013 | 89.63 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 217 |     8/    8 batches | lr 0.000012 | 89.46 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 218 |     8/    8 batches | lr 0.000012 | 89.52 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 219 |     8/    8 batches | lr 0.000012 | 89.35 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 220 |     8/    8 batches | lr 0.000012 | 89.83 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 221 |     8/    8 batches | lr 0.000012 | 90.63 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 222 |     8/    8 batches | lr 0.000011 | 88.87 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 223 |     8/    8 batches | lr 0.000011 | 88.79 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 224 |     8/    8 batches | lr 0.000011 | 88.82 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 225 |     8/    8 batches | lr 0.000011 | 88.78 ms | loss 0.00189 | ppl     1.00\n",
      "| epoch 226 |     8/    8 batches | lr 0.000010 | 89.46 ms | loss 0.00189 | ppl     1.00\n",
      "| epoch 227 |     8/    8 batches | lr 0.000010 | 89.29 ms | loss 0.00189 | ppl     1.00\n",
      "| epoch 228 |     8/    8 batches | lr 0.000010 | 89.34 ms | loss 0.00189 | ppl     1.00\n",
      "| epoch 229 |     8/    8 batches | lr 0.000010 | 89.38 ms | loss 0.00189 | ppl     1.00\n",
      "| epoch 230 |     8/    8 batches | lr 0.000010 | 89.49 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 231 |     8/    8 batches | lr 0.000009 | 87.98 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 232 |     8/    8 batches | lr 0.000009 | 87.20 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 233 |     8/    8 batches | lr 0.000009 | 87.96 ms | loss 0.00189 | ppl     1.00\n",
      "| epoch 234 |     8/    8 batches | lr 0.000009 | 88.38 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 235 |     8/    8 batches | lr 0.000009 | 87.82 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 236 |     8/    8 batches | lr 0.000008 | 88.01 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 237 |     8/    8 batches | lr 0.000008 | 88.91 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 238 |     8/    8 batches | lr 0.000008 | 88.78 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 239 |     8/    8 batches | lr 0.000008 | 88.17 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 240 |     8/    8 batches | lr 0.000008 | 87.96 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 241 |     8/    8 batches | lr 0.000008 | 88.67 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 242 |     8/    8 batches | lr 0.000008 | 88.07 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 243 |     8/    8 batches | lr 0.000007 | 88.90 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 244 |     8/    8 batches | lr 0.000007 | 88.73 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 245 |     8/    8 batches | lr 0.000007 | 89.01 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 246 |     8/    8 batches | lr 0.000007 | 89.07 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 247 |     8/    8 batches | lr 0.000007 | 88.67 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 248 |     8/    8 batches | lr 0.000007 | 88.51 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 249 |     8/    8 batches | lr 0.000007 | 88.48 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 250 |     8/    8 batches | lr 0.000006 | 87.16 ms | loss 0.00187 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 250 | time:  0.72s | valid loss 0.00284 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 251 |     8/    8 batches | lr 0.000006 | 86.74 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 252 |     8/    8 batches | lr 0.000006 | 86.63 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 253 |     8/    8 batches | lr 0.000006 | 86.60 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 254 |     8/    8 batches | lr 0.000006 | 87.38 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 255 |     8/    8 batches | lr 0.000006 | 88.43 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 256 |     8/    8 batches | lr 0.000006 | 87.48 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 257 |     8/    8 batches | lr 0.000006 | 88.92 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 258 |     8/    8 batches | lr 0.000005 | 87.98 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 259 |     8/    8 batches | lr 0.000005 | 87.75 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 260 |     8/    8 batches | lr 0.000005 | 89.35 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 261 |     8/    8 batches | lr 0.000005 | 88.07 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 262 |     8/    8 batches | lr 0.000005 | 87.96 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 263 |     8/    8 batches | lr 0.000005 | 87.83 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 264 |     8/    8 batches | lr 0.000005 | 88.20 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 265 |     8/    8 batches | lr 0.000005 | 88.80 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 266 |     8/    8 batches | lr 0.000005 | 88.84 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 267 |     8/    8 batches | lr 0.000005 | 87.21 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 268 |     8/    8 batches | lr 0.000004 | 87.78 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 269 |     8/    8 batches | lr 0.000004 | 88.36 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 270 |     8/    8 batches | lr 0.000004 | 88.42 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 271 |     8/    8 batches | lr 0.000004 | 88.92 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 272 |     8/    8 batches | lr 0.000004 | 87.12 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 273 |     8/    8 batches | lr 0.000004 | 86.85 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 274 |     8/    8 batches | lr 0.000004 | 87.71 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 275 |     8/    8 batches | lr 0.000004 | 87.68 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 276 |     8/    8 batches | lr 0.000004 | 86.84 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 277 |     8/    8 batches | lr 0.000004 | 87.51 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 278 |     8/    8 batches | lr 0.000004 | 86.89 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 279 |     8/    8 batches | lr 0.000004 | 88.37 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 280 |     8/    8 batches | lr 0.000003 | 87.33 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 281 |     8/    8 batches | lr 0.000003 | 87.34 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 282 |     8/    8 batches | lr 0.000003 | 87.70 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 283 |     8/    8 batches | lr 0.000003 | 87.24 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 284 |     8/    8 batches | lr 0.000003 | 88.56 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 285 |     8/    8 batches | lr 0.000003 | 86.52 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 286 |     8/    8 batches | lr 0.000003 | 87.49 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 287 |     8/    8 batches | lr 0.000003 | 88.07 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 288 |     8/    8 batches | lr 0.000003 | 97.81 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 289 |     8/    8 batches | lr 0.000003 | 87.98 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 290 |     8/    8 batches | lr 0.000003 | 86.08 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 291 |     8/    8 batches | lr 0.000003 | 87.27 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 292 |     8/    8 batches | lr 0.000003 | 86.71 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 293 |     8/    8 batches | lr 0.000003 | 86.97 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 294 |     8/    8 batches | lr 0.000003 | 88.45 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 295 |     8/    8 batches | lr 0.000003 | 88.75 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 296 |     8/    8 batches | lr 0.000003 | 86.92 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 297 |     8/    8 batches | lr 0.000002 | 88.46 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 298 |     8/    8 batches | lr 0.000002 | 88.82 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 299 |     8/    8 batches | lr 0.000002 | 89.05 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 300 |     8/    8 batches | lr 0.000002 | 90.08 ms | loss 0.00185 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 300 | time:  1.07s | valid loss 0.00284 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tools\\anaconda3\\envs\\data\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:381: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     8/    8 batches | lr 0.001000 | 88.77 ms | loss 9.68845 | ppl 16130.23\n",
      "| epoch   2 |     8/    8 batches | lr 0.000960 | 89.64 ms | loss 12.62445 | ppl 303898.04\n",
      "| epoch   3 |     8/    8 batches | lr 0.000941 | 89.37 ms | loss 1.12618 | ppl     3.08\n",
      "| epoch   4 |     8/    8 batches | lr 0.000922 | 88.95 ms | loss 0.77268 | ppl     2.17\n",
      "| epoch   5 |     8/    8 batches | lr 0.000904 | 89.24 ms | loss 0.09198 | ppl     1.10\n",
      "| epoch   6 |     8/    8 batches | lr 0.000886 | 89.30 ms | loss 0.10605 | ppl     1.11\n",
      "| epoch   7 |     8/    8 batches | lr 0.000868 | 90.67 ms | loss 0.22271 | ppl     1.25\n",
      "| epoch   8 |     8/    8 batches | lr 0.000851 | 90.90 ms | loss 0.27169 | ppl     1.31\n",
      "| epoch   9 |     8/    8 batches | lr 0.000834 | 89.86 ms | loss 0.04487 | ppl     1.05\n",
      "| epoch  10 |     8/    8 batches | lr 0.000817 | 89.41 ms | loss 0.10763 | ppl     1.11\n",
      "| epoch  11 |     8/    8 batches | lr 0.000801 | 89.44 ms | loss 0.03524 | ppl     1.04\n",
      "| epoch  12 |     8/    8 batches | lr 0.000785 | 89.28 ms | loss 0.03317 | ppl     1.03\n",
      "| epoch  13 |     8/    8 batches | lr 0.000769 | 89.30 ms | loss 0.02074 | ppl     1.02\n",
      "| epoch  14 |     8/    8 batches | lr 0.000754 | 89.18 ms | loss 0.02023 | ppl     1.02\n",
      "| epoch  15 |     8/    8 batches | lr 0.000739 | 89.43 ms | loss 0.03819 | ppl     1.04\n",
      "| epoch  16 |     8/    8 batches | lr 0.000724 | 89.29 ms | loss 0.15332 | ppl     1.17\n",
      "| epoch  17 |     8/    8 batches | lr 0.000709 | 89.75 ms | loss 0.15516 | ppl     1.17\n",
      "| epoch  18 |     8/    8 batches | lr 0.000695 | 90.29 ms | loss 0.04639 | ppl     1.05\n",
      "| epoch  19 |     8/    8 batches | lr 0.000681 | 92.80 ms | loss 0.06132 | ppl     1.06\n",
      "| epoch  20 |     8/    8 batches | lr 0.000668 | 91.00 ms | loss 0.03801 | ppl     1.04\n",
      "| epoch  21 |     8/    8 batches | lr 0.000654 | 90.87 ms | loss 0.01106 | ppl     1.01\n",
      "| epoch  22 |     8/    8 batches | lr 0.000641 | 89.37 ms | loss 0.03999 | ppl     1.04\n",
      "| epoch  23 |     8/    8 batches | lr 0.000628 | 90.26 ms | loss 0.06781 | ppl     1.07\n",
      "| epoch  24 |     8/    8 batches | lr 0.000616 | 89.55 ms | loss 0.06733 | ppl     1.07\n",
      "| epoch  25 |     8/    8 batches | lr 0.000603 | 89.29 ms | loss 0.04105 | ppl     1.04\n",
      "| epoch  26 |     8/    8 batches | lr 0.000591 | 89.22 ms | loss 0.16773 | ppl     1.18\n",
      "| epoch  27 |     8/    8 batches | lr 0.000580 | 90.42 ms | loss 0.03597 | ppl     1.04\n",
      "| epoch  28 |     8/    8 batches | lr 0.000568 | 90.33 ms | loss 0.04768 | ppl     1.05\n",
      "| epoch  29 |     8/    8 batches | lr 0.000557 | 90.44 ms | loss 0.01745 | ppl     1.02\n",
      "| epoch  30 |     8/    8 batches | lr 0.000545 | 89.36 ms | loss 0.02073 | ppl     1.02\n",
      "| epoch  31 |     8/    8 batches | lr 0.000535 | 89.51 ms | loss 0.01308 | ppl     1.01\n",
      "| epoch  32 |     8/    8 batches | lr 0.000524 | 88.81 ms | loss 0.02303 | ppl     1.02\n",
      "| epoch  33 |     8/    8 batches | lr 0.000513 | 90.62 ms | loss 0.03289 | ppl     1.03\n",
      "| epoch  34 |     8/    8 batches | lr 0.000503 | 89.99 ms | loss 0.04225 | ppl     1.04\n",
      "| epoch  35 |     8/    8 batches | lr 0.000493 | 89.19 ms | loss 0.09459 | ppl     1.10\n",
      "| epoch  36 |     8/    8 batches | lr 0.000483 | 89.38 ms | loss 0.12439 | ppl     1.13\n",
      "| epoch  37 |     8/    8 batches | lr 0.000474 | 89.26 ms | loss 0.03750 | ppl     1.04\n",
      "| epoch  38 |     8/    8 batches | lr 0.000464 | 89.14 ms | loss 0.00876 | ppl     1.01\n",
      "| epoch  39 |     8/    8 batches | lr 0.000455 | 89.42 ms | loss 0.01986 | ppl     1.02\n",
      "| epoch  40 |     8/    8 batches | lr 0.000446 | 89.26 ms | loss 0.03449 | ppl     1.04\n",
      "| epoch  41 |     8/    8 batches | lr 0.000437 | 89.33 ms | loss 0.02058 | ppl     1.02\n",
      "| epoch  42 |     8/    8 batches | lr 0.000428 | 89.33 ms | loss 0.00850 | ppl     1.01\n",
      "| epoch  43 |     8/    8 batches | lr 0.000419 | 89.17 ms | loss 0.05475 | ppl     1.06\n",
      "| epoch  44 |     8/    8 batches | lr 0.000411 | 89.47 ms | loss 0.01916 | ppl     1.02\n",
      "| epoch  45 |     8/    8 batches | lr 0.000403 | 89.16 ms | loss 0.01859 | ppl     1.02\n",
      "| epoch  46 |     8/    8 batches | lr 0.000395 | 89.11 ms | loss 0.01485 | ppl     1.01\n",
      "| epoch  47 |     8/    8 batches | lr 0.000387 | 89.24 ms | loss 0.02660 | ppl     1.03\n",
      "| epoch  48 |     8/    8 batches | lr 0.000379 | 89.26 ms | loss 0.02484 | ppl     1.03\n",
      "| epoch  49 |     8/    8 batches | lr 0.000372 | 89.30 ms | loss 0.05273 | ppl     1.05\n",
      "| epoch  50 |     8/    8 batches | lr 0.000364 | 89.31 ms | loss 0.00884 | ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time:  0.73s | valid loss 0.00266 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  51 |     8/    8 batches | lr 0.000357 | 89.37 ms | loss 0.00710 | ppl     1.01\n",
      "| epoch  52 |     8/    8 batches | lr 0.000350 | 89.33 ms | loss 0.00416 | ppl     1.00\n",
      "| epoch  53 |     8/    8 batches | lr 0.000343 | 89.41 ms | loss 0.00416 | ppl     1.00\n",
      "| epoch  54 |     8/    8 batches | lr 0.000336 | 89.26 ms | loss 0.00437 | ppl     1.00\n",
      "| epoch  55 |     8/    8 batches | lr 0.000329 | 89.49 ms | loss 0.00633 | ppl     1.01\n",
      "| epoch  56 |     8/    8 batches | lr 0.000323 | 89.18 ms | loss 0.00657 | ppl     1.01\n",
      "| epoch  57 |     8/    8 batches | lr 0.000316 | 89.33 ms | loss 0.00525 | ppl     1.01\n",
      "| epoch  58 |     8/    8 batches | lr 0.000310 | 89.47 ms | loss 0.00395 | ppl     1.00\n",
      "| epoch  59 |     8/    8 batches | lr 0.000304 | 89.54 ms | loss 0.00926 | ppl     1.01\n",
      "| epoch  60 |     8/    8 batches | lr 0.000298 | 89.16 ms | loss 0.01141 | ppl     1.01\n",
      "| epoch  61 |     8/    8 batches | lr 0.000292 | 89.23 ms | loss 0.01226 | ppl     1.01\n",
      "| epoch  62 |     8/    8 batches | lr 0.000286 | 89.22 ms | loss 0.03337 | ppl     1.03\n",
      "| epoch  63 |     8/    8 batches | lr 0.000280 | 89.22 ms | loss 0.02272 | ppl     1.02\n",
      "| epoch  64 |     8/    8 batches | lr 0.000274 | 89.40 ms | loss 0.01157 | ppl     1.01\n",
      "| epoch  65 |     8/    8 batches | lr 0.000269 | 89.56 ms | loss 0.00494 | ppl     1.00\n",
      "| epoch  66 |     8/    8 batches | lr 0.000264 | 89.11 ms | loss 0.00490 | ppl     1.00\n",
      "| epoch  67 |     8/    8 batches | lr 0.000258 | 89.48 ms | loss 0.00494 | ppl     1.00\n",
      "| epoch  68 |     8/    8 batches | lr 0.000253 | 89.62 ms | loss 0.01110 | ppl     1.01\n",
      "| epoch  69 |     8/    8 batches | lr 0.000248 | 89.70 ms | loss 0.01743 | ppl     1.02\n",
      "| epoch  70 |     8/    8 batches | lr 0.000243 | 89.33 ms | loss 0.00460 | ppl     1.00\n",
      "| epoch  71 |     8/    8 batches | lr 0.000238 | 89.51 ms | loss 0.00614 | ppl     1.01\n",
      "| epoch  72 |     8/    8 batches | lr 0.000233 | 89.75 ms | loss 0.01693 | ppl     1.02\n",
      "| epoch  73 |     8/    8 batches | lr 0.000229 | 89.33 ms | loss 0.00768 | ppl     1.01\n",
      "| epoch  74 |     8/    8 batches | lr 0.000224 | 90.35 ms | loss 0.00879 | ppl     1.01\n",
      "| epoch  75 |     8/    8 batches | lr 0.000220 | 92.51 ms | loss 0.00593 | ppl     1.01\n",
      "| epoch  76 |     8/    8 batches | lr 0.000215 | 90.66 ms | loss 0.00955 | ppl     1.01\n",
      "| epoch  77 |     8/    8 batches | lr 0.000211 | 89.66 ms | loss 0.00651 | ppl     1.01\n",
      "| epoch  78 |     8/    8 batches | lr 0.000207 | 89.30 ms | loss 0.00932 | ppl     1.01\n",
      "| epoch  79 |     8/    8 batches | lr 0.000203 | 89.44 ms | loss 0.00576 | ppl     1.01\n",
      "| epoch  80 |     8/    8 batches | lr 0.000199 | 89.50 ms | loss 0.00672 | ppl     1.01\n",
      "| epoch  81 |     8/    8 batches | lr 0.000195 | 89.83 ms | loss 0.00399 | ppl     1.00\n",
      "| epoch  82 |     8/    8 batches | lr 0.000191 | 89.44 ms | loss 0.00337 | ppl     1.00\n",
      "| epoch  83 |     8/    8 batches | lr 0.000187 | 89.44 ms | loss 0.00407 | ppl     1.00\n",
      "| epoch  84 |     8/    8 batches | lr 0.000183 | 89.39 ms | loss 0.00567 | ppl     1.01\n",
      "| epoch  85 |     8/    8 batches | lr 0.000180 | 89.75 ms | loss 0.00991 | ppl     1.01\n",
      "| epoch  86 |     8/    8 batches | lr 0.000176 | 89.38 ms | loss 0.00719 | ppl     1.01\n",
      "| epoch  87 |     8/    8 batches | lr 0.000172 | 89.51 ms | loss 0.00720 | ppl     1.01\n",
      "| epoch  88 |     8/    8 batches | lr 0.000169 | 89.69 ms | loss 0.00394 | ppl     1.00\n",
      "| epoch  89 |     8/    8 batches | lr 0.000166 | 89.52 ms | loss 0.00518 | ppl     1.01\n",
      "| epoch  90 |     8/    8 batches | lr 0.000162 | 89.58 ms | loss 0.00587 | ppl     1.01\n",
      "| epoch  91 |     8/    8 batches | lr 0.000159 | 89.47 ms | loss 0.00858 | ppl     1.01\n",
      "| epoch  92 |     8/    8 batches | lr 0.000156 | 89.44 ms | loss 0.00673 | ppl     1.01\n",
      "| epoch  93 |     8/    8 batches | lr 0.000153 | 98.52 ms | loss 0.00656 | ppl     1.01\n",
      "| epoch  94 |     8/    8 batches | lr 0.000150 | 89.34 ms | loss 0.00358 | ppl     1.00\n",
      "| epoch  95 |     8/    8 batches | lr 0.000147 | 89.16 ms | loss 0.00430 | ppl     1.00\n",
      "| epoch  96 |     8/    8 batches | lr 0.000144 | 88.97 ms | loss 0.00475 | ppl     1.00\n",
      "| epoch  97 |     8/    8 batches | lr 0.000141 | 89.22 ms | loss 0.00610 | ppl     1.01\n",
      "| epoch  98 |     8/    8 batches | lr 0.000138 | 89.24 ms | loss 0.00638 | ppl     1.01\n",
      "| epoch  99 |     8/    8 batches | lr 0.000135 | 88.98 ms | loss 0.00613 | ppl     1.01\n",
      "| epoch 100 |     8/    8 batches | lr 0.000133 | 88.95 ms | loss 0.00430 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time:  1.07s | valid loss 0.00035 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 101 |     8/    8 batches | lr 0.000130 | 89.31 ms | loss 0.00295 | ppl     1.00\n",
      "| epoch 102 |     8/    8 batches | lr 0.000127 | 89.65 ms | loss 0.00426 | ppl     1.00\n",
      "| epoch 103 |     8/    8 batches | lr 0.000125 | 89.71 ms | loss 0.00353 | ppl     1.00\n",
      "| epoch 104 |     8/    8 batches | lr 0.000122 | 89.75 ms | loss 0.00360 | ppl     1.00\n",
      "| epoch 105 |     8/    8 batches | lr 0.000120 | 89.79 ms | loss 0.00391 | ppl     1.00\n",
      "| epoch 106 |     8/    8 batches | lr 0.000117 | 89.85 ms | loss 0.00515 | ppl     1.01\n",
      "| epoch 107 |     8/    8 batches | lr 0.000115 | 89.49 ms | loss 0.00583 | ppl     1.01\n",
      "| epoch 108 |     8/    8 batches | lr 0.000113 | 89.32 ms | loss 0.00390 | ppl     1.00\n",
      "| epoch 109 |     8/    8 batches | lr 0.000111 | 89.34 ms | loss 0.00318 | ppl     1.00\n",
      "| epoch 110 |     8/    8 batches | lr 0.000108 | 89.53 ms | loss 0.00280 | ppl     1.00\n",
      "| epoch 111 |     8/    8 batches | lr 0.000106 | 89.46 ms | loss 0.00376 | ppl     1.00\n",
      "| epoch 112 |     8/    8 batches | lr 0.000104 | 89.48 ms | loss 0.00371 | ppl     1.00\n",
      "| epoch 113 |     8/    8 batches | lr 0.000102 | 89.41 ms | loss 0.00315 | ppl     1.00\n",
      "| epoch 114 |     8/    8 batches | lr 0.000100 | 89.57 ms | loss 0.00364 | ppl     1.00\n",
      "| epoch 115 |     8/    8 batches | lr 0.000098 | 90.40 ms | loss 0.00353 | ppl     1.00\n",
      "| epoch 116 |     8/    8 batches | lr 0.000096 | 90.81 ms | loss 0.00370 | ppl     1.00\n",
      "| epoch 117 |     8/    8 batches | lr 0.000094 | 91.24 ms | loss 0.00374 | ppl     1.00\n",
      "| epoch 118 |     8/    8 batches | lr 0.000092 | 91.16 ms | loss 0.00308 | ppl     1.00\n",
      "| epoch 119 |     8/    8 batches | lr 0.000090 | 89.74 ms | loss 0.00352 | ppl     1.00\n",
      "| epoch 120 |     8/    8 batches | lr 0.000089 | 91.46 ms | loss 0.00366 | ppl     1.00\n",
      "| epoch 121 |     8/    8 batches | lr 0.000087 | 92.41 ms | loss 0.00288 | ppl     1.00\n",
      "| epoch 122 |     8/    8 batches | lr 0.000085 | 91.21 ms | loss 0.00279 | ppl     1.00\n",
      "| epoch 123 |     8/    8 batches | lr 0.000083 | 89.46 ms | loss 0.00330 | ppl     1.00\n",
      "| epoch 124 |     8/    8 batches | lr 0.000082 | 92.22 ms | loss 0.00327 | ppl     1.00\n",
      "| epoch 125 |     8/    8 batches | lr 0.000080 | 89.06 ms | loss 0.00306 | ppl     1.00\n",
      "| epoch 126 |     8/    8 batches | lr 0.000078 | 87.94 ms | loss 0.00316 | ppl     1.00\n",
      "| epoch 127 |     8/    8 batches | lr 0.000077 | 88.42 ms | loss 0.00266 | ppl     1.00\n",
      "| epoch 128 |     8/    8 batches | lr 0.000075 | 87.23 ms | loss 0.00262 | ppl     1.00\n",
      "| epoch 129 |     8/    8 batches | lr 0.000074 | 87.39 ms | loss 0.00299 | ppl     1.00\n",
      "| epoch 130 |     8/    8 batches | lr 0.000072 | 87.73 ms | loss 0.00292 | ppl     1.00\n",
      "| epoch 131 |     8/    8 batches | lr 0.000071 | 87.54 ms | loss 0.00277 | ppl     1.00\n",
      "| epoch 132 |     8/    8 batches | lr 0.000069 | 87.81 ms | loss 0.00290 | ppl     1.00\n",
      "| epoch 133 |     8/    8 batches | lr 0.000068 | 88.11 ms | loss 0.00261 | ppl     1.00\n",
      "| epoch 134 |     8/    8 batches | lr 0.000067 | 87.45 ms | loss 0.00246 | ppl     1.00\n",
      "| epoch 135 |     8/    8 batches | lr 0.000065 | 87.56 ms | loss 0.00271 | ppl     1.00\n",
      "| epoch 136 |     8/    8 batches | lr 0.000064 | 87.00 ms | loss 0.00270 | ppl     1.00\n",
      "| epoch 137 |     8/    8 batches | lr 0.000063 | 87.93 ms | loss 0.00250 | ppl     1.00\n",
      "| epoch 138 |     8/    8 batches | lr 0.000062 | 87.64 ms | loss 0.00261 | ppl     1.00\n",
      "| epoch 139 |     8/    8 batches | lr 0.000060 | 87.56 ms | loss 0.00250 | ppl     1.00\n",
      "| epoch 140 |     8/    8 batches | lr 0.000059 | 87.99 ms | loss 0.00236 | ppl     1.00\n",
      "| epoch 141 |     8/    8 batches | lr 0.000058 | 88.00 ms | loss 0.00251 | ppl     1.00\n",
      "| epoch 142 |     8/    8 batches | lr 0.000057 | 87.85 ms | loss 0.00237 | ppl     1.00\n",
      "| epoch 143 |     8/    8 batches | lr 0.000056 | 89.35 ms | loss 0.00224 | ppl     1.00\n",
      "| epoch 144 |     8/    8 batches | lr 0.000055 | 88.04 ms | loss 0.00237 | ppl     1.00\n",
      "| epoch 145 |     8/    8 batches | lr 0.000053 | 89.30 ms | loss 0.00226 | ppl     1.00\n",
      "| epoch 146 |     8/    8 batches | lr 0.000052 | 88.94 ms | loss 0.00215 | ppl     1.00\n",
      "| epoch 147 |     8/    8 batches | lr 0.000051 | 88.43 ms | loss 0.00220 | ppl     1.00\n",
      "| epoch 148 |     8/    8 batches | lr 0.000050 | 89.32 ms | loss 0.00218 | ppl     1.00\n",
      "| epoch 149 |     8/    8 batches | lr 0.000049 | 86.99 ms | loss 0.00207 | ppl     1.00\n",
      "| epoch 150 |     8/    8 batches | lr 0.000048 | 87.57 ms | loss 0.00207 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 150 | time:  0.72s | valid loss 0.00302 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 151 |     8/    8 batches | lr 0.000047 | 90.75 ms | loss 0.00206 | ppl     1.00\n",
      "| epoch 152 |     8/    8 batches | lr 0.000046 | 89.66 ms | loss 0.00203 | ppl     1.00\n",
      "| epoch 153 |     8/    8 batches | lr 0.000045 | 89.23 ms | loss 0.00201 | ppl     1.00\n",
      "| epoch 154 |     8/    8 batches | lr 0.000045 | 88.31 ms | loss 0.00200 | ppl     1.00\n",
      "| epoch 155 |     8/    8 batches | lr 0.000044 | 88.89 ms | loss 0.00199 | ppl     1.00\n",
      "| epoch 156 |     8/    8 batches | lr 0.000043 | 88.19 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 157 |     8/    8 batches | lr 0.000042 | 88.17 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 158 |     8/    8 batches | lr 0.000041 | 88.26 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 159 |     8/    8 batches | lr 0.000040 | 87.52 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 160 |     8/    8 batches | lr 0.000039 | 90.47 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 161 |     8/    8 batches | lr 0.000039 | 90.46 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 162 |     8/    8 batches | lr 0.000038 | 88.13 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 163 |     8/    8 batches | lr 0.000037 | 90.93 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 164 |     8/    8 batches | lr 0.000036 | 93.04 ms | loss 0.00194 | ppl     1.00\n",
      "| epoch 165 |     8/    8 batches | lr 0.000036 | 90.20 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 166 |     8/    8 batches | lr 0.000035 | 89.47 ms | loss 0.00194 | ppl     1.00\n",
      "| epoch 167 |     8/    8 batches | lr 0.000034 | 89.83 ms | loss 0.00194 | ppl     1.00\n",
      "| epoch 168 |     8/    8 batches | lr 0.000034 | 89.71 ms | loss 0.00194 | ppl     1.00\n",
      "| epoch 169 |     8/    8 batches | lr 0.000033 | 90.37 ms | loss 0.00193 | ppl     1.00\n",
      "| epoch 170 |     8/    8 batches | lr 0.000032 | 89.74 ms | loss 0.00193 | ppl     1.00\n",
      "| epoch 171 |     8/    8 batches | lr 0.000032 | 89.68 ms | loss 0.00193 | ppl     1.00\n",
      "| epoch 172 |     8/    8 batches | lr 0.000031 | 89.37 ms | loss 0.00192 | ppl     1.00\n",
      "| epoch 173 |     8/    8 batches | lr 0.000030 | 90.73 ms | loss 0.00192 | ppl     1.00\n",
      "| epoch 174 |     8/    8 batches | lr 0.000030 | 89.36 ms | loss 0.00192 | ppl     1.00\n",
      "| epoch 175 |     8/    8 batches | lr 0.000029 | 89.35 ms | loss 0.00192 | ppl     1.00\n",
      "| epoch 176 |     8/    8 batches | lr 0.000029 | 89.48 ms | loss 0.00191 | ppl     1.00\n",
      "| epoch 177 |     8/    8 batches | lr 0.000028 | 89.33 ms | loss 0.00191 | ppl     1.00\n",
      "| epoch 178 |     8/    8 batches | lr 0.000027 | 89.82 ms | loss 0.00191 | ppl     1.00\n",
      "| epoch 179 |     8/    8 batches | lr 0.000027 | 90.11 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 180 |     8/    8 batches | lr 0.000026 | 89.05 ms | loss 0.00191 | ppl     1.00\n",
      "| epoch 181 |     8/    8 batches | lr 0.000026 | 87.39 ms | loss 0.00191 | ppl     1.00\n",
      "| epoch 182 |     8/    8 batches | lr 0.000025 | 89.34 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 183 |     8/    8 batches | lr 0.000025 | 87.81 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 184 |     8/    8 batches | lr 0.000024 | 88.92 ms | loss 0.00190 | ppl     1.00\n",
      "| epoch 185 |     8/    8 batches | lr 0.000024 | 88.68 ms | loss 0.00189 | ppl     1.00\n",
      "| epoch 186 |     8/    8 batches | lr 0.000023 | 90.83 ms | loss 0.00189 | ppl     1.00\n",
      "| epoch 187 |     8/    8 batches | lr 0.000023 | 92.88 ms | loss 0.00189 | ppl     1.00\n",
      "| epoch 188 |     8/    8 batches | lr 0.000022 | 90.95 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 189 |     8/    8 batches | lr 0.000022 | 89.60 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 190 |     8/    8 batches | lr 0.000022 | 89.64 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 191 |     8/    8 batches | lr 0.000021 | 91.90 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 192 |     8/    8 batches | lr 0.000021 | 90.61 ms | loss 0.00189 | ppl     1.00\n",
      "| epoch 193 |     8/    8 batches | lr 0.000020 | 89.66 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 194 |     8/    8 batches | lr 0.000020 | 89.45 ms | loss 0.00188 | ppl     1.00\n",
      "| epoch 195 |     8/    8 batches | lr 0.000019 | 90.25 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 196 |     8/    8 batches | lr 0.000019 | 90.01 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 197 |     8/    8 batches | lr 0.000019 | 89.47 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 198 |     8/    8 batches | lr 0.000018 | 90.53 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 199 |     8/    8 batches | lr 0.000018 | 89.52 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 200 |     8/    8 batches | lr 0.000018 | 100.36 ms | loss 0.00187 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 200 | time:  1.14s | valid loss 0.00296 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 201 |     8/    8 batches | lr 0.000017 | 87.81 ms | loss 0.00187 | ppl     1.00\n",
      "| epoch 202 |     8/    8 batches | lr 0.000017 | 87.63 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 203 |     8/    8 batches | lr 0.000017 | 87.49 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 204 |     8/    8 batches | lr 0.000016 | 87.54 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 205 |     8/    8 batches | lr 0.000016 | 87.47 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 206 |     8/    8 batches | lr 0.000016 | 87.36 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 207 |     8/    8 batches | lr 0.000015 | 87.26 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 208 |     8/    8 batches | lr 0.000015 | 87.36 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 209 |     8/    8 batches | lr 0.000015 | 87.55 ms | loss 0.00186 | ppl     1.00\n",
      "| epoch 210 |     8/    8 batches | lr 0.000014 | 87.26 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 211 |     8/    8 batches | lr 0.000014 | 87.11 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 212 |     8/    8 batches | lr 0.000014 | 87.15 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 213 |     8/    8 batches | lr 0.000014 | 87.34 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 214 |     8/    8 batches | lr 0.000013 | 87.37 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 215 |     8/    8 batches | lr 0.000013 | 87.23 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 216 |     8/    8 batches | lr 0.000013 | 87.50 ms | loss 0.00185 | ppl     1.00\n",
      "| epoch 217 |     8/    8 batches | lr 0.000012 | 87.23 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 218 |     8/    8 batches | lr 0.000012 | 87.51 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 219 |     8/    8 batches | lr 0.000012 | 87.18 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 220 |     8/    8 batches | lr 0.000012 | 87.18 ms | loss 0.00183 | ppl     1.00\n",
      "| epoch 221 |     8/    8 batches | lr 0.000012 | 87.25 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 222 |     8/    8 batches | lr 0.000011 | 87.39 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 223 |     8/    8 batches | lr 0.000011 | 87.50 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 224 |     8/    8 batches | lr 0.000011 | 87.23 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 225 |     8/    8 batches | lr 0.000011 | 87.46 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 226 |     8/    8 batches | lr 0.000010 | 87.45 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 227 |     8/    8 batches | lr 0.000010 | 87.47 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 228 |     8/    8 batches | lr 0.000010 | 87.59 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 229 |     8/    8 batches | lr 0.000010 | 87.39 ms | loss 0.00183 | ppl     1.00\n",
      "| epoch 230 |     8/    8 batches | lr 0.000010 | 88.67 ms | loss 0.00184 | ppl     1.00\n",
      "| epoch 231 |     8/    8 batches | lr 0.000009 | 89.33 ms | loss 0.00182 | ppl     1.00\n",
      "| epoch 232 |     8/    8 batches | lr 0.000009 | 89.64 ms | loss 0.00183 | ppl     1.00\n",
      "| epoch 233 |     8/    8 batches | lr 0.000009 | 90.82 ms | loss 0.00182 | ppl     1.00\n",
      "| epoch 234 |     8/    8 batches | lr 0.000009 | 89.79 ms | loss 0.00182 | ppl     1.00\n",
      "| epoch 235 |     8/    8 batches | lr 0.000009 | 90.42 ms | loss 0.00182 | ppl     1.00\n",
      "| epoch 236 |     8/    8 batches | lr 0.000008 | 90.56 ms | loss 0.00182 | ppl     1.00\n",
      "| epoch 237 |     8/    8 batches | lr 0.000008 | 90.61 ms | loss 0.00183 | ppl     1.00\n",
      "| epoch 238 |     8/    8 batches | lr 0.000008 | 90.23 ms | loss 0.00182 | ppl     1.00\n",
      "| epoch 239 |     8/    8 batches | lr 0.000008 | 89.84 ms | loss 0.00182 | ppl     1.00\n",
      "| epoch 240 |     8/    8 batches | lr 0.000008 | 89.80 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 241 |     8/    8 batches | lr 0.000008 | 89.74 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 242 |     8/    8 batches | lr 0.000008 | 89.61 ms | loss 0.00182 | ppl     1.00\n",
      "| epoch 243 |     8/    8 batches | lr 0.000007 | 89.57 ms | loss 0.00182 | ppl     1.00\n",
      "| epoch 244 |     8/    8 batches | lr 0.000007 | 89.46 ms | loss 0.00182 | ppl     1.00\n",
      "| epoch 245 |     8/    8 batches | lr 0.000007 | 88.13 ms | loss 0.00182 | ppl     1.00\n",
      "| epoch 246 |     8/    8 batches | lr 0.000007 | 88.71 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 247 |     8/    8 batches | lr 0.000007 | 88.43 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 248 |     8/    8 batches | lr 0.000007 | 87.09 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 249 |     8/    8 batches | lr 0.000007 | 87.07 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 250 |     8/    8 batches | lr 0.000006 | 88.02 ms | loss 0.00181 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 250 | time:  0.72s | valid loss 0.00298 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 251 |     8/    8 batches | lr 0.000006 | 87.64 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 252 |     8/    8 batches | lr 0.000006 | 88.71 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 253 |     8/    8 batches | lr 0.000006 | 88.43 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 254 |     8/    8 batches | lr 0.000006 | 88.32 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 255 |     8/    8 batches | lr 0.000006 | 89.73 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 256 |     8/    8 batches | lr 0.000006 | 87.67 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 257 |     8/    8 batches | lr 0.000006 | 87.73 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 258 |     8/    8 batches | lr 0.000005 | 87.89 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 259 |     8/    8 batches | lr 0.000005 | 89.37 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 260 |     8/    8 batches | lr 0.000005 | 87.83 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 261 |     8/    8 batches | lr 0.000005 | 87.28 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 262 |     8/    8 batches | lr 0.000005 | 87.77 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 263 |     8/    8 batches | lr 0.000005 | 87.35 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 264 |     8/    8 batches | lr 0.000005 | 87.72 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 265 |     8/    8 batches | lr 0.000005 | 90.39 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 266 |     8/    8 batches | lr 0.000005 | 89.68 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 267 |     8/    8 batches | lr 0.000005 | 89.58 ms | loss 0.00181 | ppl     1.00\n",
      "| epoch 268 |     8/    8 batches | lr 0.000004 | 89.61 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 269 |     8/    8 batches | lr 0.000004 | 89.99 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 270 |     8/    8 batches | lr 0.000004 | 89.88 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 271 |     8/    8 batches | lr 0.000004 | 89.72 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 272 |     8/    8 batches | lr 0.000004 | 89.42 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 273 |     8/    8 batches | lr 0.000004 | 89.61 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 274 |     8/    8 batches | lr 0.000004 | 89.71 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 275 |     8/    8 batches | lr 0.000004 | 89.38 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 276 |     8/    8 batches | lr 0.000004 | 89.57 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 277 |     8/    8 batches | lr 0.000004 | 89.57 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 278 |     8/    8 batches | lr 0.000004 | 89.68 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 279 |     8/    8 batches | lr 0.000004 | 89.37 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 280 |     8/    8 batches | lr 0.000003 | 89.86 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 281 |     8/    8 batches | lr 0.000003 | 89.70 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 282 |     8/    8 batches | lr 0.000003 | 89.42 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 283 |     8/    8 batches | lr 0.000003 | 89.88 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 284 |     8/    8 batches | lr 0.000003 | 89.85 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 285 |     8/    8 batches | lr 0.000003 | 89.56 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 286 |     8/    8 batches | lr 0.000003 | 89.75 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 287 |     8/    8 batches | lr 0.000003 | 89.93 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 288 |     8/    8 batches | lr 0.000003 | 89.59 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 289 |     8/    8 batches | lr 0.000003 | 89.55 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 290 |     8/    8 batches | lr 0.000003 | 89.70 ms | loss 0.00180 | ppl     1.00\n",
      "| epoch 291 |     8/    8 batches | lr 0.000003 | 89.45 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 292 |     8/    8 batches | lr 0.000003 | 89.39 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 293 |     8/    8 batches | lr 0.000003 | 89.77 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 294 |     8/    8 batches | lr 0.000003 | 89.69 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 295 |     8/    8 batches | lr 0.000003 | 89.75 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 296 |     8/    8 batches | lr 0.000003 | 89.44 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 297 |     8/    8 batches | lr 0.000002 | 89.41 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 298 |     8/    8 batches | lr 0.000002 | 89.74 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 299 |     8/    8 batches | lr 0.000002 | 89.65 ms | loss 0.00179 | ppl     1.00\n",
      "| epoch 300 |     8/    8 batches | lr 0.000002 | 89.57 ms | loss 0.00179 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 300 | time:  1.06s | valid loss 0.00301 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tools\\anaconda3\\envs\\data\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:381: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     8/    8 batches | lr 0.001000 | 89.47 ms | loss 28.31386 | ppl 1979485998565.38\n",
      "| epoch   2 |     8/    8 batches | lr 0.000960 | 100.44 ms | loss 5.50485 | ppl   245.88\n",
      "| epoch   3 |     8/    8 batches | lr 0.000941 | 91.82 ms | loss 1.38073 | ppl     3.98\n",
      "| epoch   4 |     8/    8 batches | lr 0.000922 | 90.90 ms | loss 0.48929 | ppl     1.63\n",
      "| epoch   5 |     8/    8 batches | lr 0.000904 | 90.46 ms | loss 0.15500 | ppl     1.17\n",
      "| epoch   6 |     8/    8 batches | lr 0.000886 | 90.14 ms | loss 0.08348 | ppl     1.09\n",
      "| epoch   7 |     8/    8 batches | lr 0.000868 | 90.59 ms | loss 0.03604 | ppl     1.04\n",
      "| epoch   8 |     8/    8 batches | lr 0.000851 | 91.63 ms | loss 0.02714 | ppl     1.03\n",
      "| epoch   9 |     8/    8 batches | lr 0.000834 | 91.37 ms | loss 0.03488 | ppl     1.04\n",
      "| epoch  10 |     8/    8 batches | lr 0.000817 | 90.87 ms | loss 0.03718 | ppl     1.04\n",
      "| epoch  11 |     8/    8 batches | lr 0.000801 | 90.13 ms | loss 0.25166 | ppl     1.29\n",
      "| epoch  12 |     8/    8 batches | lr 0.000785 | 89.41 ms | loss 0.09774 | ppl     1.10\n",
      "| epoch  13 |     8/    8 batches | lr 0.000769 | 91.75 ms | loss 0.19732 | ppl     1.22\n",
      "| epoch  14 |     8/    8 batches | lr 0.000754 | 91.01 ms | loss 0.09216 | ppl     1.10\n",
      "| epoch  15 |     8/    8 batches | lr 0.000739 | 91.02 ms | loss 0.01236 | ppl     1.01\n",
      "| epoch  16 |     8/    8 batches | lr 0.000724 | 90.28 ms | loss 0.02530 | ppl     1.03\n",
      "| epoch  17 |     8/    8 batches | lr 0.000709 | 89.52 ms | loss 0.02015 | ppl     1.02\n",
      "| epoch  18 |     8/    8 batches | lr 0.000695 | 91.38 ms | loss 0.01647 | ppl     1.02\n",
      "| epoch  19 |     8/    8 batches | lr 0.000681 | 91.25 ms | loss 0.02067 | ppl     1.02\n",
      "| epoch  20 |     8/    8 batches | lr 0.000668 | 90.99 ms | loss 0.01059 | ppl     1.01\n",
      "| epoch  21 |     8/    8 batches | lr 0.000654 | 90.61 ms | loss 0.01192 | ppl     1.01\n",
      "| epoch  22 |     8/    8 batches | lr 0.000641 | 90.13 ms | loss 0.05567 | ppl     1.06\n",
      "| epoch  23 |     8/    8 batches | lr 0.000628 | 89.85 ms | loss 0.06771 | ppl     1.07\n",
      "| epoch  24 |     8/    8 batches | lr 0.000616 | 91.74 ms | loss 0.05423 | ppl     1.06\n",
      "| epoch  25 |     8/    8 batches | lr 0.000603 | 91.62 ms | loss 0.08960 | ppl     1.09\n",
      "| epoch  26 |     8/    8 batches | lr 0.000591 | 90.84 ms | loss 0.08755 | ppl     1.09\n",
      "| epoch  27 |     8/    8 batches | lr 0.000580 | 90.20 ms | loss 0.01939 | ppl     1.02\n",
      "| epoch  28 |     8/    8 batches | lr 0.000568 | 89.60 ms | loss 0.00981 | ppl     1.01\n",
      "| epoch  29 |     8/    8 batches | lr 0.000557 | 91.76 ms | loss 0.02150 | ppl     1.02\n",
      "| epoch  30 |     8/    8 batches | lr 0.000545 | 91.23 ms | loss 0.05068 | ppl     1.05\n",
      "| epoch  31 |     8/    8 batches | lr 0.000535 | 91.55 ms | loss 0.09563 | ppl     1.10\n",
      "| epoch  32 |     8/    8 batches | lr 0.000524 | 90.06 ms | loss 0.04353 | ppl     1.04\n",
      "| epoch  33 |     8/    8 batches | lr 0.000513 | 89.78 ms | loss 0.09694 | ppl     1.10\n",
      "| epoch  34 |     8/    8 batches | lr 0.000503 | 91.92 ms | loss 0.11902 | ppl     1.13\n",
      "| epoch  35 |     8/    8 batches | lr 0.000493 | 91.70 ms | loss 0.01846 | ppl     1.02\n",
      "| epoch  36 |     8/    8 batches | lr 0.000483 | 90.93 ms | loss 0.00855 | ppl     1.01\n",
      "| epoch  37 |     8/    8 batches | lr 0.000474 | 90.89 ms | loss 0.01394 | ppl     1.01\n",
      "| epoch  38 |     8/    8 batches | lr 0.000464 | 91.25 ms | loss 0.00697 | ppl     1.01\n",
      "| epoch  39 |     8/    8 batches | lr 0.000455 | 89.86 ms | loss 0.02594 | ppl     1.03\n",
      "| epoch  40 |     8/    8 batches | lr 0.000446 | 91.87 ms | loss 0.03007 | ppl     1.03\n",
      "| epoch  41 |     8/    8 batches | lr 0.000437 | 91.39 ms | loss 0.01816 | ppl     1.02\n",
      "| epoch  42 |     8/    8 batches | lr 0.000428 | 90.52 ms | loss 0.05920 | ppl     1.06\n",
      "| epoch  43 |     8/    8 batches | lr 0.000419 | 90.13 ms | loss 0.04101 | ppl     1.04\n",
      "| epoch  44 |     8/    8 batches | lr 0.000411 | 89.33 ms | loss 0.00733 | ppl     1.01\n",
      "| epoch  45 |     8/    8 batches | lr 0.000403 | 92.07 ms | loss 0.02169 | ppl     1.02\n",
      "| epoch  46 |     8/    8 batches | lr 0.000395 | 91.50 ms | loss 0.02033 | ppl     1.02\n",
      "| epoch  47 |     8/    8 batches | lr 0.000387 | 91.00 ms | loss 0.03337 | ppl     1.03\n",
      "| epoch  48 |     8/    8 batches | lr 0.000379 | 90.06 ms | loss 0.02996 | ppl     1.03\n",
      "| epoch  49 |     8/    8 batches | lr 0.000372 | 89.79 ms | loss 0.01062 | ppl     1.01\n",
      "| epoch  50 |     8/    8 batches | lr 0.000364 | 92.11 ms | loss 0.01290 | ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time:  0.76s | valid loss 0.00396 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  51 |     8/    8 batches | lr 0.000357 | 91.45 ms | loss 0.01751 | ppl     1.02\n",
      "| epoch  52 |     8/    8 batches | lr 0.000350 | 91.09 ms | loss 0.01099 | ppl     1.01\n",
      "| epoch  53 |     8/    8 batches | lr 0.000343 | 90.36 ms | loss 0.03913 | ppl     1.04\n",
      "| epoch  54 |     8/    8 batches | lr 0.000336 | 89.77 ms | loss 0.05823 | ppl     1.06\n",
      "| epoch  55 |     8/    8 batches | lr 0.000329 | 89.58 ms | loss 0.00883 | ppl     1.01\n",
      "| epoch  56 |     8/    8 batches | lr 0.000323 | 92.01 ms | loss 0.00492 | ppl     1.00\n",
      "| epoch  57 |     8/    8 batches | lr 0.000316 | 91.35 ms | loss 0.00873 | ppl     1.01\n",
      "| epoch  58 |     8/    8 batches | lr 0.000310 | 90.44 ms | loss 0.00815 | ppl     1.01\n",
      "| epoch  59 |     8/    8 batches | lr 0.000304 | 90.17 ms | loss 0.02711 | ppl     1.03\n",
      "| epoch  60 |     8/    8 batches | lr 0.000298 | 89.83 ms | loss 0.01218 | ppl     1.01\n",
      "| epoch  61 |     8/    8 batches | lr 0.000292 | 91.98 ms | loss 0.01205 | ppl     1.01\n",
      "| epoch  62 |     8/    8 batches | lr 0.000286 | 91.53 ms | loss 0.00771 | ppl     1.01\n",
      "| epoch  63 |     8/    8 batches | lr 0.000280 | 91.04 ms | loss 0.00983 | ppl     1.01\n",
      "| epoch  64 |     8/    8 batches | lr 0.000274 | 90.07 ms | loss 0.01304 | ppl     1.01\n",
      "| epoch  65 |     8/    8 batches | lr 0.000269 | 91.48 ms | loss 0.00883 | ppl     1.01\n",
      "| epoch  66 |     8/    8 batches | lr 0.000264 | 90.82 ms | loss 0.02083 | ppl     1.02\n",
      "| epoch  67 |     8/    8 batches | lr 0.000258 | 91.83 ms | loss 0.01161 | ppl     1.01\n",
      "| epoch  68 |     8/    8 batches | lr 0.000253 | 91.41 ms | loss 0.00510 | ppl     1.01\n",
      "| epoch  69 |     8/    8 batches | lr 0.000248 | 91.81 ms | loss 0.00965 | ppl     1.01\n",
      "| epoch  70 |     8/    8 batches | lr 0.000243 | 90.39 ms | loss 0.01074 | ppl     1.01\n",
      "| epoch  71 |     8/    8 batches | lr 0.000238 | 91.45 ms | loss 0.00801 | ppl     1.01\n",
      "| epoch  72 |     8/    8 batches | lr 0.000233 | 92.28 ms | loss 0.01120 | ppl     1.01\n",
      "| epoch  73 |     8/    8 batches | lr 0.000229 | 91.29 ms | loss 0.01303 | ppl     1.01\n",
      "| epoch  74 |     8/    8 batches | lr 0.000224 | 90.61 ms | loss 0.00471 | ppl     1.00\n",
      "| epoch  75 |     8/    8 batches | lr 0.000220 | 90.08 ms | loss 0.00617 | ppl     1.01\n",
      "| epoch  76 |     8/    8 batches | lr 0.000215 | 89.48 ms | loss 0.00809 | ppl     1.01\n",
      "| epoch  77 |     8/    8 batches | lr 0.000211 | 91.24 ms | loss 0.00827 | ppl     1.01\n",
      "| epoch  78 |     8/    8 batches | lr 0.000207 | 91.46 ms | loss 0.01189 | ppl     1.01\n",
      "| epoch  79 |     8/    8 batches | lr 0.000203 | 90.69 ms | loss 0.00944 | ppl     1.01\n",
      "| epoch  80 |     8/    8 batches | lr 0.000199 | 89.88 ms | loss 0.00415 | ppl     1.00\n",
      "| epoch  81 |     8/    8 batches | lr 0.000195 | 89.68 ms | loss 0.00577 | ppl     1.01\n",
      "| epoch  82 |     8/    8 batches | lr 0.000191 | 90.45 ms | loss 0.00766 | ppl     1.01\n",
      "| epoch  83 |     8/    8 batches | lr 0.000187 | 91.42 ms | loss 0.00711 | ppl     1.01\n",
      "| epoch  84 |     8/    8 batches | lr 0.000183 | 91.11 ms | loss 0.00998 | ppl     1.01\n",
      "| epoch  85 |     8/    8 batches | lr 0.000180 | 90.53 ms | loss 0.01023 | ppl     1.01\n",
      "| epoch  86 |     8/    8 batches | lr 0.000176 | 89.82 ms | loss 0.00854 | ppl     1.01\n",
      "| epoch  87 |     8/    8 batches | lr 0.000172 | 89.15 ms | loss 0.00483 | ppl     1.00\n",
      "| epoch  88 |     8/    8 batches | lr 0.000169 | 91.88 ms | loss 0.00443 | ppl     1.00\n",
      "| epoch  89 |     8/    8 batches | lr 0.000166 | 91.19 ms | loss 0.00717 | ppl     1.01\n",
      "| epoch  90 |     8/    8 batches | lr 0.000162 | 90.57 ms | loss 0.00802 | ppl     1.01\n",
      "| epoch  91 |     8/    8 batches | lr 0.000159 | 90.24 ms | loss 0.00425 | ppl     1.00\n",
      "| epoch  92 |     8/    8 batches | lr 0.000156 | 89.84 ms | loss 0.00411 | ppl     1.00\n",
      "| epoch  93 |     8/    8 batches | lr 0.000153 | 91.65 ms | loss 0.00617 | ppl     1.01\n",
      "| epoch  94 |     8/    8 batches | lr 0.000150 | 91.71 ms | loss 0.00535 | ppl     1.01\n",
      "| epoch  95 |     8/    8 batches | lr 0.000147 | 90.56 ms | loss 0.00615 | ppl     1.01\n",
      "| epoch  96 |     8/    8 batches | lr 0.000144 | 90.29 ms | loss 0.00631 | ppl     1.01\n",
      "| epoch  97 |     8/    8 batches | lr 0.000141 | 89.78 ms | loss 0.00330 | ppl     1.00\n",
      "| epoch  98 |     8/    8 batches | lr 0.000138 | 90.81 ms | loss 0.00369 | ppl     1.00\n",
      "| epoch  99 |     8/    8 batches | lr 0.000135 | 91.69 ms | loss 0.00518 | ppl     1.01\n",
      "| epoch 100 |     8/    8 batches | lr 0.000133 | 91.07 ms | loss 0.00447 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time:  1.08s | valid loss 0.00382 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 101 |     8/    8 batches | lr 0.000130 | 90.11 ms | loss 0.00507 | ppl     1.01\n",
      "| epoch 102 |     8/    8 batches | lr 0.000127 | 91.75 ms | loss 0.00638 | ppl     1.01\n",
      "| epoch 103 |     8/    8 batches | lr 0.000125 | 90.67 ms | loss 0.00368 | ppl     1.00\n",
      "| epoch 104 |     8/    8 batches | lr 0.000122 | 91.87 ms | loss 0.00321 | ppl     1.00\n",
      "| epoch 105 |     8/    8 batches | lr 0.000120 | 91.40 ms | loss 0.00384 | ppl     1.00\n",
      "| epoch 106 |     8/    8 batches | lr 0.000117 | 91.25 ms | loss 0.00423 | ppl     1.00\n",
      "| epoch 107 |     8/    8 batches | lr 0.000115 | 89.99 ms | loss 0.00392 | ppl     1.00\n",
      "| epoch 108 |     8/    8 batches | lr 0.000113 | 89.52 ms | loss 0.00463 | ppl     1.00\n",
      "| epoch 109 |     8/    8 batches | lr 0.000111 | 92.59 ms | loss 0.00332 | ppl     1.00\n",
      "| epoch 110 |     8/    8 batches | lr 0.000108 | 91.85 ms | loss 0.00330 | ppl     1.00\n",
      "| epoch 111 |     8/    8 batches | lr 0.000106 | 91.42 ms | loss 0.00457 | ppl     1.00\n",
      "| epoch 112 |     8/    8 batches | lr 0.000104 | 90.93 ms | loss 0.00361 | ppl     1.00\n",
      "| epoch 113 |     8/    8 batches | lr 0.000102 | 90.52 ms | loss 0.00369 | ppl     1.00\n",
      "| epoch 114 |     8/    8 batches | lr 0.000100 | 90.18 ms | loss 0.00440 | ppl     1.00\n",
      "| epoch 115 |     8/    8 batches | lr 0.000098 | 101.72 ms | loss 0.00297 | ppl     1.00\n",
      "| epoch 116 |     8/    8 batches | lr 0.000096 | 90.89 ms | loss 0.00284 | ppl     1.00\n",
      "| epoch 117 |     8/    8 batches | lr 0.000094 | 90.72 ms | loss 0.00358 | ppl     1.00\n",
      "| epoch 118 |     8/    8 batches | lr 0.000092 | 90.04 ms | loss 0.00362 | ppl     1.00\n",
      "| epoch 119 |     8/    8 batches | lr 0.000090 | 91.08 ms | loss 0.00344 | ppl     1.00\n",
      "| epoch 120 |     8/    8 batches | lr 0.000089 | 88.78 ms | loss 0.00388 | ppl     1.00\n",
      "| epoch 121 |     8/    8 batches | lr 0.000087 | 89.00 ms | loss 0.00281 | ppl     1.00\n",
      "| epoch 122 |     8/    8 batches | lr 0.000085 | 89.17 ms | loss 0.00272 | ppl     1.00\n",
      "| epoch 123 |     8/    8 batches | lr 0.000083 | 89.61 ms | loss 0.00335 | ppl     1.00\n",
      "| epoch 124 |     8/    8 batches | lr 0.000082 | 88.84 ms | loss 0.00300 | ppl     1.00\n",
      "| epoch 125 |     8/    8 batches | lr 0.000080 | 91.25 ms | loss 0.00295 | ppl     1.00\n",
      "| epoch 126 |     8/    8 batches | lr 0.000078 | 90.71 ms | loss 0.00366 | ppl     1.00\n",
      "| epoch 127 |     8/    8 batches | lr 0.000077 | 90.16 ms | loss 0.00285 | ppl     1.00\n",
      "| epoch 128 |     8/    8 batches | lr 0.000075 | 91.23 ms | loss 0.00257 | ppl     1.00\n",
      "| epoch 129 |     8/    8 batches | lr 0.000074 | 88.99 ms | loss 0.00301 | ppl     1.00\n",
      "| epoch 130 |     8/    8 batches | lr 0.000072 | 89.89 ms | loss 0.00270 | ppl     1.00\n",
      "| epoch 131 |     8/    8 batches | lr 0.000071 | 89.24 ms | loss 0.00264 | ppl     1.00\n",
      "| epoch 132 |     8/    8 batches | lr 0.000069 | 89.22 ms | loss 0.00312 | ppl     1.00\n",
      "| epoch 133 |     8/    8 batches | lr 0.000068 | 89.23 ms | loss 0.00265 | ppl     1.00\n",
      "| epoch 134 |     8/    8 batches | lr 0.000067 | 89.72 ms | loss 0.00249 | ppl     1.00\n",
      "| epoch 135 |     8/    8 batches | lr 0.000065 | 91.20 ms | loss 0.00280 | ppl     1.00\n",
      "| epoch 136 |     8/    8 batches | lr 0.000064 | 88.71 ms | loss 0.00255 | ppl     1.00\n",
      "| epoch 137 |     8/    8 batches | lr 0.000063 | 89.41 ms | loss 0.00244 | ppl     1.00\n",
      "| epoch 138 |     8/    8 batches | lr 0.000062 | 91.25 ms | loss 0.00266 | ppl     1.00\n",
      "| epoch 139 |     8/    8 batches | lr 0.000060 | 91.14 ms | loss 0.00249 | ppl     1.00\n",
      "| epoch 140 |     8/    8 batches | lr 0.000059 | 88.97 ms | loss 0.00241 | ppl     1.00\n",
      "| epoch 141 |     8/    8 batches | lr 0.000058 | 88.87 ms | loss 0.00248 | ppl     1.00\n",
      "| epoch 142 |     8/    8 batches | lr 0.000057 | 89.81 ms | loss 0.00242 | ppl     1.00\n",
      "| epoch 143 |     8/    8 batches | lr 0.000056 | 91.24 ms | loss 0.00237 | ppl     1.00\n",
      "| epoch 144 |     8/    8 batches | lr 0.000055 | 90.76 ms | loss 0.00236 | ppl     1.00\n",
      "| epoch 145 |     8/    8 batches | lr 0.000053 | 89.80 ms | loss 0.00231 | ppl     1.00\n",
      "| epoch 146 |     8/    8 batches | lr 0.000052 | 88.95 ms | loss 0.00235 | ppl     1.00\n",
      "| epoch 147 |     8/    8 batches | lr 0.000051 | 88.93 ms | loss 0.00230 | ppl     1.00\n",
      "| epoch 148 |     8/    8 batches | lr 0.000050 | 88.84 ms | loss 0.00225 | ppl     1.00\n",
      "| epoch 149 |     8/    8 batches | lr 0.000049 | 88.73 ms | loss 0.00229 | ppl     1.00\n",
      "| epoch 150 |     8/    8 batches | lr 0.000048 | 89.12 ms | loss 0.00224 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 150 | time:  0.73s | valid loss 0.00277 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 151 |     8/    8 batches | lr 0.000047 | 88.92 ms | loss 0.00223 | ppl     1.00\n",
      "| epoch 152 |     8/    8 batches | lr 0.000046 | 88.91 ms | loss 0.00223 | ppl     1.00\n",
      "| epoch 153 |     8/    8 batches | lr 0.000045 | 89.30 ms | loss 0.00222 | ppl     1.00\n",
      "| epoch 154 |     8/    8 batches | lr 0.000045 | 89.12 ms | loss 0.00221 | ppl     1.00\n",
      "| epoch 155 |     8/    8 batches | lr 0.000044 | 89.93 ms | loss 0.00219 | ppl     1.00\n",
      "| epoch 156 |     8/    8 batches | lr 0.000043 | 90.72 ms | loss 0.00218 | ppl     1.00\n",
      "| epoch 157 |     8/    8 batches | lr 0.000042 | 90.85 ms | loss 0.00219 | ppl     1.00\n",
      "| epoch 158 |     8/    8 batches | lr 0.000041 | 88.87 ms | loss 0.00218 | ppl     1.00\n",
      "| epoch 159 |     8/    8 batches | lr 0.000040 | 90.52 ms | loss 0.00218 | ppl     1.00\n",
      "| epoch 160 |     8/    8 batches | lr 0.000039 | 90.47 ms | loss 0.00217 | ppl     1.00\n",
      "| epoch 161 |     8/    8 batches | lr 0.000039 | 89.12 ms | loss 0.00218 | ppl     1.00\n",
      "| epoch 162 |     8/    8 batches | lr 0.000038 | 89.09 ms | loss 0.00216 | ppl     1.00\n",
      "| epoch 163 |     8/    8 batches | lr 0.000037 | 88.51 ms | loss 0.00217 | ppl     1.00\n",
      "| epoch 164 |     8/    8 batches | lr 0.000036 | 89.13 ms | loss 0.00216 | ppl     1.00\n",
      "| epoch 165 |     8/    8 batches | lr 0.000036 | 89.74 ms | loss 0.00215 | ppl     1.00\n",
      "| epoch 166 |     8/    8 batches | lr 0.000035 | 90.86 ms | loss 0.00215 | ppl     1.00\n",
      "| epoch 167 |     8/    8 batches | lr 0.000034 | 89.42 ms | loss 0.00214 | ppl     1.00\n",
      "| epoch 168 |     8/    8 batches | lr 0.000034 | 91.32 ms | loss 0.00214 | ppl     1.00\n",
      "| epoch 169 |     8/    8 batches | lr 0.000033 | 89.87 ms | loss 0.00215 | ppl     1.00\n",
      "| epoch 170 |     8/    8 batches | lr 0.000032 | 89.10 ms | loss 0.00213 | ppl     1.00\n",
      "| epoch 171 |     8/    8 batches | lr 0.000032 | 88.51 ms | loss 0.00213 | ppl     1.00\n",
      "| epoch 172 |     8/    8 batches | lr 0.000031 | 88.92 ms | loss 0.00213 | ppl     1.00\n",
      "| epoch 173 |     8/    8 batches | lr 0.000030 | 88.96 ms | loss 0.00212 | ppl     1.00\n",
      "| epoch 174 |     8/    8 batches | lr 0.000030 | 89.06 ms | loss 0.00212 | ppl     1.00\n",
      "| epoch 175 |     8/    8 batches | lr 0.000029 | 88.83 ms | loss 0.00211 | ppl     1.00\n",
      "| epoch 176 |     8/    8 batches | lr 0.000029 | 89.21 ms | loss 0.00211 | ppl     1.00\n",
      "| epoch 177 |     8/    8 batches | lr 0.000028 | 89.25 ms | loss 0.00211 | ppl     1.00\n",
      "| epoch 178 |     8/    8 batches | lr 0.000027 | 89.75 ms | loss 0.00211 | ppl     1.00\n",
      "| epoch 179 |     8/    8 batches | lr 0.000027 | 89.00 ms | loss 0.00210 | ppl     1.00\n",
      "| epoch 180 |     8/    8 batches | lr 0.000026 | 88.88 ms | loss 0.00210 | ppl     1.00\n",
      "| epoch 181 |     8/    8 batches | lr 0.000026 | 88.99 ms | loss 0.00210 | ppl     1.00\n",
      "| epoch 182 |     8/    8 batches | lr 0.000025 | 89.05 ms | loss 0.00210 | ppl     1.00\n",
      "| epoch 183 |     8/    8 batches | lr 0.000025 | 89.35 ms | loss 0.00209 | ppl     1.00\n",
      "| epoch 184 |     8/    8 batches | lr 0.000024 | 89.26 ms | loss 0.00209 | ppl     1.00\n",
      "| epoch 185 |     8/    8 batches | lr 0.000024 | 89.37 ms | loss 0.00208 | ppl     1.00\n",
      "| epoch 186 |     8/    8 batches | lr 0.000023 | 88.91 ms | loss 0.00209 | ppl     1.00\n",
      "| epoch 187 |     8/    8 batches | lr 0.000023 | 89.48 ms | loss 0.00208 | ppl     1.00\n",
      "| epoch 188 |     8/    8 batches | lr 0.000022 | 89.97 ms | loss 0.00207 | ppl     1.00\n",
      "| epoch 189 |     8/    8 batches | lr 0.000022 | 89.44 ms | loss 0.00208 | ppl     1.00\n",
      "| epoch 190 |     8/    8 batches | lr 0.000022 | 90.50 ms | loss 0.00208 | ppl     1.00\n",
      "| epoch 191 |     8/    8 batches | lr 0.000021 | 91.04 ms | loss 0.00208 | ppl     1.00\n",
      "| epoch 192 |     8/    8 batches | lr 0.000021 | 91.51 ms | loss 0.00206 | ppl     1.00\n",
      "| epoch 193 |     8/    8 batches | lr 0.000020 | 89.50 ms | loss 0.00206 | ppl     1.00\n",
      "| epoch 194 |     8/    8 batches | lr 0.000020 | 88.81 ms | loss 0.00207 | ppl     1.00\n",
      "| epoch 195 |     8/    8 batches | lr 0.000019 | 89.29 ms | loss 0.00206 | ppl     1.00\n",
      "| epoch 196 |     8/    8 batches | lr 0.000019 | 88.59 ms | loss 0.00206 | ppl     1.00\n",
      "| epoch 197 |     8/    8 batches | lr 0.000019 | 89.42 ms | loss 0.00206 | ppl     1.00\n",
      "| epoch 198 |     8/    8 batches | lr 0.000018 | 88.61 ms | loss 0.00205 | ppl     1.00\n",
      "| epoch 199 |     8/    8 batches | lr 0.000018 | 89.59 ms | loss 0.00205 | ppl     1.00\n",
      "| epoch 200 |     8/    8 batches | lr 0.000018 | 89.62 ms | loss 0.00205 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 200 | time:  1.06s | valid loss 0.00310 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 201 |     8/    8 batches | lr 0.000017 | 90.05 ms | loss 0.00205 | ppl     1.00\n",
      "| epoch 202 |     8/    8 batches | lr 0.000017 | 89.04 ms | loss 0.00205 | ppl     1.00\n",
      "| epoch 203 |     8/    8 batches | lr 0.000017 | 88.70 ms | loss 0.00204 | ppl     1.00\n",
      "| epoch 204 |     8/    8 batches | lr 0.000016 | 89.10 ms | loss 0.00204 | ppl     1.00\n",
      "| epoch 205 |     8/    8 batches | lr 0.000016 | 88.64 ms | loss 0.00204 | ppl     1.00\n",
      "| epoch 206 |     8/    8 batches | lr 0.000016 | 88.98 ms | loss 0.00204 | ppl     1.00\n",
      "| epoch 207 |     8/    8 batches | lr 0.000015 | 88.66 ms | loss 0.00204 | ppl     1.00\n",
      "| epoch 208 |     8/    8 batches | lr 0.000015 | 88.99 ms | loss 0.00204 | ppl     1.00\n",
      "| epoch 209 |     8/    8 batches | lr 0.000015 | 89.08 ms | loss 0.00204 | ppl     1.00\n",
      "| epoch 210 |     8/    8 batches | lr 0.000014 | 88.88 ms | loss 0.00203 | ppl     1.00\n",
      "| epoch 211 |     8/    8 batches | lr 0.000014 | 88.92 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 212 |     8/    8 batches | lr 0.000014 | 88.70 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 213 |     8/    8 batches | lr 0.000014 | 89.21 ms | loss 0.00203 | ppl     1.00\n",
      "| epoch 214 |     8/    8 batches | lr 0.000013 | 88.97 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 215 |     8/    8 batches | lr 0.000013 | 89.07 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 216 |     8/    8 batches | lr 0.000013 | 89.37 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 217 |     8/    8 batches | lr 0.000012 | 88.64 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 218 |     8/    8 batches | lr 0.000012 | 88.88 ms | loss 0.00201 | ppl     1.00\n",
      "| epoch 219 |     8/    8 batches | lr 0.000012 | 88.82 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 220 |     8/    8 batches | lr 0.000012 | 89.12 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 221 |     8/    8 batches | lr 0.000012 | 89.15 ms | loss 0.00201 | ppl     1.00\n",
      "| epoch 222 |     8/    8 batches | lr 0.000011 | 88.96 ms | loss 0.00202 | ppl     1.00\n",
      "| epoch 223 |     8/    8 batches | lr 0.000011 | 88.66 ms | loss 0.00201 | ppl     1.00\n",
      "| epoch 224 |     8/    8 batches | lr 0.000011 | 89.08 ms | loss 0.00201 | ppl     1.00\n",
      "| epoch 225 |     8/    8 batches | lr 0.000011 | 88.97 ms | loss 0.00201 | ppl     1.00\n",
      "| epoch 226 |     8/    8 batches | lr 0.000010 | 88.70 ms | loss 0.00200 | ppl     1.00\n",
      "| epoch 227 |     8/    8 batches | lr 0.000010 | 89.20 ms | loss 0.00201 | ppl     1.00\n",
      "| epoch 228 |     8/    8 batches | lr 0.000010 | 89.74 ms | loss 0.00201 | ppl     1.00\n",
      "| epoch 229 |     8/    8 batches | lr 0.000010 | 99.43 ms | loss 0.00200 | ppl     1.00\n",
      "| epoch 230 |     8/    8 batches | lr 0.000010 | 88.96 ms | loss 0.00200 | ppl     1.00\n",
      "| epoch 231 |     8/    8 batches | lr 0.000009 | 88.51 ms | loss 0.00200 | ppl     1.00\n",
      "| epoch 232 |     8/    8 batches | lr 0.000009 | 89.70 ms | loss 0.00200 | ppl     1.00\n",
      "| epoch 233 |     8/    8 batches | lr 0.000009 | 88.91 ms | loss 0.00200 | ppl     1.00\n",
      "| epoch 234 |     8/    8 batches | lr 0.000009 | 88.96 ms | loss 0.00200 | ppl     1.00\n",
      "| epoch 235 |     8/    8 batches | lr 0.000009 | 88.64 ms | loss 0.00199 | ppl     1.00\n",
      "| epoch 236 |     8/    8 batches | lr 0.000008 | 89.20 ms | loss 0.00200 | ppl     1.00\n",
      "| epoch 237 |     8/    8 batches | lr 0.000008 | 89.03 ms | loss 0.00199 | ppl     1.00\n",
      "| epoch 238 |     8/    8 batches | lr 0.000008 | 88.84 ms | loss 0.00199 | ppl     1.00\n",
      "| epoch 239 |     8/    8 batches | lr 0.000008 | 89.52 ms | loss 0.00199 | ppl     1.00\n",
      "| epoch 240 |     8/    8 batches | lr 0.000008 | 89.98 ms | loss 0.00199 | ppl     1.00\n",
      "| epoch 241 |     8/    8 batches | lr 0.000008 | 88.66 ms | loss 0.00199 | ppl     1.00\n",
      "| epoch 242 |     8/    8 batches | lr 0.000008 | 88.77 ms | loss 0.00199 | ppl     1.00\n",
      "| epoch 243 |     8/    8 batches | lr 0.000007 | 88.87 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 244 |     8/    8 batches | lr 0.000007 | 88.50 ms | loss 0.00199 | ppl     1.00\n",
      "| epoch 245 |     8/    8 batches | lr 0.000007 | 88.97 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 246 |     8/    8 batches | lr 0.000007 | 88.87 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 247 |     8/    8 batches | lr 0.000007 | 90.10 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 248 |     8/    8 batches | lr 0.000007 | 91.22 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 249 |     8/    8 batches | lr 0.000007 | 90.39 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 250 |     8/    8 batches | lr 0.000006 | 91.53 ms | loss 0.00199 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 250 | time:  0.75s | valid loss 0.00309 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 251 |     8/    8 batches | lr 0.000006 | 89.69 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 252 |     8/    8 batches | lr 0.000006 | 89.42 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 253 |     8/    8 batches | lr 0.000006 | 88.85 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 254 |     8/    8 batches | lr 0.000006 | 88.79 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 255 |     8/    8 batches | lr 0.000006 | 90.61 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 256 |     8/    8 batches | lr 0.000006 | 89.36 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 257 |     8/    8 batches | lr 0.000006 | 89.22 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 258 |     8/    8 batches | lr 0.000005 | 89.34 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 259 |     8/    8 batches | lr 0.000005 | 88.95 ms | loss 0.00198 | ppl     1.00\n",
      "| epoch 260 |     8/    8 batches | lr 0.000005 | 89.04 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 261 |     8/    8 batches | lr 0.000005 | 88.97 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 262 |     8/    8 batches | lr 0.000005 | 88.94 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 263 |     8/    8 batches | lr 0.000005 | 89.87 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 264 |     8/    8 batches | lr 0.000005 | 90.08 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 265 |     8/    8 batches | lr 0.000005 | 89.26 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 266 |     8/    8 batches | lr 0.000005 | 89.19 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 267 |     8/    8 batches | lr 0.000005 | 89.07 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 268 |     8/    8 batches | lr 0.000004 | 88.74 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 269 |     8/    8 batches | lr 0.000004 | 88.38 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 270 |     8/    8 batches | lr 0.000004 | 89.02 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 271 |     8/    8 batches | lr 0.000004 | 89.16 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 272 |     8/    8 batches | lr 0.000004 | 89.05 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 273 |     8/    8 batches | lr 0.000004 | 89.18 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 274 |     8/    8 batches | lr 0.000004 | 88.82 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 275 |     8/    8 batches | lr 0.000004 | 88.99 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 276 |     8/    8 batches | lr 0.000004 | 89.06 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 277 |     8/    8 batches | lr 0.000004 | 89.12 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 278 |     8/    8 batches | lr 0.000004 | 89.05 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 279 |     8/    8 batches | lr 0.000004 | 89.28 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 280 |     8/    8 batches | lr 0.000003 | 89.18 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 281 |     8/    8 batches | lr 0.000003 | 89.05 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 282 |     8/    8 batches | lr 0.000003 | 88.96 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 283 |     8/    8 batches | lr 0.000003 | 89.25 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 284 |     8/    8 batches | lr 0.000003 | 88.99 ms | loss 0.00197 | ppl     1.00\n",
      "| epoch 285 |     8/    8 batches | lr 0.000003 | 89.20 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 286 |     8/    8 batches | lr 0.000003 | 89.09 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 287 |     8/    8 batches | lr 0.000003 | 89.19 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 288 |     8/    8 batches | lr 0.000003 | 89.23 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 289 |     8/    8 batches | lr 0.000003 | 89.23 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 290 |     8/    8 batches | lr 0.000003 | 89.06 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 291 |     8/    8 batches | lr 0.000003 | 89.22 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 292 |     8/    8 batches | lr 0.000003 | 89.03 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 293 |     8/    8 batches | lr 0.000003 | 89.02 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 294 |     8/    8 batches | lr 0.000003 | 89.19 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 295 |     8/    8 batches | lr 0.000003 | 89.12 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 296 |     8/    8 batches | lr 0.000003 | 88.67 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 297 |     8/    8 batches | lr 0.000002 | 88.89 ms | loss 0.00196 | ppl     1.00\n",
      "| epoch 298 |     8/    8 batches | lr 0.000002 | 88.92 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 299 |     8/    8 batches | lr 0.000002 | 88.84 ms | loss 0.00195 | ppl     1.00\n",
      "| epoch 300 |     8/    8 batches | lr 0.000002 | 88.76 ms | loss 0.00194 | ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 300 | time:  1.06s | valid loss 0.00313 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tools\\anaconda3\\envs\\data\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:381: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     8/    8 batches | lr 0.001000 | 89.06 ms | loss 23.02655 | ppl 10006974454.62\n",
      "| epoch   2 |     8/    8 batches | lr 0.000960 | 89.43 ms | loss 0.95368 | ppl     2.60\n",
      "| epoch   3 |     8/    8 batches | lr 0.000941 | 89.28 ms | loss 0.37163 | ppl     1.45\n",
      "| epoch   4 |     8/    8 batches | lr 0.000922 | 89.07 ms | loss 0.09444 | ppl     1.10\n",
      "| epoch   5 |     8/    8 batches | lr 0.000904 | 89.08 ms | loss 0.26842 | ppl     1.31\n",
      "| epoch   6 |     8/    8 batches | lr 0.000886 | 89.09 ms | loss 0.13204 | ppl     1.14\n",
      "| epoch   7 |     8/    8 batches | lr 0.000868 | 89.18 ms | loss 0.15611 | ppl     1.17\n",
      "| epoch   8 |     8/    8 batches | lr 0.000851 | 89.08 ms | loss 0.12912 | ppl     1.14\n",
      "| epoch   9 |     8/    8 batches | lr 0.000834 | 89.04 ms | loss 0.06987 | ppl     1.07\n",
      "| epoch  10 |     8/    8 batches | lr 0.000817 | 88.93 ms | loss 0.13342 | ppl     1.14\n",
      "| epoch  11 |     8/    8 batches | lr 0.000801 | 88.87 ms | loss 0.11817 | ppl     1.13\n",
      "| epoch  12 |     8/    8 batches | lr 0.000785 | 89.18 ms | loss 0.12714 | ppl     1.14\n",
      "| epoch  13 |     8/    8 batches | lr 0.000769 | 89.33 ms | loss 0.11315 | ppl     1.12\n",
      "| epoch  14 |     8/    8 batches | lr 0.000754 | 89.00 ms | loss 0.03250 | ppl     1.03\n",
      "| epoch  15 |     8/    8 batches | lr 0.000739 | 89.23 ms | loss 0.01741 | ppl     1.02\n",
      "| epoch  16 |     8/    8 batches | lr 0.000724 | 89.18 ms | loss 0.02428 | ppl     1.02\n",
      "| epoch  17 |     8/    8 batches | lr 0.000709 | 89.36 ms | loss 0.02877 | ppl     1.03\n",
      "| epoch  18 |     8/    8 batches | lr 0.000695 | 89.29 ms | loss 0.02096 | ppl     1.02\n",
      "| epoch  19 |     8/    8 batches | lr 0.000681 | 89.08 ms | loss 0.05322 | ppl     1.05\n",
      "| epoch  20 |     8/    8 batches | lr 0.000668 | 89.92 ms | loss 0.04351 | ppl     1.04\n",
      "| epoch  21 |     8/    8 batches | lr 0.000654 | 89.11 ms | loss 0.02883 | ppl     1.03\n",
      "| epoch  22 |     8/    8 batches | lr 0.000641 | 89.17 ms | loss 0.02278 | ppl     1.02\n",
      "| epoch  23 |     8/    8 batches | lr 0.000628 | 89.23 ms | loss 0.01462 | ppl     1.01\n",
      "| epoch  24 |     8/    8 batches | lr 0.000616 | 89.13 ms | loss 0.01786 | ppl     1.02\n",
      "| epoch  25 |     8/    8 batches | lr 0.000603 | 89.27 ms | loss 0.02052 | ppl     1.02\n",
      "| epoch  26 |     8/    8 batches | lr 0.000591 | 89.13 ms | loss 0.01825 | ppl     1.02\n",
      "| epoch  27 |     8/    8 batches | lr 0.000580 | 88.94 ms | loss 0.04500 | ppl     1.05\n",
      "| epoch  28 |     8/    8 batches | lr 0.000568 | 89.14 ms | loss 0.14746 | ppl     1.16\n",
      "| epoch  29 |     8/    8 batches | lr 0.000557 | 89.23 ms | loss 0.08343 | ppl     1.09\n",
      "| epoch  30 |     8/    8 batches | lr 0.000545 | 90.58 ms | loss 0.05067 | ppl     1.05\n",
      "| epoch  31 |     8/    8 batches | lr 0.000535 | 89.19 ms | loss 0.03030 | ppl     1.03\n",
      "| epoch  32 |     8/    8 batches | lr 0.000524 | 89.18 ms | loss 0.01098 | ppl     1.01\n",
      "| epoch  33 |     8/    8 batches | lr 0.000513 | 89.09 ms | loss 0.02688 | ppl     1.03\n",
      "| epoch  34 |     8/    8 batches | lr 0.000503 | 89.03 ms | loss 0.02950 | ppl     1.03\n",
      "| epoch  35 |     8/    8 batches | lr 0.000493 | 88.93 ms | loss 0.06477 | ppl     1.07\n",
      "| epoch  36 |     8/    8 batches | lr 0.000483 | 88.89 ms | loss 0.06479 | ppl     1.07\n",
      "| epoch  37 |     8/    8 batches | lr 0.000474 | 89.08 ms | loss 0.02922 | ppl     1.03\n",
      "| epoch  38 |     8/    8 batches | lr 0.000464 | 88.92 ms | loss 0.08053 | ppl     1.08\n",
      "| epoch  39 |     8/    8 batches | lr 0.000455 | 89.16 ms | loss 0.04551 | ppl     1.05\n",
      "| epoch  40 |     8/    8 batches | lr 0.000446 | 88.90 ms | loss 0.02952 | ppl     1.03\n",
      "| epoch  41 |     8/    8 batches | lr 0.000437 | 89.00 ms | loss 0.01852 | ppl     1.02\n",
      "| epoch  42 |     8/    8 batches | lr 0.000428 | 89.48 ms | loss 0.00847 | ppl     1.01\n",
      "| epoch  43 |     8/    8 batches | lr 0.000419 | 88.78 ms | loss 0.01662 | ppl     1.02\n",
      "| epoch  44 |     8/    8 batches | lr 0.000411 | 89.07 ms | loss 0.00710 | ppl     1.01\n",
      "| epoch  45 |     8/    8 batches | lr 0.000403 | 97.98 ms | loss 0.02410 | ppl     1.02\n",
      "| epoch  46 |     8/    8 batches | lr 0.000395 | 88.91 ms | loss 0.04259 | ppl     1.04\n",
      "| epoch  47 |     8/    8 batches | lr 0.000387 | 88.90 ms | loss 0.00507 | ppl     1.01\n",
      "| epoch  48 |     8/    8 batches | lr 0.000379 | 89.22 ms | loss 0.00540 | ppl     1.01\n",
      "| epoch  49 |     8/    8 batches | lr 0.000372 | 88.90 ms | loss 0.00699 | ppl     1.01\n",
      "| epoch  50 |     8/    8 batches | lr 0.000364 | 89.01 ms | loss 0.01167 | ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time:  0.73s | valid loss 0.00385 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  51 |     8/    8 batches | lr 0.000357 | 89.00 ms | loss 0.01924 | ppl     1.02\n",
      "| epoch  52 |     8/    8 batches | lr 0.000350 | 89.08 ms | loss 0.00879 | ppl     1.01\n",
      "| epoch  53 |     8/    8 batches | lr 0.000343 | 89.04 ms | loss 0.00578 | ppl     1.01\n",
      "| epoch  54 |     8/    8 batches | lr 0.000336 | 88.91 ms | loss 0.00949 | ppl     1.01\n",
      "| epoch  55 |     8/    8 batches | lr 0.000329 | 89.09 ms | loss 0.01723 | ppl     1.02\n",
      "| epoch  56 |     8/    8 batches | lr 0.000323 | 89.08 ms | loss 0.02897 | ppl     1.03\n",
      "| epoch  57 |     8/    8 batches | lr 0.000316 | 89.18 ms | loss 0.05868 | ppl     1.06\n",
      "| epoch  58 |     8/    8 batches | lr 0.000310 | 89.03 ms | loss 0.02571 | ppl     1.03\n",
      "| epoch  59 |     8/    8 batches | lr 0.000304 | 89.08 ms | loss 0.04309 | ppl     1.04\n",
      "| epoch  60 |     8/    8 batches | lr 0.000298 | 88.98 ms | loss 0.03032 | ppl     1.03\n",
      "| epoch  61 |     8/    8 batches | lr 0.000292 | 88.88 ms | loss 0.03398 | ppl     1.03\n",
      "| epoch  62 |     8/    8 batches | lr 0.000286 | 89.13 ms | loss 0.01067 | ppl     1.01\n",
      "| epoch  63 |     8/    8 batches | lr 0.000280 | 89.77 ms | loss 0.00572 | ppl     1.01\n",
      "| epoch  64 |     8/    8 batches | lr 0.000274 | 91.67 ms | loss 0.01158 | ppl     1.01\n",
      "| epoch  65 |     8/    8 batches | lr 0.000269 | 90.44 ms | loss 0.02204 | ppl     1.02\n",
      "| epoch  66 |     8/    8 batches | lr 0.000264 | 91.27 ms | loss 0.01322 | ppl     1.01\n",
      "| epoch  67 |     8/    8 batches | lr 0.000258 | 89.37 ms | loss 0.02105 | ppl     1.02\n",
      "| epoch  68 |     8/    8 batches | lr 0.000253 | 89.04 ms | loss 0.02770 | ppl     1.03\n",
      "| epoch  69 |     8/    8 batches | lr 0.000248 | 89.05 ms | loss 0.01569 | ppl     1.02\n",
      "| epoch  70 |     8/    8 batches | lr 0.000243 | 89.10 ms | loss 0.00775 | ppl     1.01\n",
      "| epoch  71 |     8/    8 batches | lr 0.000238 | 89.16 ms | loss 0.00472 | ppl     1.00\n",
      "| epoch  72 |     8/    8 batches | lr 0.000233 | 89.14 ms | loss 0.00528 | ppl     1.01\n",
      "| epoch  73 |     8/    8 batches | lr 0.000229 | 89.04 ms | loss 0.00612 | ppl     1.01\n",
      "| epoch  74 |     8/    8 batches | lr 0.000224 | 89.13 ms | loss 0.00528 | ppl     1.01\n",
      "| epoch  75 |     8/    8 batches | lr 0.000220 | 89.35 ms | loss 0.00370 | ppl     1.00\n",
      "| epoch  76 |     8/    8 batches | lr 0.000215 | 90.23 ms | loss 0.00499 | ppl     1.01\n",
      "| epoch  77 |     8/    8 batches | lr 0.000211 | 90.01 ms | loss 0.00830 | ppl     1.01\n",
      "| epoch  78 |     8/    8 batches | lr 0.000207 | 92.43 ms | loss 0.00926 | ppl     1.01\n",
      "| epoch  79 |     8/    8 batches | lr 0.000203 | 91.68 ms | loss 0.00981 | ppl     1.01\n",
      "| epoch  80 |     8/    8 batches | lr 0.000199 | 89.48 ms | loss 0.00563 | ppl     1.01\n",
      "| epoch  81 |     8/    8 batches | lr 0.000195 | 89.05 ms | loss 0.00638 | ppl     1.01\n",
      "| epoch  82 |     8/    8 batches | lr 0.000191 | 89.03 ms | loss 0.01013 | ppl     1.01\n",
      "| epoch  83 |     8/    8 batches | lr 0.000187 | 88.86 ms | loss 0.00816 | ppl     1.01\n",
      "| epoch  84 |     8/    8 batches | lr 0.000183 | 89.02 ms | loss 0.01641 | ppl     1.02\n",
      "| epoch  85 |     8/    8 batches | lr 0.000180 | 89.03 ms | loss 0.01788 | ppl     1.02\n",
      "| epoch  86 |     8/    8 batches | lr 0.000176 | 88.83 ms | loss 0.01012 | ppl     1.01\n",
      "| epoch  87 |     8/    8 batches | lr 0.000172 | 89.33 ms | loss 0.00655 | ppl     1.01\n",
      "| epoch  88 |     8/    8 batches | lr 0.000169 | 88.97 ms | loss 0.00452 | ppl     1.00\n",
      "| epoch  89 |     8/    8 batches | lr 0.000166 | 89.11 ms | loss 0.00685 | ppl     1.01\n",
      "| epoch  90 |     8/    8 batches | lr 0.000162 | 89.03 ms | loss 0.00811 | ppl     1.01\n",
      "| epoch  91 |     8/    8 batches | lr 0.000159 | 89.38 ms | loss 0.00717 | ppl     1.01\n",
      "| epoch  92 |     8/    8 batches | lr 0.000156 | 90.38 ms | loss 0.00932 | ppl     1.01\n",
      "| epoch  93 |     8/    8 batches | lr 0.000153 | 89.25 ms | loss 0.00975 | ppl     1.01\n",
      "| epoch  94 |     8/    8 batches | lr 0.000150 | 89.83 ms | loss 0.00406 | ppl     1.00\n",
      "| epoch  95 |     8/    8 batches | lr 0.000147 | 90.04 ms | loss 0.00474 | ppl     1.00\n",
      "| epoch  96 |     8/    8 batches | lr 0.000144 | 89.61 ms | loss 0.00676 | ppl     1.01\n",
      "| epoch  97 |     8/    8 batches | lr 0.000141 | 89.33 ms | loss 0.00661 | ppl     1.01\n",
      "| epoch  98 |     8/    8 batches | lr 0.000138 | 89.79 ms | loss 0.00835 | ppl     1.01\n",
      "| epoch  99 |     8/    8 batches | lr 0.000135 | 90.17 ms | loss 0.00954 | ppl     1.01\n",
      "| epoch 100 |     8/    8 batches | lr 0.000133 | 89.86 ms | loss 0.00669 | ppl     1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time:  1.09s | valid loss 0.00018 | valid ppl     1.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 101 |     8/    8 batches | lr 0.000130 | 90.70 ms | loss 0.00540 | ppl     1.01\n",
      "| epoch 102 |     8/    8 batches | lr 0.000127 | 90.49 ms | loss 0.00382 | ppl     1.00\n",
      "| epoch 103 |     8/    8 batches | lr 0.000125 | 89.22 ms | loss 0.00500 | ppl     1.01\n",
      "| epoch 104 |     8/    8 batches | lr 0.000122 | 90.08 ms | loss 0.00661 | ppl     1.01\n",
      "| epoch 105 |     8/    8 batches | lr 0.000120 | 89.10 ms | loss 0.00464 | ppl     1.00\n",
      "| epoch 106 |     8/    8 batches | lr 0.000117 | 89.23 ms | loss 0.00518 | ppl     1.01\n",
      "| epoch 107 |     8/    8 batches | lr 0.000115 | 89.28 ms | loss 0.00633 | ppl     1.01\n",
      "| epoch 108 |     8/    8 batches | lr 0.000113 | 89.06 ms | loss 0.00347 | ppl     1.00\n",
      "| epoch 109 |     8/    8 batches | lr 0.000111 | 89.12 ms | loss 0.00391 | ppl     1.00\n",
      "| epoch 110 |     8/    8 batches | lr 0.000108 | 88.88 ms | loss 0.00530 | ppl     1.01\n",
      "| epoch 111 |     8/    8 batches | lr 0.000106 | 89.68 ms | loss 0.00479 | ppl     1.00\n",
      "| epoch 112 |     8/    8 batches | lr 0.000104 | 91.43 ms | loss 0.00526 | ppl     1.01\n",
      "| epoch 113 |     8/    8 batches | lr 0.000102 | 89.42 ms | loss 0.00523 | ppl     1.01\n",
      "| epoch 114 |     8/    8 batches | lr 0.000100 | 89.59 ms | loss 0.00329 | ppl     1.00\n",
      "| epoch 115 |     8/    8 batches | lr 0.000098 | 90.22 ms | loss 0.00347 | ppl     1.00\n",
      "| epoch 116 |     8/    8 batches | lr 0.000096 | 92.13 ms | loss 0.00451 | ppl     1.00\n",
      "| epoch 117 |     8/    8 batches | lr 0.000094 | 89.59 ms | loss 0.00421 | ppl     1.00\n",
      "| epoch 118 |     8/    8 batches | lr 0.000092 | 89.23 ms | loss 0.00444 | ppl     1.00\n",
      "| epoch 119 |     8/    8 batches | lr 0.000090 | 91.61 ms | loss 0.00524 | ppl     1.01\n",
      "| epoch 120 |     8/    8 batches | lr 0.000089 | 90.57 ms | loss 0.00317 | ppl     1.00\n",
      "| epoch 121 |     8/    8 batches | lr 0.000087 | 89.78 ms | loss 0.00310 | ppl     1.00\n"
     ]
    }
   ],
   "source": [
    "result = dict()\n",
    "for i in ['open','close','high','low']:\n",
    "    predict,truth = train_and_get(i)\n",
    "    result.update({i:predict})\n",
    "    result.update({i+'_truth':truth})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result.keys():\n",
    "    result[i] = result[i].reshape(-1)\n",
    "output = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('result2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00d1462882258b783cb181eb86adde5698c4f2204c9695f847918151df6a5450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
